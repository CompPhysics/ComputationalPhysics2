TITLE: Computational Physics:  Introduction to Many-body Theory and Hartree-Fock theory
AUTHOR: Morten Hjorth-Jensen {copyright, 2013-present|CC BY-NC} at "National Superconducting Cyclotron Laboratory":"http://www.nscl.msu.edu/" and "Department of Physics and Astronomy":"https://www.pa.msu.edu/", "Michigan State University":"http://www.msu.edu/", East Lansing, MI 48824, USA & Department of Physics, University of Oslo, Oslo, Norway 
DATE:  today

!split
===== Quantum Many-particle Methods =====

* Large-scale diagonalization (Iterative methods, Lanczo's method, dimensionalities $10^{10}$ states)
* Coupled cluster theory, favoured method in quantum chemistry, molecular and atomic physics. Applications to ab initio calculations in nuclear physics as well for large nuclei
* Perturbative many-body methods
* Density functional theories/Mean-field theory and Hartree-Fock theory
* Monte-Carlo methods (Only in FYS4411, Computational quantum mechanics)
* Green's function theories
* and other. The physics of the system hints at which many-body methods to use.


!split
===== Selected Texts and Many-body theory =====

* Blaizot and Ripka, *Quantum Theory of Finite systems*, MIT press 1986
* Negele and Orland, *Quantum Many-Particle Systems*, Addison-Wesley, 1987.
* Fetter and Walecka, *Quantum Theory of Many-Particle Systems*, McGraw-Hill, 1971.
* Helgaker, Jorgensen and Olsen, *Molecular Electronic Structure Theory*, Wiley, 2001.
* Mattuck, *Guide to Feynman Diagrams in the Many-Body Problem*, Dover, 1971.
* Dickhoff and Van Neck, *Many-Body Theory Exposed*, World Scientific, 2006.



!split 
===== Definitions ===== 

An operator is defined as $\hat{O}$ throughout. Unless otherwise specified the number of particles is
always $N$ and $d$ is the dimension of the system.  In nuclear physics
we normally define the total number of particles to be $A=N+Z$, where
$N$ is total number of neutrons and $Z$ the total number of
protons. In case of other baryons such isobars $\Delta$ or various
hyperons such as $\Lambda$ or $\Sigma$, one needs to add their
definitions.  Hereafter, $N$ is reserved for the total number of
particles, unless otherwise specificied. 


!split
===== Definitions =====

The quantum numbers of a single-particle state in coordinate space are
defined by the variable 
!bt
\[
x=(\bm{r},\sigma), 
\]
!et
where 
!bt
\[
\bm{r}\in {\mathbb{R}}^{d},
\]
!et
with $d=1,2,3$ represents the spatial coordinates and $\sigma$ is the eigenspin of the particle. For fermions with eigenspin $1/2$ this means that
!bt
\[
 x\in {\mathbb{R}}^{d}\oplus (\frac{1}{2}),
\]
!et
and the integral $\int dx = \sum_{\sigma}\int d^dr = \sum_{\sigma}\int d\bm{r}$,
and
!bt
\[
\int d^Nx= \int dx_1\int dx_2\dots\int dx_N.
\]
!et



!split
===== Definitions =====

The quantum mechanical wave function of a given state with quantum numbers $\lambda$ (encompassing all quantum numbers needed to specify the system), ignoring time, is
!bt
\[
\Psi_{\lambda}=\Psi_{\lambda}(x_1,x_2,\dots,x_N),
\]
!et
with $x_i=(\bm{r}_i,\sigma_i)$ and the projection of $\sigma_i$ takes the values
$\{-1/2,+1/2\}$ for particles with spin $1/2$. 
We will hereafter always refer to $\Psi_{\lambda}$ as the exact wave function, and if the ground state is not degenerate we label it as 
!bt
\[
\Psi_0=\Psi_0(x_1,x_2,\dots,x_N).
\]
!et



!split
===== Definitions =====

Since the solution $\Psi_{\lambda}$ seldomly can be found in closed form, approximations are sought. Here we define an approximative wave function or an ansatz to the exact wave function as 
!bt
\[
\Phi_{\lambda}=\Phi_{\lambda}(x_1,x_2,\dots,x_N),
\]
!et
with
!bt 
\[
\Phi_0=\Phi_0(x_1,x_2,\dots,x_N),
\]
!et
being the ansatz to the ground state.  



!split
===== Definitions =====

The wave function $\Psi_{\lambda}$ is sought in the Hilbert space of either symmetric or anti-symmetric $N$-body functions, namely
!bt
\[
\Psi_{\lambda}\in {\cal H}_N:= {\cal H}_1\oplus{\cal H}_1\oplus\dots\oplus{\cal H}_1,
\]
!et
where the single-particle Hilbert space $\hat{H}_1$ is the space of square integrable functions over
$\in {\mathbb{R}}^{d}\oplus (\sigma)$
resulting in
!bt
\[
{\cal H}_1:= L^2(\mathbb{R}^{d}\oplus (\sigma)).
\]
!et




!split
===== Definitions =====

Our Hamiltonian is invariant under the permutation (interchange) of two particles.
Since we deal with fermions however, the total wave function is antisymmetric.
Let $\hat{P}$ be an operator which interchanges two particles.
Due to the symmetries we have ascribed to our Hamiltonian, this operator commutes with the total Hamiltonian,
!bt
\[
[\hat{H},\hat{P}] = 0,
\]
!et
meaning that $\Psi_{\lambda}(x_1, x_2, \dots , x_N)$ is an eigenfunction of 
$\hat{P}$ as well, that is
!bt
\[
\hat{P}_{ij}\Psi_{\lambda}(x_1, x_2, \dots,x_i,\dots,x_j,\dots,x_N)=
\beta\Psi_{\lambda}(x_1, x_2, \dots,x_j,\dots,x_i,\dots,x_N),
\]
!et
where $\beta$ is the eigenvalue of $\hat{P}$. We have introduced the suffix $ij$ in order to indicate that we permute particles $i$ and $j$.
The Pauli principle tells us that the total wave function for a system of fermions
has to be antisymmetric, resulting in the eigenvalue $\beta = -1$.   



!split
===== Definitions and notations =====

The Schrodinger equation reads 
!bt
\begin{equation}
\hat{H}(x_1, x_2, \dots , x_N) \Psi_{\lambda}(x_1, x_2, \dots , x_N) = 
E_\lambda  \Psi_\lambda(x_1, x_2, \dots , x_N), label{eq:basicSE1}
\end{equation}
!et
where the vector $x_i$ represents the coordinates (spatial and spin) of particle $i$, $\lambda$ stands  for all the quantum
numbers needed to classify a given $N$-particle state and $\Psi_{\lambda}$ is the pertaining eigenfunction.  Throughout this course,
$\Psi$ refers to the exact eigenfunction, unless otherwise stated.


!split
===== Definitions and notations =====

We write the Hamilton operator, or Hamiltonian,  in a generic way 
!bt
\[
	\hat{H} = \hat{T} + \hat{V} 
\]
!et
where $\hat{T}$  represents the kinetic energy of the system
!bt
\[
	\hat{T} = \sum_{i=1}^N \frac{\mathbf{p}_i^2}{2m_i} = \sum_{i=1}^N \left( -\frac{\hbar^2}{2m_i} \mathbf{\nabla_i}^2 \right) =
		\sum_{i=1}^N t(x_i)
\]
!et
while the operator $\hat{V}$ for the potential energy is given by
!bt
\begin{equation}
	\hat{V} = \sum_{i=1}^N \hat{u}_{\mathrm{ext}}(x_i) + \sum_{j < i=1}^N v(x_i,x_j)+\sum_{i< j < k=1}^Nv(x_i,x_j,x_k)+\dots
label{eq:firstv}
\end{equation}
!et
Hereafter we use natural units, viz.~$\hbar=c=e=1$, with $e$ the elementary charge and $c$ the speed of light. This means that momenta and masses
have dimension energy. 


 
!split
===== Definitions and notations =====

If one does quantum chemistry, after having introduced the  Born-Oppenheimer approximation which effectively freezes out the nucleonic degrees of freedom, the Hamiltonian for $N=n_e$ electrons takes the following form 
!bt 
\[
  \hat{H} = \sum_{i=1}^{n_e} t(x_i) - \sum_{i=1}^{n_e} k\frac{Z}{r_i} + \sum_{i < j}^{n_e} \frac{k}{r_{ij}},
\]
!et
with $k=1.44$ eVnm



!split
===== Definitions and notations =====

We can rewrite this as
!bt
\begin{equation}
    \hat{H} = \hat{H}_0 + \hat{H}_I 
    = \sum_{i=1}^{n_e}\hat{h}_0(x_i) + \sum_{i < j}^{n_e}\frac{1}{r_{ij}},
label{H1H2}
\end{equation}
!et
where  we have defined 
!bt
\[
r_{ij}=| \bm{r}_i-\bm{r}_j|,
\]
!et
 and
!bt
\begin{equation}
  \hat{h}_0(x_i) =  \hat{t}(x_i) - \frac{Z}{x_i}.
label{hi}
\end{equation}
!et
The first term of Eq.~(ref{H1H2}), $H_0$, is the sum of the $N$
*one-body* Hamiltonians $\hat{h}_0$. Each individual
Hamiltonian $\hat{h}_0$ contains the kinetic energy operator of an
electron and its potential energy due to the attraction of the
nucleus. The second term, $H_I$, is the sum of the $n_e(n_e-1)/2$
two-body interactions between each pair of electrons. Note that the double sum carries a restriction $i < j$.



!split
===== Definitions and notations =====

The potential energy term due to the attraction of the nucleus defines the onebody field $u_i=u_{\mathrm{ext}}(x_i)$ of Eq.~(ref{eq:firstv}).
We have moved this term into the $\hat{H}_0$ part of the Hamiltonian, instead of keeping  it in $\hat{V}$ as in  Eq.~(ref{eq:firstv}).
The reason is that we will hereafter treat $\hat{H}_0$ as our non-interacting  Hamiltonian. For a many-body wavefunction $\Phi_{\lambda}$ defined by an  
appropriate single-particle basis, we may solve exactly the non-interacting eigenvalue problem 
!bt 
\[
\hat{H}_0\Phi_{\lambda}= w_{\lambda}\Phi_{\lambda},
\]
!et
with $w_{\lambda}$ being the non-interacting energy. This energy is defined by the sum over single-particle energies to be defined below.
For atoms the single-particle energies could be the hydrogen-like single-particle energies corrected for the charge $Z$. For nuclei and quantum
dots, these energies could be given by the harmonic oscillator in three and two dimensions, respectively.


!split
===== Definitions and notations =====

We will assume that the interacting part of the Hamiltonian
can be approximated by a two-body interaction.
This means that our Hamiltonian is written as 
!bt
\begin{equation}
    \hat{H} = \hat{H}_0 + \hat{H}_I 
    = \sum_{i=1}^N \hat{h}_0(x_i) + \sum_{i < j}^N V(r_{ij}),
label{Hnuclei}
\end{equation}
!et
with 
!bt
\begin{equation}
  H_0=\sum_{i=1}^N \hat{h}_0(x_i) =  \sum_{i=1}^N\left(\hat{t}(x_i) + \hat{u}_{\mathrm{ext}}(x_i)\right).
label{hinuclei}
\end{equation}
!et
The onebody part $u_{\mathrm{ext}}(x_i)$ is normally approximated by a harmonic oscillator potential or the Coulomb interaction an electron feels from the nucleus. However, other potentials are fully possible, such as 
one derived from the self-consistent solution of the Hartree-Fock equations.



!split
===== Definitions and notations =====

Our Hamiltonian is invariant under the permutation (interchange) of two particles. % (exercise here, prove it)
Since we deal with fermions however, the total wave function is antisymmetric.
Let $\hat{P}$ be an operator which interchanges two particles.
Due to the symmetries we have ascribed to our Hamiltonian, this operator commutes with the total Hamiltonian,
!bt 
\[
[\hat{H},\hat{P}] = 0,
 \]
!et
meaning that $\Psi_{\lambda}(x_1, x_2, \dots , x_N)$ is an eigenfunction of 
$\hat{P}$ as well, that is
!bt 
\[
\hat{P}_{ij}\Psi_{\lambda}(x_1, x_2, \dots,x_i,\dots,x_j,\dots,x_N)=
\beta\Psi_{\lambda}(x_1, x_2, \dots,x_i,\dots,x_j,\dots,x_N),
\]
!et
where $\beta$ is the eigenvalue of $\hat{P}$. We have introduced the suffix $ij$ in order to indicate that we permute particles $i$ and $j$.
The Pauli principle tells us that the total wave function for a system of fermions
has to be antisymmetric, resulting in the eigenvalue $\beta = -1$.   


!split
===== Definitions and notations =====

In our case we assume that  we can approximate the exact eigenfunction with a Slater determinant
!bt
\begin{equation}
   \Phi(x_1, x_2,\dots ,x_N,\alpha,\beta,\dots, \sigma)=\frac{1}{\sqrt{N!}}
\left| \begin{array}{ccccc} \psi_{\alpha}(x_1)& \psi_{\alpha}(x_2)& \dots & \dots & \psi_{\alpha}(x_N)\\
                            \psi_{\beta}(x_1)&\psi_{\beta}(x_2)& \dots & \dots & \psi_{\beta}(x_N)\\  
                            \dots & \dots & \dots & \dots & \dots \\
                            \dots & \dots & \dots & \dots & \dots \\
                     \psi_{\sigma}(x_1)&\psi_{\sigma}(x_2)& \dots & \dots & \psi_{\sigma}(x_N)\end{array} \right|, label{eq:HartreeFockDet}
\end{equation}
!et
where  $x_i$  stand for the coordinates and spin values of a particle $i$ and $\alpha,\beta,\dots, \gamma$ 
are quantum numbers needed to describe remaining quantum numbers.  


!split
===== Definitions and notations =====

The single-particle function $\psi_{\alpha}(x_i)$  are eigenfunctions of the onebody
Hamiltonian $h_i$, that is
!bt 
\[
\hat{h}_0(x_i)=\hat{t}(x_i) + \hat{u}_{\mathrm{ext}}(x_i),
\]
!et
with eigenvalues 
!bt 
\[
\hat{h}_0(x_i) \psi_{\alpha}(x_i)=\left(\hat{t}(x_i) + \hat{u}_{\mathrm{ext}}(x_i)\right)\psi_{\alpha}(x_i)=\varepsilon_{\alpha}\psi_{\alpha}(x_i).
\]
!et
The energies $\varepsilon_{\alpha}$ are the so-called non-interacting single-particle energies, or unperturbed energies. 
The total energy is in this case the sum over all  single-particle energies, if no two-body or more complicated
many-body interactions are present.


!split
===== Definitions and notations =====

Let us denote the ground state energy by $E_0$. According to the
variational principle we have
!bt
\[
  E_0 \le E[\Phi] = \int \Phi^*\hat{H}\Phi d\mathbf{\tau}
\]
!et
where $\Phi$ is a trial function which we assume to be normalized
!bt
\[
  \int \Phi^*\Phi d\mathbf{\tau} = 1,
\]
!et
where we have used the shorthand $d\mathbf{\tau}=d\mathbf{r}_1d\mathbf{r}_2\dots d\mathbf{r}_N$.



!split
===== Brief reminder on some linear algebra properties =====

Before we proceed with a more compact representation of a Slater determinant, we would like to repeat some linear algebra properties which will be useful for our derivations of the energy as function of a Slater determinant, Hartree-Fock theory and later the nuclear shell model.

The inverse of a matrix is defined by

!bt
\[
\mathbf{A}^{-1} \cdot \mathbf{A} = I
\]
!et
A unitary matrix $\mathbf{A}$ is one whose inverse is its adjoint
!bt
\[
\mathbf{A}^{-1}=\mathbf{A}^{\dagger}
\]
!et
A real unitary matrix is called orthogonal and its inverse is equal to its transpose.
A hermitian matrix is its own self-adjoint, that  is
!bt
\[
\mathbf{A}=\mathbf{A}^{\dagger}. 
\]
!et



!split
===== Basic Matrix Features =====

 Matrix Properties Reminder

|----------------------------------------------------------------------|
|       Relations      |       Name      | matrix elements             |
|----------------------------------------------------------------------|
| $A = A^{T}$         | symmetric       | $a_{ij} = a_{ji}$            |
| $A = \left (A^{T} \right )^{-1}$ | real orthogonal | $\sum_k a_{ik} a_{jk} = \sum_k a_{ki} a_{kj} = \delta_{ij}$ |
| $A = A^{ * }$          | real matrix     | $a_{ij} = a_{ij}^{ * }$       |
| $A = A^{\dagger}$     |  hermitian      | $a_{ij} = a_{ji}^{ * }$       |
| $A = \left (A^{\dagger} \right )^{-1}$ | unitary | $\sum_k a_{ik} a_{jk}^{ * } = \sum_k a_{ki}^{ * } a_{kj} = \delta_{ij}$ |
|----------------------------------------------------------------------|





!split
===== Basic Matrix Features =====

If we deal with Fermions (identical and indistinguishable particles) we will 
form an ansatz for a given state in terms of so-called Slater determinants determined
by a chosen basis of single-particle functions. 

For a given $n\times n$ matrix $\mathbf{A}$ we can write its determinant
!bt
\[
   det(\mathbf{A})=|\mathbf{A}|=
\left| \begin{array}{ccccc} a_{11}& a_{12}& \dots & \dots & a_{1n}\\
                            a_{21}&a_{22}& \dots & \dots & a_{2n}\\  
                            \dots & \dots & \dots & \dots & \dots \\
                            \dots & \dots & \dots & \dots & \dots \\
                            a_{n1}& a_{n2}& \dots & \dots & a_{nn}\end{array} \right|,
\]
!et
in a more compact form as 
!bt
\[
|\mathbf{A}|= \sum_{i=1}^{n!}(-1)^{p_i}\hat{P}_i a_{11}a_{22}\dots a_{nn},
\]
!et
where $\hat{P}_i$ is a permutation operator which permutes the column indices $1,2,3,\dots,n$
and the sum runs over all $n!$ permutations.  The quantity $p_i$ represents the number of transpositions of column indices that are needed in order to bring a given permutation back to its initial ordering, in our case given by $a_{11}a_{22}\dots a_{nn}$ here.



!split
===== Basic Matrix Features, simple $2 \times 2$ determinant  =====

A simple $2\times 2$ determinant illustrates this. We have
!bt
\[
   det(\mathbf{A})=
\left| \begin{array}{cc} a_{11}& a_{12}\\
                            a_{21}&a_{22}\end{array} \right|= (-1)^0a_{11}a_{22}+(-1)^1a_{12}a_{21},
\]
!et
where in the last term we have interchanged the column indices $1$ and $2$. The natural ordering we have chosen is $a_{11}a_{22}$. 




!split
===== Definitions and notations =====

With the above we can rewrite our Slater determinant in a more compact form.
In the Hartree-Fock method the trial function is the Slater
determinant of Eq.~(ref{eq:HartreeFockDet}) which can be rewritten as 
!bt
\[
  \Phi(x_1,x_2,\dots,x_N,\alpha,\beta,\dots,\nu) = \frac{1}{\sqrt{N!}}\sum_{P} (-)^P\hat{P}\psi_{\alpha}(x_1)
    \psi_{\beta}(x_2)\dots\psi_{\nu}(x_N)=\sqrt{N!}\hat{A}\Phi_H,
\]
!et
where we have introduced the antisymmetrization operator $\hat{A}$ defined by the 
summation over all possible permutations of two particles.


!split
===== Definitions and notations =====

It is defined as
!bt
\begin{equation}
  \hat{A} = \frac{1}{N!}\sum_{p} (-)^p\hat{P},
label{antiSymmetryOperator}
\end{equation}
!et
with $p$ standing for the number of permutations. We have introduced for later use the so-called
Hartree-function, defined by the simple product of all possible single-particle functions
!bt
\[
  \Phi_H(x_1,x_2,\dots,x_N,\alpha,\beta,\dots,\nu) =
  \psi_{\alpha}(x_1)
    \psi_{\beta}(x_2)\dots\psi_{\nu}(x_N).
\]
!et


!split
===== Definitions and notations =====

Both $\hat{H}_0$ and $\hat{H}_I$ are invariant under all possible permutations of any two particles
and hence commute with $\hat{A}$
!bt
\begin{equation}
  [H_0,\hat{A}] = [H_I,\hat{A}] = 0. label{commutionAntiSym}
\end{equation}
!et
Furthermore, $\hat{A}$ satisfies
!bt
\begin{equation}
  \hat{A}^2 = \hat{A},  label{AntiSymSquared}
\end{equation}
!et
since every permutation of the Slater
determinant reproduces it. 


!split
===== Definitions and notations =====

The expectation value of $\hat{H}_0$ 
!bt
\[
  \int \Phi^*\hat{H}_0\Phi d\mathbf{\tau} 
  = N! \int \Phi_H^*\hat{A}\hat{H}_0\hat{A}\Phi_H d\mathbf{\tau}
\]
!et
is readily reduced to
!bt
\[
  \int \Phi^*\hat{H}_0\Phi d\mathbf{\tau} 
  = N! \int \Phi_H^*\hat{H}_0\hat{A}\Phi_H d\mathbf{\tau},
\]
!et
where we have used Eqs.~(ref{commutionAntiSym}) and
(ref{AntiSymSquared}). The next step is to replace the antisymmetrization
operator by its definition and to
replace $\hat{H}_0$ with the sum of one-body operators
!bt
\[
  \int \Phi^*\hat{H}_0\Phi  d\mathbf{\tau}
  = \sum_{i=1}^N \sum_{p} (-)^p\int 
  \Phi_H^*\hat{h}_0\hat{P}\Phi_H d\mathbf{\tau}.
\]
!et


!split
===== Definitions and notations =====

The integral vanishes if two or more particles are permuted in only one
of the Hartree-functions $\Phi_H$ because the individual single-particle wave functions are
orthogonal. We obtain then
!bt
\[
  \int \Phi^*\hat{H}_0\Phi  d\mathbf{\tau}= \sum_{i=1}^N \int \Phi_H^*\hat{h}_0\Phi_H  d\mathbf{\tau}.
\]
!et
Orthogonality of the single-particle functions allows us to further simplify the integral, and we
arrive at the following expression for the expectation values of the
sum of one-body Hamiltonians 
!bt
\begin{equation}
  \int \Phi^*\hat{H}_0\Phi  d\mathbf{\tau}
  = \sum_{\mu=1}^N \int \psi_{\mu}^*(\mathbf{r})\hat{h}_0\psi_{\mu}(\mathbf{r})
  d\mathbf{r}.
  label{H1Expectation}
\end{equation}
!et


!split
===== Definitions and notations =====

We introduce the following shorthand for the above integral
!bt
\[
\langle \mu | \hat{h}_0 | \mu \rangle = \int \psi_{\mu}^*(\mathbf{r})\hat{h}_0\psi_{\mu}(\mathbf{r})  d\mathbf{r},
\]
!et
and rewrite Eq.~(ref{H1Expectation}) as
!bt
\begin{equation}
  \int \Phi^*\hat{H}_0\Phi  d\mathbf{\tau}
  = \sum_{\mu=1}^N \langle \mu | \hat{h}_0 | \mu \rangle.
  label{H1Expectation1}
\end{equation}
!et


!split
===== Definitions and notations =====

The expectation value of the two-body part of the Hamiltonian is obtained in a
similar manner. We have
!bt
\[
  \int \Phi^*\hat{H}_I\Phi d\mathbf{\tau} 
  = N! \int \Phi_H^*\hat{A}\hat{H}_I\hat{A}\Phi_H d\mathbf{\tau},
\]
!et
which reduces to
!bt
\[
 \int \Phi^*\hat{H}_I\Phi d\mathbf{\tau} 
  = \sum_{i\le j=1}^N \sum_{p} (-)^p\int 
  \Phi_H^*V(r_{ij})\hat{P}\Phi_H d\mathbf{\tau},
\]
!et
by following the same arguments as for the one-body
Hamiltonian. 


!split
===== Definitions and notations =====

Because of the dependence on the inter-particle distance $r_{ij}$,  permutations of
any two particles no longer vanish, and we get
!bt
\[
  \int \Phi^*\hat{H}_I\Phi d\mathbf{\tau} 
  = \sum_{i < j=1}^N \int  
  \Phi_H^*V(r_{ij})(1-P_{ij})\Phi_H d\mathbf{\tau}.
\]
!et
where $P_{ij}$ is the permutation operator that interchanges
particle $i$ and particle $j$. Again we use the assumption that the single-particle wave functions
are orthogonal. 



!split
===== Definitions and notations =====

We obtain
!bt
\begin{align}
  \int \Phi^*\hat{H}_I\Phi d\mathbf{\tau} 
  = \frac{1}{2}\sum_{\mu=1}^N\sum_{\nu=1}^N
    &\left[ \int \psi_{\mu}^*(x_i)\psi_{\nu}^*(x_j)V(r_{ij})\psi_{\mu}(x_i)\psi_{\nu}(x_j)
    dx_idx_j \right.\\
  &\left.
  - \int \psi_{\mu}^*(x_i)\psi_{\nu}^*(x_j)
  V(r_{ij})\psi_{\nu}(x_i)\psi_{\mu}(x_j)
  dx_idx_j
  \right]. label{H2Expectation}
\end{align}
!et
The first term is the so-called direct term. It is frequently also called the  Hartree term, 
while the second is due to the Pauli principle and is called
the exchange term or just the Fock term.
The factor  $1/2$ is introduced because we now run over
all pairs twice. 


!split
===== Definitions and notations =====

The last equation allows us to  introduce some further definitions.  
The single-particle wave functions $\psi_{\mu}(x)$, defined by the quantum numbers $\mu$ and $x$
are defined as the overlap 
!bt
\[
   \psi_{\alpha}(x)  = \langle x | \alpha \rangle .
\]
!et


!split
===== Definitions and notations =====

We introduce the following shorthands for the above two integrals
!bt
\[
\langle \mu\nu|\hat{v}|\mu\nu\rangle =  \int \psi_{\mu}^*(x_i)\psi_{\nu}^*(x_j)V(r_{ij})\psi_{\mu}(x_i)\psi_{\nu}(x_j)
    dx_idx_j,
\]
!et
and
!bt 
\[
\langle \mu\nu|\hat{v}|\nu\mu\rangle = \int \psi_{\mu}^*(x_i)\psi_{\nu}^*(x_j)
  V(r_{ij})\psi_{\nu}(x_i)\psi_{\mu}(x_j)
  dx_idx_j.  
\]
!et


!split
===== Definitions and notations =====

The direct and exchange matrix elements can be  brought together if we define the antisymmetrized matrix element
!bt
\[
\langle \mu\nu|\hat{v}|\mu\nu\rangle_{\mathrm{AS}}= \langle \mu\nu|\hat{v}|\mu\nu\rangle-\langle \mu\nu|\hat{v}|\nu\mu\rangle,
\]
!et
or for a general matrix element  
!bt
\[
\langle \mu\nu|\hat{v}|\sigma\tau\rangle_{\mathrm{AS}}= \langle \mu\nu|\hat{v}|\sigma\tau\rangle-\langle \mu\nu|\hat{v}|\tau\sigma\rangle.
\]
!et
It has the symmetry property
!bt
\[
\langle \mu\nu|\hat{v}|\sigma\tau\rangle_{\mathrm{AS}}= -\langle \mu\nu|\hat{v}|\tau\sigma\rangle_{\mathrm{AS}}=-\langle \nu\mu|\hat{v}|\sigma\tau\rangle_{\mathrm{AS}}.
\]
!et



!split
===== Definitions and notations =====

The antisymmetric matrix element is also hermitian, implying 
!bt
\[
\langle \mu\nu|\hat{v}|\sigma\tau\rangle_{\mathrm{AS}}= \langle \sigma\tau|\hat{v}|\mu\nu\rangle_{\mathrm{AS}}.
\]
!et
With these notations we rewrite Eq.~(ref{H2Expectation}) as 
!bt
\begin{equation}
  \int \Phi^*\hat{H}_I\Phi d\mathbf{\tau} 
  = \frac{1}{2}\sum_{\mu=1}^N\sum_{\nu=1}^N \langle \mu\nu|\hat{v}|\mu\nu\rangle_{\mathrm{AS}}.
label{H2Expectation2}
\end{equation}
!et


!split
===== Definitions and notations =====

Combining Eqs.~(ref{H1Expectation1}) and
(ref{H2Expectation2}) we obtain the energy functional 
!bt
\begin{equation}
  E[\Phi] 
  = \sum_{\mu=1}^N \langle \mu | \hat{h}_0 | \mu \rangle +
  \frac{1}{2}\sum_{{\mu}=1}^N\sum_{{\nu}=1}^N \langle \mu\nu|\hat{v}|\mu\nu\rangle_{\mathrm{AS}}.
label{FunctionalEPhi}
\end{equation}
!et
which we will use as our starting point for the Hartree-Fock calculations. 




!split
===== Why Hartree-Fock?  =====

Hartree-Fock (HF) theory is an algorithm for finding an approximative expression for the ground state of a given Hamiltonian. The basic ingredients are
 *  Define a single-particle basis $\{\psi_{\alpha}\}$ so that
!bt
\[ 
\hat{h}^{\mathrm{HF}}\psi_{\alpha} = \varepsilon_{\alpha}\psi_{\alpha}
\]
!et
with the Hartree-Fock Hamiltonian defined as
!bt
\[
\hat{h}^{\mathrm{HF}}=\hat{t}+\hat{u}_{\mathrm{ext}}+\hat{u}^{\mathrm{HF}}
\]
!et
 *  The term  $\hat{u}^{\mathrm{HF}}$ is a single-particle potential to be determined by the HF algorithm.
 *  The HF algorithm means to choose $\hat{u}^{\mathrm{HF}}$ in order to have 
!bt
\[ \langle \hat{H} \rangle = E^{\mathrm{HF}}= \langle \Phi_0 | \hat{H}|\Phi_0 \rangle
\]
!et
that is to find a local minimum with a Slater determinant $\Phi_0$ being the ansatz for the ground state. 
 *  The variational principle ensures that $E^{\mathrm{HF}} \ge E_0$, with $E_0$ the exact ground state energy.



!split
===== Why Hartree-Fock?  =====

We will show that the Hartree-Fock Hamiltonian $\hat{h}^{\mathrm{HF}}$ equals our definition of the operator $\hat{f}$ discussed in connection with the new definition of the normal-ordered Hamiltonian (see later lectures), that is we have, for a specific matrix element
!bt
\[
\langle p |\hat{h}^{\mathrm{HF}}| q \rangle =\langle p |\hat{f}| q \rangle=\langle p|\hat{t}+\hat{u}_{\mathrm{ext}}|q \rangle +\sum_{i\le F} \langle pi | \hat{V} | qi\rangle_{AS},
\]
!et
meaning that
!bt
\[
\langle p|\hat{u}^{\mathrm{HF}}|q\rangle = \sum_{i\le F} \langle pi | \hat{V} | qi\rangle_{AS}.
\]
!et
The so-called Hartree-Fock potential $\hat{u}^{\mathrm{HF}}$ brings an explicit medium dependence due to the summation over all single-particle states below the Fermi level $F$. It brings also in an explicit dependence on the two-body interaction (in nuclear physics we can also have complicated three- or higher-body forces). The two-body interaction, with its contribution from the other bystanding fermions, creates an effective mean field in which a given fermion moves, in addition to the external potential $\hat{u}_{\mathrm{ext}}$ which confines the motion of the fermion. For systems like nuclei, there is no external confining potential. Nuclei are examples of self-bound systems, where the binding arises due to the intrinsic nature of the strong force. For nuclear systems thus, there would be no external one-body potential in the Hartree-Fock Hamiltonian. 



!split
===== Example system for fermions:  quantum dots =====

We will deal only with systems where all possible single-particle states below a certain level are filled up. Such systems are called closed shell systems, a naming inspired from atomic and nuclear physics. These closed shell systems define what is frequently named _magic numbers_. Quantum dots exhibit also magic numbers, meaning that the addition or removal of one eletron requires more energy than systems where the lowest-lying shells are not filled. Using the harmonic oscillator in two dimensions as basis functions (with degenerate single-particle energies) the magic numbers are $N=2$, $N=6$, $N=12$, $N=20$ etc, where $N$ is the number of electrons. See the table below for more details. 

We write our Hamiltonian as a one-body part 
!bt
\[
\hat{H}_0=\sum_{i=1}^{N_e}\left(-{\frac{1}{2}}\nabla^2_{i}+\frac{ \omega^2}{2}r^2_{i} \right),
\]
!et
and an interacting part
!bt
\[
\hat{V}=\sum_{i < j}^{N_e}\frac{1}{|\bm{r}_i-\bm{r}_j|}.
\]
!et
The unperturbed part of the Hamiltonian yields the  single-particle energies
!bt
\[
\epsilon_i = \omega\left(2n+|m| + 1\right),
\]
!et
where $n = 0,1,2,3,..$ and $m = 0, \pm 1, \pm 2,..$. The index $i$ runs from $0,1,2,\dots$.







!split
===== Our integrals  =====
 
The integral
!bt
\[
\langle pq \vert \hat{v} \vert rs \rangle = A\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}\int_{-\infty}^{\infty} \exp{[-(x_1^2+x_2^2+y_1^2+y_2^2)/2]}f(x_1,y_1,x_2,y_2)dx_1dy_1dx_2dy_2,
\]
!et
can be calculate in analytical form if we switch to polar coordinates. 




!split
===== Single-particle functions in polar coordinates  =====

Instead of Hermite polynomials it is convenient for the Hartree-Fock calculations to use polar coordinates.


Using polar coordinates
!bt
\begin{align}
x &= r \cos \theta \\
y &= r \sin \theta \\
r &= \sqrt{x^2 + y^2},
\end{align}
!et
the normalized solution for the angular part in two dimensions is
!bt
\[
Y(\theta) = \frac{1}{\sqrt{2\pi}} e^{im\theta}
  \label{normalized angular part}
\]
!et

The total wavefunction must satisfy the physical condition that $\psi(r,\theta) = \psi(r,\theta+2\pi)$ This makes a restriction on the quantum number $m$ which can take integral values
!bt
\[
m = 0, \pm 1, \pm 2, ...
\]
!et

!split 
===== Eigenfunctions in two dimensions =====

The time-independent part of the wave function  is separated in an angular and a radial part
!bt
\[
\psi(r,\theta) = R(r) \frac{1}{\sqrt{2\pi}} e^{im\theta}, \qquad m=0,\pm 1, \pm 2,... 
\]
!et

The solution of the radial equation is
!bt
\[
R_{nm}(r) = \sqrt{\frac{2n!}{(n+|m|)!}}\beta^{\frac{1}{2}(|m|+1)}r^{|m|}e^{-\frac{1}{2}\beta r^2} L_n^{|m|} (\beta r^2)
\]
!et
Here the subscript $n$ denote the principal quantum number, and $m$ is the angular momentum number
!bt
\begin{align}
  n &= 0, 1, 2, 3, .... \\
  m &= 0, \pm 1, \pm, 2, \pm 3,...
\end{align}
!et
$L_n^{|m|}$ is the associated Laguerre polynomials discussed above, and $\beta$ is defined as
!bt
\[
\beta = \frac{m\omega}{\hbar}
\]
!et


!split
===== Final expression for the eigenfunction =====

The final eigenfunction for an electron moving in a two-dimensional harmonic oscillator is then
!bt
\[
 \psi(r,\theta) = \sqrt{\frac{n!}{\pi(n+|m|)!}}\beta^{\frac{1}{2}(|m|+1)}r^{|m|}e^{-\frac{1}{2}\beta r^2} L_n^{|m|} (\beta r^2) e^{im\theta},
\]
!et
with the  eigenvalue
!bt
\[
E = \hbar \omega(2n+|m|+1)
\]
!et
which is the same as the energy with cartesian coordinates but now in terms of $n_x$ and $n_y$, that is
!bt
\[
E = \hbar \omega(n_x+n_y+1).
\]
!et

!split
===== "Program for computing the Coulomb interaction in polar coordinates":"https://github.com/CompPhysics/ComputationalPhysics2/tree/gh-pages/doc/Programs/QDCoulombPotential" =====

The program is based on the analytical expression given by "Anisimova and Matulis":"http://iopscience.iop.org/article/10.1088/0953-8984/10/3/013/pdf". It returns the value of the integral (without checking for spin values, you need to add this test) using as input the quantum numbers
$n_i$ and $m_i$, that is 
!bt
\[
\langle pq \vert \hat{v} \vert rs \rangle =\langle (n_pm_p)(n_qm_q) \vert \hat{v} \vert (n_rm_r)(n_sm_s) \rangle, 
\]
!et  
and the main code is (click on the above link for the full code)
!bc cppcod
#include "Coulomb_Functions.hpp"

int main(int argc, char * argv[])
{
  if(argc != 10){ std::cerr << "Wrong Input: should be ./QD_Coulomb  hw  n1  ml1  n2  ml2  n3  ml3  n4  ml4" << std::endl; exit(1); }
  double hw = std::atof(argv[1]);
  int n1 = std::atoi(argv[2]);
  int ml1 = std::atoi(argv[3]);
  int n2 = std::atoi(argv[4]);
  int ml2 = std::atoi(argv[5]);
  int n3 = std::atoi(argv[6]);
  int ml3 = std::atoi(argv[7]);
  int n4 = std::atoi(argv[8]);
  int ml4 = std::atoi(argv[9]);

  double TBME = Coulomb_HO(hw, n1, ml1, n2, ml2, n3, ml3, n4, ml4);
  std::cout << std::setprecision(12);
  std::cout << "< " << n1 << "," << ml1 << " ; " << n2 << "," << ml2 << " || V || " << n3 << "," << ml3 << " ; " << n4 << "," << ml4 << " > = " << TBME << std::endl;
  
  return 0;
}
!ec

!split
===== Conserved quantum numbers =====

When setting up the matrix elements 
!bt
\[
\langle pq \vert \hat{v} \vert rs \rangle =\langle (n_pm_p)(n_qm_q) \vert \hat{v} \vert (n_rm_r)(n_sm_s) \rangle, 
\]
!et  
you need to take into account that there are conserved two-electron quantum numbers since the Hamiltonian is invariant under rotations, namely
!bt
\[
m_p+m_q = M = m_r+m_s,
\]
!et
and the total spin projection which is not included in the above code. You need to add this as a test, that is check that
!bt
\[
\sigma_p+\sigma_q = S_z = \sigma_r+\sigma_s.
\]
!et
Finally, you need to ensure that the single-particle spinors satisfy  $\sigma_p=\sigma_r$ 
and $\sigma_q=\sigma_s$. Pay in particular attention to this when you compute the exchange matrix elements. 

!split
===== Reminder on Variational Calculus and Lagrangian Multipliers  =====
 
The calculus of variations involves 
problems where the quantity to be minimized or maximized is an integral. 

In the general case we have an integral of the type
!bt
\[ 
E[\Phi]= \int_a^b f(\Phi(x),\frac{\partial \Phi}{\partial x},x)dx,
\]
!et
where $E$ is the quantity which is sought minimized or maximized.
The problem is that although $f$ is a function of the variables $\Phi$, $\partial \Phi/\partial x$ and $x$, the exact dependence of
$\Phi$ on $x$ is not known.  This means again that even though the integral has fixed limits $a$ and $b$, the path of integration is
not known. In our case the unknown quantities are the single-particle wave functions and we wish to choose an integration path which makes
the functional $E[\Phi]$ stationary. This means that we want to find minima, or maxima or saddle points. In physics we search normally for minima.
Our task is therefore to find the minimum of $E[\Phi]$ so that its variation $\delta E$ is zero  subject to specific
constraints. In our case the constraints appear as the integral which expresses the orthogonality of the  single-particle wave functions.
The constraints can be treated via the technique of Lagrangian multipliers



!split
===== Variational Calculus and Lagrangian Multipliers, simple example  =====
 
Let us specialize to the expectation value of the energy for one particle in three-dimensions.
This expectation value reads
!bt
\[
  E=\int dxdydz \psi^*(x,y,z) \hat{H} \psi(x,y,z),
\]
!et
with the constraint
!bt
\[
 \int dxdydz \psi^*(x,y,z) \psi(x,y,z)=1,
\]
!et
and a Hamiltonian
!bt
\[
\hat{H}=-\frac{1}{2}\nabla^2+V(x,y,z).
\]
!et
We will, for the sake of notational convenience,  skip the variables $x,y,z$ below, and write for example $V(x,y,z)=V$.


!split
===== Manipulating terms  =====
 
The integral involving the kinetic energy can be written as, with the function $\psi$ vanishing
strongly for large values of $x,y,z$ (given here by the limits $a$ and $b$), 
!bt
 \[
  \int_a^b dxdydz \psi^* \left(-\frac{1}{2}\nabla^2\right) \psi dxdydz = \psi^*\nabla\psi|_a^b+\int_a^b dxdydz\frac{1}{2}\nabla\psi^*\nabla\psi.
\]
!et
We will drop the limits $a$ and $b$ in the remaining discussion. 
Inserting this expression into the expectation value for the energy and taking the variational minimum  we obtain
!bt
\[
\delta E = \delta \left\{\int dxdydz\left( \frac{1}{2}\nabla\psi^*\nabla\psi+V\psi^*\psi\right)\right\} = 0.
\]
!et


!split
===== Adding the Lagrangian multiplier  =====
 
The constraint appears in integral form as 
!bt
\[
 \int dxdydz \psi^* \psi=\mathrm{constant},
\]
!et
and multiplying with a Lagrangian multiplier $\lambda$ and taking the variational minimum we obtain the final variational equation
!bt
\[
\delta \left\{\int dxdydz\left( \frac{1}{2}\nabla\psi^*\nabla\psi+V\psi^*\psi-\lambda\psi^*\psi\right)\right\} = 0.
\]
!et
We introduce the function  $f$
!bt
\[
  f =  \frac{1}{2}\nabla\psi^*\nabla\psi+V\psi^*\psi-\lambda\psi^*\psi=
\frac{1}{2}(\psi^*_x\psi_x+\psi^*_y\psi_y+\psi^*_z\psi_z)+V\psi^*\psi-\lambda\psi^*\psi,
\]
!et
where we have skipped the dependence on $x,y,z$ and introduced the shorthand $\psi_x$, $\psi_y$ and $\psi_z$  for the various derivatives.


!split
===== And with the Euler-Lagrange equations we get  =====
 
For $\psi^*$ the Euler-Lagrange  equations yield
!bt
\[
\frac{\partial f}{\partial \psi^*}- \frac{\partial }{\partial x}\frac{\partial f}{\partial \psi^*_x}-\frac{\partial }{\partial y}\frac{\partial f}{\partial \psi^*_y}-\frac{\partial }{\partial z}\frac{\partial f}{\partial \psi^*_z}=0,
\] 
!et
which results in 
!bt
\[
    -\frac{1}{2}(\psi_{xx}+\psi_{yy}+\psi_{zz})+V\psi=\lambda \psi.
\]
!et
We can then identify the  Lagrangian multiplier as the energy of the system. The last equation is 
nothing but the standard 
Schroedinger equation and the variational  approach discussed here provides 
a powerful method for obtaining approximate solutions of the wave function.




!split
===== Hartree-Fock by varying the coefficients of a wave function expansion =====

In deriving the Hartree-Fock equations, we  will expand the single-particle functions in a known basis  and vary the coefficients, 
that is, the new single-particle wave function is written as a linear expansion
in terms of a fixed chosen orthogonal basis (for example the well-known harmonic oscillator functions or the hydrogen-like functions etc).
We define our new Hartree-Fock single-particle basis by performing a unitary transformation 
on our previous basis (labelled with greek indices) as
!bt
\begin{equation}
\psi_p^{HF}  = \sum_{\lambda} C_{p\lambda}\phi_{\lambda}. label{eq:newbasis}
\end{equation}
!et
In this case we vary the coefficients $C_{p\lambda}$. If the basis has infinitely many solutions, we need
to truncate the above sum.  We assume that the basis $\phi_{\lambda}$ is orthogonal. A unitary transformation keeps the orthogonality, as discussed in exercise 1 below.  


!split
===== More on linear algebra  =====

In the previous slide we stated that a unitary transformation keeps the orthogonality, as discussed in exercise 1 below.  To see this consider first a basis of vectors $\mathbf{v}_i$,
!bt
\[
\mathbf{v}_i = \begin{bmatrix} v_{i1} \\ \dots \\ \dots \\v_{in} \end{bmatrix}
\]
!et
We assume that the basis is orthogonal, that is 
!bt
\[
\mathbf{v}_j^T\mathbf{v}_i = \delta_{ij}.
\]
!et
An orthogonal or unitary transformation
!bt
\[
\mathbf{w}_i=\mathbf{U}\mathbf{v}_i,
\]
!et
preserves the dot product and orthogonality since
!bt
\[
\mathbf{w}_j^T\mathbf{w}_i=(\mathbf{U}\mathbf{v}_j)^T\mathbf{U}\mathbf{v}_i=\mathbf{v}_j^T\mathbf{U}^T\mathbf{U}\mathbf{v}_i= \mathbf{v}_j^T\mathbf{v}_i = \delta_{ij}.
\]
!et

!split
=====  Coefficients of a wave function expansion =====

This means that if the coefficients $C_{p\lambda}$ belong to a unitary or orthogonal trasformation (using the Dirac bra-ket notation)
!bt
\[
\vert p\rangle  = \sum_{\lambda} C_{p\lambda}\vert\lambda\rangle,
\]
!et
orthogonality is preserved, that is $\langle \alpha \vert \beta\rangle = \delta_{\alpha\beta}$
and $\langle p \vert q\rangle = \delta_{pq}$. 

This propertry is extremely useful when we build up a basis of many-body Stater determinant based states. 

_Note also that although a basis $\vert \alpha\rangle$ contains an infinity of states, for practical calculations we have always to make some truncations._ 




!split
===== More Basic Matrix Features, simple $2 \times 2$ determinant, useful property of determinants  =====

Before we develop the Hartree-Fock equations, there is another very useful property of determinants that we will use both in connection with Hartree-Fock calculations and later shell-model calculations.  

Consider the following determinant
!bt
\[
\left| \begin{array}{cc} \alpha_1b_{11}+\alpha_2sb_{12}& a_{12}\\
                         \alpha_1b_{21}+\alpha_2b_{22}&a_{22}\end{array} \right|=\alpha_1\left|\begin{array}{cc} b_{11}& a_{12}\\
                         b_{21}&a_{22}\end{array} \right|+\alpha_2\left| \begin{array}{cc} b_{12}& a_{12}\\b_{22}&a_{22}\end{array} \right|
\]
!et






!split
===== More Basic Matrix Features, $n \times n$ determinant =====

We can generalize this to  an $n\times n$ matrix and have 
!bt
\[
\left| \begin{array}{cccccc} a_{11}& a_{12} & \dots & \sum_{k=1}^n c_k b_{1k} &\dots & a_{1n}\\
a_{21}& a_{22} & \dots & \sum_{k=1}^n c_k b_{2k} &\dots & a_{2n}\\
\dots & \dots & \dots & \dots & \dots & \dots \\
\dots & \dots & \dots & \dots & \dots & \dots \\
a_{n1}& a_{n2} & \dots & \sum_{k=1}^n c_k b_{nk} &\dots & a_{nn}\end{array} \right|=
\sum_{k=1}^n c_k\left| \begin{array}{cccccc} a_{11}& a_{12} & \dots &  b_{1k} &\dots & a_{1n}\\
a_{21}& a_{22} & \dots &  b_{2k} &\dots & a_{2n}\\
\dots & \dots & \dots & \dots & \dots & \dots\\
\dots & \dots & \dots & \dots & \dots & \dots\\
a_{n1}& a_{n2} & \dots &  b_{nk} &\dots & a_{nn}\end{array} \right| .
\]
!et
This is a property we will use in our Hartree-Fock discussions. 






!split
===== More Basic Matrix Features, a general $n \times n$ determinant =====

We can generalize the previous results, now 
with all elements $a_{ij}$  being given as functions of 
linear combinations  of various coefficients $c$ and elements $b_{ij}$,
!bt
\[
\left| \begin{array}{cccccc} \sum_{k=1}^n b_{1k}c_{k1}& \sum_{k=1}^n b_{1k}c_{k2} & \dots & \sum_{k=1}^n b_{1k}c_{kj}  &\dots & \sum_{k=1}^n b_{1k}c_{kn}\\
\sum_{k=1}^n b_{2k}c_{k1}& \sum_{k=1}^n b_{2k}c_{k2} & \dots & \sum_{k=1}^n b_{2k}c_{kj} &\dots & \sum_{k=1}^n b_{2k}c_{kn}\\
\dots & \dots & \dots & \dots & \dots & \dots \\
\dots & \dots & \dots & \dots & \dots &\dots \\
\sum_{k=1}^n b_{nk}c_{k1}& \sum_{k=1}^n b_{nk}c_{k2} & \dots & \sum_{k=1}^n b_{nk}c_{kj} &\dots & \sum_{k=1}^n b_{nk}c_{kn}\end{array} \right|=det(\mathbf{C})det(\mathbf{B}),
\]
!et
where $det(\mathbf{C})$ and $det(\mathbf{B})$ are the determinants of $n\times n$ matrices
with elements $c_{ij}$ and $b_{ij}$ respectively.  
This is a property we will use in our Hartree-Fock discussions. Convince yourself about the correctness of the above expression by setting $n=2$. 





!split
===== A general Slater determinant =====

With our definition of the new basis in terms of an orthogonal basis we have
!bt
\[
\psi_p(x)  = \sum_{\lambda} C_{p\lambda}\phi_{\lambda}(x).
\]
!et
If the coefficients $C_{p\lambda}$ belong to an orthogonal or unitary matrix, the new basis
is also orthogonal. 
Our Slater determinant in the new basis $\psi_p(x)$ is written as
!bt
\[
\frac{1}{\sqrt{A!}}
\left| \begin{array}{ccccc} \psi_{p}(x_1)& \psi_{p}(x_2)& \dots & \dots & \psi_{p}(x_A)\\
                            \psi_{q}(x_1)&\psi_{q}(x_2)& \dots & \dots & \psi_{q}(x_A)\\  
                            \dots & \dots & \dots & \dots & \dots \\
                            \dots & \dots & \dots & \dots & \dots \\
                     \psi_{t}(x_1)&\psi_{t}(x_2)& \dots & \dots & \psi_{t}(x_A)\end{array} \right|=\frac{1}{\sqrt{A!}}
\left| \begin{array}{ccccc} \sum_{\lambda} C_{p\lambda}\phi_{\lambda}(x_1)& \sum_{\lambda} C_{p\lambda}\phi_{\lambda}(x_2)& \dots & \dots & \sum_{\lambda} C_{p\lambda}\phi_{\lambda}(x_A)\\
                            \sum_{\lambda} C_{q\lambda}\phi_{\lambda}(x_1)&\sum_{\lambda} C_{q\lambda}\phi_{\lambda}(x_2)& \dots & \dots & \sum_{\lambda} C_{q\lambda}\phi_{\lambda}(x_A)\\  
                            \dots & \dots & \dots & \dots & \dots \\
                            \dots & \dots & \dots & \dots & \dots \\
                     \sum_{\lambda} C_{t\lambda}\phi_{\lambda}(x_1)&\sum_{\lambda} C_{t\lambda}\phi_{\lambda}(x_2)& \dots & \dots & \sum_{\lambda} C_{t\lambda}\phi_{\lambda}(x_A)\end{array} \right|,
\]
!et
which is nothing but $det(\mathbf{C})det(\Phi)$, with $det(\Phi)$ being the determinant given by the basis functions $\phi_{\lambda}(x)$. 





!split
===== Hartree-Fock by varying the coefficients of a wave function expansion =====

It is normal to choose a single-particle basis defined as the eigenfunctions
of parts of the full Hamiltonian. The typical situation consists of the solutions of the one-body part of the Hamiltonian, that is we have
!bt
\[
\hat{h}_0\phi_{\lambda}=\epsilon_{\lambda}\phi_{\lambda}.
\]
!et 
The single-particle wave functions $\phi_{\lambda}(\bm{r})$, defined by the quantum numbers $\lambda$ and $\bm{r}$
are defined as the overlap 
!bt
\[
   \phi_{\lambda}(\bm{r})  = \langle \bm{r} | \lambda \rangle .
\]
!et


!split
===== Hartree-Fock by varying the coefficients of a wave function expansion =====

In our discussions hereafter we will use our definitions of single-particle states above and below the Fermi ($F$) level given by the labels
$ijkl\dots \le F$ for so-called single-hole states and $abcd\dots > F$ for so-called particle states.
For general single-particle states we employ the labels $pqrs\dots$. 



!split
===== Hartree-Fock by varying the coefficients of a wave function expansion =====

In Eq.~(ref{FunctionalEPhi}), restated here
!bt
\[
  E[\Phi] 
  = \sum_{\mu=1}^A \langle \mu | h | \mu \rangle +
  \frac{1}{2}\sum_{{\mu}=1}^A\sum_{{\nu}=1}^A \langle \mu\nu|\hat{v}|\mu\nu\rangle_{AS},
\]
!et 
we found the expression for the energy functional in terms of the basis function $\phi_{\lambda}(\bm{r})$. We then  varied the above energy functional with respect to the basis functions $|\mu \rangle$. 
Now we are interested in defining a new basis defined in terms of
a chosen basis as defined in Eq.~(ref{eq:newbasis}). We can then rewrite the energy functional as
!bt
\begin{equation}
  E[\Phi^{HF}] 
  = \sum_{i=1}^A \langle i | h | i \rangle +
  \frac{1}{2}\sum_{ij=1}^A\langle ij|\hat{v}|ij\rangle_{AS}, label{FunctionalEPhi2}
\end{equation}
!et
where $\Phi^{HF}$ is the new Slater determinant defined by the new basis of Eq.~(ref{eq:newbasis}). 


!split
===== Hartree-Fock by varying the coefficients of a wave function expansion =====

Using Eq.~(ref{eq:newbasis}) we can rewrite Eq.~(ref{FunctionalEPhi2}) as 
!bt
\begin{equation}
  E[\Psi] 
  = \sum_{i=1}^A \sum_{\alpha\beta} C^*_{i\alpha}C_{i\beta}\langle \alpha | h | \beta \rangle +
  \frac{1}{2}\sum_{ij=1}^A\sum_{{\alpha\beta\gamma\delta}} C^*_{i\alpha}C^*_{j\beta}C_{i\gamma}C_{j\delta}\langle \alpha\beta|\hat{v}|\gamma\delta\rangle_{AS}. label{FunctionalEPhi3}
\end{equation}
!et


!split
===== Hartree-Fock by varying the coefficients of a wave function expansion =====

We wish now to minimize the above functional. We introduce again a set of Lagrange multipliers, noting that
since $\langle i | j \rangle = \delta_{i,j}$ and $\langle \alpha | \beta \rangle = \delta_{\alpha,\beta}$, 
the coefficients $C_{i\gamma}$ obey the relation
!bt
\[
 \langle i | j \rangle=\delta_{i,j}=\sum_{\alpha\beta} C^*_{i\alpha}C_{i\beta}\langle \alpha | \beta \rangle=
\sum_{\alpha} C^*_{i\alpha}C_{i\alpha},
\]
!et
which allows us to define a functional to be minimized that reads
!bt
\begin{equation}
  F[\Phi^{HF}]=E[\Phi^{HF}] - \sum_{i=1}^A\epsilon_i\sum_{\alpha} C^*_{i\alpha}C_{i\alpha}.
\end{equation}
!et




!split
===== Hartree-Fock by varying the coefficients of a wave function expansion =====

Minimizing with respect to $C^*_{i\alpha}$, remembering that the equations for $C^*_{i\alpha}$ and $C_{i\alpha}$
can be written as two  independent equations, we obtain
!bt
\[
\frac{d}{dC^*_{i\alpha}}\left[  E[\Phi^{HF}] - \sum_{j}\epsilon_j\sum_{\alpha} C^*_{j\alpha}C_{j\alpha}\right]=0,
\]
!et
which yields for every single-particle state $i$ and index $\alpha$ (recalling that the coefficients $C_{i\alpha}$ are matrix elements of a unitary (or orthogonal for a real symmetric matrix) matrix)
the following Hartree-Fock equations
!bt
\[
\sum_{\beta} C_{i\beta}\langle \alpha | h | \beta \rangle+
\sum_{j=1}^A\sum_{\beta\gamma\delta} C^*_{j\beta}C_{j\delta}C_{i\gamma}\langle \alpha\beta|\hat{v}|\gamma\delta\rangle_{AS}=\epsilon_i^{HF}C_{i\alpha}.
\]
!et


!split
===== Hartree-Fock by varying the coefficients of a wave function expansion =====

We can rewrite this equation as (changing dummy variables)
!bt
\[
\sum_{\beta} \left\{\langle \alpha | h | \beta \rangle+
\sum_{j}^A\sum_{\gamma\delta} C^*_{j\gamma}C_{j\delta}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}\right\}C_{i\beta}=\epsilon_i^{HF}C_{i\alpha}.
\]
!et
Note that the sums over greek indices run over the number of basis set functions (in principle an infinite number).


!split
===== Hartree-Fock by varying the coefficients of a wave function expansion =====

Defining 
!bt
\[
h_{\alpha\beta}^{HF}=\langle \alpha | h | \beta \rangle+
\sum_{j=1}^A\sum_{\gamma\delta} C^*_{j\gamma}C_{j\delta}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS},
\]
!et
we can rewrite the new equations as 
!bt
\begin{equation}
\sum_{\gamma}h_{\alpha\beta}^{HF}C_{i\beta}=\epsilon_i^{HF}C_{i\alpha}. label{eq:newhf}
\end{equation}
!et
The latter is nothing but a standard eigenvalue problem. 

It suffices to tabulate the matrix elements $\langle \alpha | h | \beta \rangle$ and $\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}$ once and for all. Successive iterations require thus only a look-up in tables over one-body and two-body matrix elements. These details will be discussed below when we solve the Hartree-Fock equations numerically. 


!split
===== Hartree-Fock algorithm =====

Our Hartree-Fock matrix  is thus
!bt
\[
\hat{h}_{\alpha\beta}^{HF}=\langle \alpha | \hat{h}_0 | \beta \rangle+
\sum_{j=1}^A\sum_{\gamma\delta} C^*_{j\gamma}C_{j\delta}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}.
\]
!et
The Hartree-Fock equations are solved in an iterative waym starting with a guess for the coefficients $C_{j\gamma}=\delta_{j,\gamma}$ and solving the equations by diagonalization till the new single-particle energies
$\epsilon_i^{\mathrm{HF}}$ do not change anymore by a prefixed quantity. 


!split
===== Hartree-Fock algorithm =====

Normally we assume that the single-particle basis $|\beta\rangle$ forms an eigenbasis for the operator
$\hat{h}_0$, meaning that the Hartree-Fock matrix becomes  
!bt
\[
\hat{h}_{\alpha\beta}^{HF}=\epsilon_{\alpha}\delta_{\alpha,\beta}+
\sum_{j=1}^A\sum_{\gamma\delta} C^*_{j\gamma}C_{j\delta}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}.
\]
!et
The Hartree-Fock eigenvalue problem
!bt
\[
\sum_{\beta}\hat{h}_{\alpha\beta}^{HF}C_{i\beta}=\epsilon_i^{\mathrm{HF}}C_{i\alpha},
\]
!et
can be written out in a more compact form as
!bt
\[
\hat{h}^{HF}\hat{C}=\epsilon^{\mathrm{HF}}\hat{C}. 
\]
!et


!split
===== Hartree-Fock algorithm =====

The Hartree-Fock equations are, in their simplest form, solved in an iterative way, starting with a guess for the
coefficients $C_{i\alpha}$. We label the coefficients as $C_{i\alpha}^{(n)}$, where the subscript $n$ stands for iteration $n$.
To set up the algorithm we can proceed as follows:

 * We start with a guess $C_{i\alpha}^{(0)}=\delta_{i,\alpha}$. Alternatively, we could have used random starting values as long as the vectors are normalized. Another possibility is to give states below the Fermi level a larger weight.
 * The Hartree-Fock matrix simplifies then to (assuming that the coefficients $C_{i\alpha} $  are real)
!bt
\[
\hat{h}_{\alpha\beta}^{HF}=\epsilon_{\alpha}\delta_{\alpha,\beta}+
\sum_{j = 1}^A\sum_{\gamma\delta} C_{j\gamma}^{(0)}C_{j\delta}^{(0)}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}.
\]
!et


!split
===== Hartree-Fock algorithm =====

Solving the Hartree-Fock eigenvalue problem yields then new eigenvectors $C_{i\alpha}^{(1)}$ and eigenvalues
$\epsilon_i^{HF(1)}$. 
 * With the new eigenvalues we can set up a new Hartree-Fock potential 
!bt
\[
\sum_{j = 1}^A\sum_{\gamma\delta} C_{j\gamma}^{(1)}C_{j\delta}^{(1)}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}.
\]
!et
The diagonalization with the new Hartree-Fock potential yields new eigenvectors and eigenvalues.
This process is continued till for example
!bt
\[
\frac{\sum_{p} |\epsilon_i^{(n)}-\epsilon_i^{(n-1)}|}{m} \le \lambda,  
\]
!et
where $\lambda$ is a user prefixed quantity ($\lambda \sim 10^{-8}$ or smaller) and $p$ runs over all calculated single-particle
energies and $m$ is the number of single-particle states.


!split
===== Analysis of Hartree-Fock equations and Koopman's theorem =====

We can rewrite the ground state energy by adding and subtracting $\hat{u}^{HF}(x_i)$ 
!bt
\[
  E_0^{HF} =\langle \Phi_0 | \hat{H} | \Phi_0\rangle = 
\sum_{i\le F}^A \langle i | \hat{h}_0 +\hat{u}^{HF}| j\rangle+ \frac{1}{2}\sum_{i\le F}^A\sum_{j \le F}^A\left[\langle ij |\hat{v}|ij \rangle-\langle ij|\hat{v}|ji\rangle\right]-\sum_{i\le F}^A \langle i |\hat{u}^{HF}| i\rangle,
\]
!et
which results in
!bt
\[
  E_0^{HF}
  = \sum_{i\le F}^A \varepsilon_i^{HF} + \frac{1}{2}\sum_{i\le F}^A\sum_{j \le F}^A\left[\langle ij |\hat{v}|ij \rangle-\langle ij|\hat{v}|ji\rangle\right]-\sum_{i\le F}^A \langle i |\hat{u}^{HF}| i\rangle.
\]
!et
Our single-particle states $ijk\dots$ are now single-particle states obtained from the solution of the Hartree-Fock equations.


!split
===== Analysis of Hartree-Fock equations and Koopman's theorem =====

Using our definition of the Hartree-Fock single-particle energies we obtain then the following expression for the total ground-state energy
!bt
\[
  E_0^{HF}
  = \sum_{i\le F}^A \varepsilon_i - \frac{1}{2}\sum_{i\le F}^A\sum_{j \le F}^A\left[\langle ij |\hat{v}|ij \rangle-\langle ij|\hat{v}|ji\rangle\right].
\]
!et
This form will be used in our discussion of Koopman's theorem.


!split
===== Analysis of Hartree-Fock equations and Koopman's theorem =====
  Atomic physics case
We have 
!bt
\[
  E[\Phi^{\mathrm{HF}}(N)] 
  = \sum_{i=1}^H \langle i | \hat{h}_0 | i \rangle +
  \frac{1}{2}\sum_{ij=1}^N\langle ij|\hat{v}|ij\rangle_{AS},
\]
!et
where $\Phi^{\mathrm{HF}}(N)$ is the new Slater determinant defined by the new basis of Eq.~(ref{eq:newbasis})
for $N$ electrons (same $Z$).  If we assume that the single-particle wave functions in the new basis do not change 
when we remove one electron or add one electron, we can then define the corresponding energy for the $N-1$ systems as 
!bt
\[
  E[\Phi^{\mathrm{HF}}(N-1)] 
  = \sum_{i=1; i\ne k}^N \langle i | \hat{h}_0 | i \rangle +
  \frac{1}{2}\sum_{ij=1;i,j\ne k}^N\langle ij|\hat{v}|ij\rangle_{AS},
\]
!et
where we have removed a single-particle state $k\le F$, that is a state below the Fermi level.  


!split
===== Analysis of Hartree-Fock equations and Koopman's theorem =====

Calculating the difference 
!bt
\[
  E[\Phi^{\mathrm{HF}}(N)]-   E[\Phi^{\mathrm{HF}}(N-1)] = \langle k | \hat{h}_0 | k \rangle +
  \frac{1}{2}\sum_{i=1;i\ne k}^N\langle ik|\hat{v}|ik\rangle_{AS}  \frac{1}{2}\sum_{j=1;j\ne k}^N\langle kj|\hat{v}|kj\rangle_{AS},
\]
!et
we obtain
!bt
\[
  E[\Phi^{\mathrm{HF}}(N)]-   E[\Phi^{\mathrm{HF}}(N-1)] = \langle k | \hat{h}_0 | k \rangle +
  \frac{1}{2}\sum_{j=1}^N\langle kj|\hat{v}|kj\rangle_{AS}
\]
!et
which is just our definition of the Hartree-Fock single-particle energy
!bt
\[
  E[\Phi^{\mathrm{HF}}(N)]-   E[\Phi^{\mathrm{HF}}(N-1)] = \epsilon_k^{\mathrm{HF}} 
\]
!et


!split
===== Analysis of Hartree-Fock equations and Koopman's theorem =====

Similarly, we can now compute the difference (we label the single-particle states above the Fermi level as $abcd > F$)
!bt
\[
  E[\Phi^{\mathrm{HF}}(N+1)]-   E[\Phi^{\mathrm{HF}}(N)]= \epsilon_a^{\mathrm{HF}}. 
\]
!et
These two equations can thus be used to the electron affinity or ionization energies, respectively. 
Koopman's theorem states that for example the ionization energy of a closed-shell system is given by the energy of the highest occupied single-particle state.  If we assume that changing the number of electrons from $N$ to $N+1$ does not change the Hartree-Fock single-particle energies and eigenfunctions, then Koopman's theorem simply states that the ionization energy of an atom is given by the single-particle energy of the last bound state. In a similar way, we can also define the electron affinities. 


!split
===== Analysis of Hartree-Fock equations and Koopman's theorem =====

As an example, consider a simple model for atomic sodium, Na. Neutral sodium has eleven electrons, 
with the weakest bound one being confined the $3s$ single-particle quantum numbers. The energy needed to remove an electron from neutral sodium is rather small, 5.1391 eV, a feature which pertains to all alkali metals.
Having performed a  Hartree-Fock calculation for neutral sodium would then allows us to compute the
ionization energy by using the single-particle energy for the $3s$ states, namely $\epsilon_{3s}^{\mathrm{HF}}$. 

From these considerations, we see that Hartree-Fock theory allows us to make a connection between experimental 
observables (here ionization and affinity energies) and the underlying interactions between particles.  
In this sense, we are now linking the dynamics and structure of a many-body system with the laws of motion which govern the system. Our approach is a reductionistic one, meaning that we want to understand the laws of motion 
in terms of the particles or degrees of freedom which we believe are the fundamental ones. Our Slater determinant, being constructed as the product of various single-particle functions, follows this philosophy.





!split
===== Developing a  Hartree-Fock program  =====


The Hamiltonian for a system of $N$ electrons confined in a
harmonic potential reads
!bt
\[
\hat{H} = \sum_{i=1}^{N} \frac{\hat{p}_{i}^{2}}{2m}+\sum_{i=1}^{N} \frac{1}{2} m\omega {r}_{i}^{2}+\sum_{i<j} \hat{V}_{ij},
\]
!et
with  $\hat{V}_{ij}$ is the two-body potential whose 
matrix elements are calculated on fly in your program. See expression below.

The Hartree-Fock algorithm can be broken down as follows. We recall that  our Hartree-Fock matrix  is 
!bt
\[
\hat{h}_{\alpha\beta}^{HF}=\langle \alpha \vert\hat{h}_0 \vert \beta \rangle+
\sum_{j=1}^N\sum_{\gamma\delta} C^*_{j\gamma}C_{j\delta}\langle \alpha\gamma|V|\beta\delta\rangle_{AS}.
\]
!et
Normally we assume that the single-particle basis $\vert\beta\rangle$
forms an eigenbasis for the operator $\hat{h}_0$ (this is our case), meaning that the
Hartree-Fock matrix becomes
!bt
\[
\hat{h}_{\alpha\beta}^{HF}=\epsilon_{\alpha}\delta_{\alpha,\beta}+
\sum_{j=1}^N\sum_{\gamma\delta} C^*_{j\gamma}C_{j\delta}\langle \alpha\gamma|V|\beta\delta\rangle_{AS}.
\]
!et
The Hartree-Fock eigenvalue problem
!bt
\[
\sum_{\beta}\hat{h}_{\alpha\beta}^{HF}C_{i\beta}=\epsilon_i^{\mathrm{HF}}C_{i\alpha},
\]
!et
can be written out in a more compact form as
!bt
\[
\hat{h}^{HF}\hat{C}=\epsilon^{\mathrm{HF}}\hat{C}. 
\]
!et


The equations are often rewritten in terms of a so-called density matrix,
which is defined as 
!bt
\begin{equation}
\rho_{\gamma\delta}=\sum_{i=1}^{N}\langle\gamma|i\rangle\langle i|\delta\rangle = \sum_{i=1}^{N}C_{i\gamma}C^*_{i\delta}.
\end{equation}
!et
It means that we can rewrite the Hartree-Fock Hamiltonian as
!bt
\[
\hat{h}_{\alpha\beta}^{HF}=\epsilon_{\alpha}\delta_{\alpha,\beta}+
\sum_{\gamma\delta} \rho_{\gamma\delta}\langle \alpha\gamma|V|\beta\delta\rangle_{AS}.
\]
!et
It is convenient to use the density matrix since we can precalculate in every iteration the product of two eigenvector components $C$. 


!split
===== "Program for computing the Coulomb interaction in polar coordinates":"https://github.com/CompPhysics/ComputationalPhysics2/tree/gh-pages/doc/Programs/HFcode/python/hf.py" =====

Here we show a simple code in python for a Hartree-Fock calculation using precalculated matrix elements.
!bc pycod
import numpy as np 
from decimal import Decimal
# expectation value for the one body part, Harmonic oscillator in three dimensions
def onebody(i, n, l):
	homega = 10.0
	return homega*(2*n[i] + l[i] + 1.5)

if __name__ == '__main__':
	
        Nparticles = 16
	""" Read quantum numbers from file """
        index = []
	n = []
        l = []
        j = []	
        mj = []
        tz = []
	spOrbitals = 0
	with open("nucleispnumbers.dat", "r") as qnumfile:
		for line in qnumfile:
			nums = line.split()
			if len(nums) != 0:
				index.append(int(nums[0]))
				n.append(int(nums[1]))
				l.append(int(nums[2]))
				j.append(int(nums[3]))
				mj.append(int(nums[4]))
				tz.append(int(nums[5]))
				spOrbitals += 1


	""" Read two-nucleon interaction elements (integrals) from file, brute force 4-dim array """
	nninteraction = np.zeros([spOrbitals, spOrbitals, spOrbitals, spOrbitals])
	with open("nucleitwobody.dat", "r") as infile:
		for line in infile:
			number = line.split()
			a = int(number[0]) - 1
			b = int(number[1]) - 1
			c = int(number[2]) - 1
			d = int(number[3]) - 1
			#print a, b, c, d, float(l[4])
			nninteraction[a][b][c][d] = Decimal(number[4])
	""" Set up single-particle integral """
	singleparticleH = np.zeros(spOrbitals)
	for i in range(spOrbitals):
		singleparticleH[i] = Decimal(onebody(i, n, l))
	
	""" Star HF-iterations, preparing variables and density matrix """

        """ Coefficients for setting up density matrix, assuming only one along the diagonals """
	C = np.eye(spOrbitals) # HF coefficients
        DensityMatrix = np.zeros([spOrbitals,spOrbitals])
        for gamma in range(spOrbitals):
            for delta in range(spOrbitals):
                sum = 0.0
                for i in range(Nparticles):
                    sum += C[gamma][i]*C[delta][i]
                DensityMatrix[gamma][delta] = Decimal(sum)
        maxHFiter = 100
        epsilon =  1.0e-5 
        difference = 1.0
	hf_count = 0
	oldenergies = np.zeros(spOrbitals)
	newenergies = np.zeros(spOrbitals)
	while hf_count < maxHFiter and difference > epsilon:
		print "############### Iteration %i ###############" % hf_count
   	        HFmatrix = np.zeros([spOrbitals,spOrbitals])		
		for alpha in range(spOrbitals):
			for beta in range(spOrbitals):
                            """  If tests for three-dimensional systems, including isospin conservation """
                            if l[alpha] != l[beta] and j[alpha] != j[beta] and mj[alpha] != mj[beta] and tz[alpha] != tz[beta]: continue
                            """  Setting up the Fock matrix using the density matrix and antisymmetrized NN interaction in m-scheme """
     		            sumFockTerm = 0.0
                            for gamma in range(spOrbitals):
                                for delta in range(spOrbitals):
                                    if (mj[alpha]+mj[gamma]) != (mj[beta]+mj[delta]) and (tz[alpha]+tz[gamma]) != (tz[beta]+tz[delta]): continue
                                    sumFockTerm += DensityMatrix[gamma][delta]*nninteraction[alpha][gamma][beta][delta]
                            HFmatrix[alpha][beta] = Decimal(sumFockTerm)
                            """  Adding the one-body term, here plain harmonic oscillator """
                            if beta == alpha:   HFmatrix[alpha][alpha] += singleparticleH[alpha]
		spenergies, C = np.linalg.eigh(HFmatrix)
                """ Setting up new density matrix in m-scheme """
                DensityMatrix = np.zeros([spOrbitals,spOrbitals])
                for gamma in range(spOrbitals):
                    for delta in range(spOrbitals):
                        sum = 0.0
                        for i in range(Nparticles):
                            sum += C[gamma][i]*C[delta][i]
                        DensityMatrix[gamma][delta] = Decimal(sum)
		newenergies = spenergies
                """ Brute force computation of difference between previous and new sp HF energies """
                sum =0.0
                for i in range(spOrbitals):
                    sum += (abs(newenergies[i]-oldenergies[i]))/spOrbitals
                difference = sum
                oldenergies = newenergies
                print "Single-particle energies, ordering may have changed "
                for i in range(spOrbitals):
                    print('{0:4d}  {1:.4f}'.format(i, Decimal(oldenergies[i])))
		hf_count += 1

!ec


!split 
===== Practicalities with the Hartree-Fock code development, basis construction =====
When  setting up the Hartree-Fock algorithm you will find it convenient to number the basis states
by filling the lowest subshells. For the first two shells we could then have the following mapping.
!bt
\begin{align*}
  \vert 0\rangle & = \{n=0, m=0, m_s = -0.5\} \\ 
  \vert 1\rangle & = \{n=0, m=0, m_s = 0.5\} \\
  \vert 2\rangle & = \{n=0, m=-1, m_s = -0.5\} \\
  \vert 3\rangle & = \{n=0, m=-1, m_s = 0.5\} \\
  \vert 4\rangle & = \{n=0, m=+1, m_s = -0.5\} \\
  \vert 5\rangle & = \{n=0, m=+1, m_s = 0.5\}   
\end{align*}
!et

!split 
===== Practicalities with the Hartree-Fock code development, two-body basis construction, brute force =====
In the setup of the two-body matrix elements we can typically opt between two alternatives. We can read the matrix elements from file or calculate the matrix elements on the fly. The latter requires simply that we 
call the abovementioned function for setting up the two-body matrix elements when we run our Hartree-Fock code. 

If we however wish to read from file, we can store the matrix elements in two ways:
* Brute force
* Organize according to conserved two-body quantum numbers

The brute force way is easy to implement. 

!split 
===== Two-body interaction, brute force part I =====
We can read in from file the two-body interaction matrix elements or compute once and for all and store in
memory.
The elements are
!bt
\[
\langle pr | \hat{v}|qs\rangle.
\]
!et

The time-consuming part in the Hartree-Fock calculations
involves the calculation of the two-body matrix. Furthermore, the
storage of these matrix elements plays also an important role, in
particular we wish to access the table of matrix elements as fast as
possible.  

!split 
===== Two-body interaction, brute force part II =====
In a brute force algorithm for storing the matrix elements, if we have $d$ basis functions, we end up with the need of storing 
$d^4$ matrix elements. We can reduce this considerably by the following considerations.
In the calculation of the two-body matrix elements $\langle pr | \hat{v}|qs\rangle$ we have the following symmetries

o  Invariance under permutations, that is
!bt
\[
\langle pq | \hat{v}|rs\rangle = \langle qp | \hat{v}|sr\rangle.
\]
!et
o  The functions entering the evaluation of the integrals are all real, meaning that if we interchange $p\leftrightarrow q$ or  $r\leftrightarrow s$, we end up with the same matrix element.

This reduces by a factor of eight the total number of matrix elements to be stored if we also use that 
we can store only for $p < q$ and $ r < s$. 


!split 
===== Two-body interaction, brute force part III =====

Furthermore, in setting up a table for the two-body matrix elements we can convert the need of using four indices $pqrs$ of 
!bt
\[
\langle pr | \hat{v}|qs\rangle,
\]
!et
 which in a brute forces way could be coded as a four-dimensional array, to 
a two-dimensional array $V_{lm}$, where $l$ and $m$ stand for all possible two-body configurations $pq$.
 
Each number $l$ and $m$ in $V_{lm}$  should then point to a set of single-particle  states $(p,q)$ and $(r,s)$.  

In our case, since we have 
symmetries which allow us to set $p\le q$, we have, with $d$ single particle states a total of $d(d+1)/2$ two-body configurations.

!split 
===== Two-body interaction, brute force part IV =====

How do we store such a matrix? The simplest thing to do is to convert it into a one-dimensional array. How do we achieve that? 

We now have a matrix $V$ of dimension $n\times n$ and we want to store the elements $V_{lm}$ as a one-dimensional array $A$ using
$0 \le l \le m \le n-1$. For
o $l=0$ we have $n$ elements
o $l=1$ we have $n-1$ elements
o $\dots$
o $l=\nu$ we have $n-\nu$ elements
o $\dots$
o $l=n-1$ we have $1$ element,
and the total number is  
!bt
\[
\sum_{\nu =0}^{n-1}\left(n-\nu\right)=\frac{n(n+1)}{2}.
\] 
!et


!split 
===== Two-body interaction, brute force part V =====

To find the number ($\mathrm{number}(l,m)$) in a one-dimensional array $A$ which corresponds to a matrix element $V_{lm}$, we note that
!bt
\[
\mathrm{number}(l,m)=\sum_{\nu =0}^{l-1}\left(n-\nu\right)+m-l=\frac{l(2n-l-1)}{2}+m.
\] 
!et
The first matrix element $V(0,0)$ is obviously given by the element $A(0)$. 

We have thus reduced a four dimensional array to a one-dimensional array, where the given pairs $(p,q)$ and $(r,s)$ point to the matrix indices $l$
and $m$, respectively. The latter are used to find the explicit number $\mathrm{number}(l,m)$ which points to the desired matrix element stored 
in a one-dimensional array.


!split 
===== Practicalities with the Hartree-Fock code development, two-body basis construction =====

Another way to store the matrix elements is to organize the matrix elements according to conserved quantum numbers.
This means setting up a block structure and to look up matrix elements using two-body conserved quantum numbers.
For quantum dots, the two-body quantum numbers that are conserved are
The total orbital momentum projection
!bt
\[
M = m_1 + m_2,
\]
!et
and the total spin projection
!bt
\[
M_s = m_{s_1} + m_{s_2}
\]
!et

!split 
===== Two-body basis construction =====

For 2 shells we have

|-------------------------------------|
|$M$ | $M_s$ | $\alpha$ | State|
|-------------------------------------|
| -2 |  0 |  1  |$\vert 3,2\rangle$ |
| -1 | -1  | 3  |$\vert 2,0\rangle$ |
| -1 |  0 |  4  |$\vert 3,0\rangle$ |
| -1 |  0  | 4  |$\vert 2,1\rangle$ |
| -1 |  1 |  5  |$\vert 3,1\rangle$ |
|  0 | -1 |  6  |$\vert 4,2\rangle$ |
|  0 |  0 |  7  |$\vert 1,0\rangle$ |
|  0 |  0 | 7   |$\vert 5,2\rangle$ |
|  0 |  0 | 7   |$\vert 4,3\rangle$|
|  0 |  1 |  8  |$\vert 5,3\rangle$|
|  1 | -1 |  9  |$\vert 4,0\rangle$ |
|  1 |  0 | 10  |$\vert 5,0\rangle$|
|  1 |  0 | 10  |$\vert 4,1\rangle$|
|  1 |  1 |  11 |$\vert 5,1\rangle$ |
|  2 |  0 | 13  |$\vert 5,4\rangle$ |
|-------------------------------------|

In this table we have paired orbitals with same $M$ and $M_s$. Where $\alpha \in \{0,...,N\}$ and $N$ is the number of pairs $\{M,M_s\}$. Notice that for $\alpha = 1$ we only have one pair, and for $\alpha = 4$, we have two pairs.



!split 
===== Hartree-Fock code =====
In developing our Hartree-Fock code, we can define a configuration class with the following mapping for a single-particle state
!bt
\[
  \vert \alpha\rangle \rightarrow \vert n m m_s\rangle,
\]
!et
and a similar mapping for a two-body state
!bt
\[
  \vert \alpha \beta\rangle \rightarrow \vert M M_s\rangle,
\]
!et
where $M$ is the total angualar momentum 
!bt
\[
M = m_\alpha + m_\beta,
\]
!et
and the $M_s$ is the total spin
!bt
\[
M_s = m_{s_1} + m_{s_2}.
\]
!et



!split 
===== Hartree-Fock code, setting up tables of matrix elements  =====
The single-particle part is diagonal for the harmonic oscillator basis, that is
!bt
\[
\langle \alpha\vert \hat{h}_0\vert \beta\rangle = \delta_{\alpha \beta} \epsilon_\alpha
\]
!et
with 
!bt
\[
\epsilon_\alpha  = \hbar\omega (2n_{\alpha}+\vert m_{\alpha}\vert +1).
\]
!et
The two-body matrix elements are diagonal in the $M$ and $M_s$, that is
!bt
\[
  \langle M M_s\vert \hat{v}\vert M' M_s'\rangle = \delta_{M,M'}\delta_{M_s,M_s'}\langle MM_s\vert \hat{v}\vert MM_s\rangle.
\]
!et


!split 
===== Example calculations, $N=6$ and $\omega =1.0$ a.u.  =====

We list here some selected Hartree-Fock results for $N=6$ electrons as function of the number of major shells $R$
included. Here we have $\omega =1$ a.u.

|--------------------------------------------------|
|    $R$      |   $E_0^{HF}$                       |
|--------------------------------------------------|
|3 | 21.59320 |
|4 | 20.76692 |
|5 | 20.7484 |
|6 | 20.72026 |
|7 | 20.72013 |
|8 | 20.71925 |
|9 | 20.71925 |
|10 | 20.71922 |
|11 | 20.71922 |
|12 |20.71922 |
| 13 | 20.71922 |
|--------------------------------------------------|

The results are practically converged for approximately $R=10-13$. 



!split 
===== Example calculations, $N=6$ and $\omega =0.1$ a.u.  =====

We list here some selected Hartree-Fock results for $N=6$ electrons as function of the number of major shells $R$
included. Here we have $\omega =0.1$ a.u.

|--------------------------------------------------|
|    $R$      |   $E_0^{HF}$                       |
|--------------------------------------------------|
|4 | 4.01979   |
| 5 | 3.96315  |
| 6 | 3.87062  |
| 7 | 3.86314  |
| 8 | 3.85288  |
| 9 | 3.85259  |
| 10 | 3.85239 |
| 11 | 3.85239 |
| 12 | 3.85238 |
| 13 | 3.85238 |
|--------------------------------------------------|

Again, the results are practically converged for approximately $R=10-13$. 
