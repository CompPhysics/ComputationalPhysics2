<!DOCTYPE html>

<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/hplgit/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Week 3 January 18-22: Building a Variational Monte Carlo program">

<title>Week 3 January 18-22: Building a Variational Monte Carlo program</title>







<!-- reveal.js: http://lab.hakim.se/reveal-js/ -->

<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

<link rel="stylesheet" href="reveal.js/css/reveal.css">
<link rel="stylesheet" href="reveal.js/css/theme/beige.css" id="theme">
<!--
<link rel="stylesheet" href="reveal.js/css/reveal.css">
<link rel="stylesheet" href="reveal.js/css/theme/beige.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/beigesmall.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/solarized.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/serif.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/night.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/moon.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/simple.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/sky.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/darkgray.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/default.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/cbc.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/simula.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/white.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/league.css" id="theme">
-->

<!-- For syntax highlighting -->
<link rel="stylesheet" href="reveal.js/lib/css/zenburn.css">

<!-- Printing and PDF exports -->
<script>
var link = document.createElement( 'link' );
link.rel = 'stylesheet';
link.type = 'text/css';
link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
document.getElementsByTagName( 'head' )[0].appendChild( link );
</script>

<style type="text/css">
    hr { border: 0; width: 80%; border-bottom: 1px solid #aaa}
    p.caption { width: 80%; font-size: 60%; font-style: italic; text-align: left; }
    hr.figure { border: 0; width: 80%; border-bottom: 1px solid #aaa}
    .reveal .alert-text-small   { font-size: 80%;  }
    .reveal .alert-text-large   { font-size: 130%; }
    .reveal .alert-text-normal  { font-size: 90%;  }
    .reveal .alert {
             padding:8px 35px 8px 14px; margin-bottom:18px;
             text-shadow:0 1px 0 rgba(255,255,255,0.5);
             border:5px solid #bababa;
             -webkit-border-radius: 14px; -moz-border-radius: 14px;
             border-radius:14px;
             background-position: 10px 10px;
             background-repeat: no-repeat;
             background-size: 38px;
             padding-left: 30px; /* 55px; if icon */
     }
     .reveal .alert-block {padding-top:14px; padding-bottom:14px}
     .reveal .alert-block > p, .alert-block > ul {margin-bottom:1em}
     /*.reveal .alert li {margin-top: 1em}*/
     .reveal .alert-block p+p {margin-top:5px}
     /*.reveal .alert-notice { background-image: url(http://hplgit.github.io/doconce/bundled/html_images/small_gray_notice.png); }
     .reveal .alert-summary  { background-image:url(http://hplgit.github.io/doconce/bundled/html_images/small_gray_summary.png); }
     .reveal .alert-warning { background-image: url(http://hplgit.github.io/doconce/bundled/html_images/small_gray_warning.png); }
     .reveal .alert-question {background-image:url(http://hplgit.github.io/doconce/bundled/html_images/small_gray_question.png); } */

</style>



<!-- Styles for table layout of slides -->
<style type="text/css">
td.padding {
  padding-top:20px;
  padding-bottom:20px;
  padding-right:50px;
  padding-left:50px;
}
</style>

</head>

<body>
<div class="reveal">

<!-- Any section element inside the <div class="slides"> container
     is displayed as a slide -->

<div class="slides">





<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



    



<section>
<!-- ------------------- main content ---------------------- -->



<center><h1 style="text-align: center;">Week 3 January 18-22: Building a Variational Monte Carlo program </h1></center>  <!-- document title -->

<p>
<!-- author(s): Morten Hjorth-Jensen  Email morten.hjorth-jensen@fys.uio.no -->

<center>
<b>Morten Hjorth-Jensen  Email morten.hjorth-jensen@fys.uio.no</b> [1, 2]
</center>

<p>&nbsp;<br>
<!-- institution(s) -->

<center>[1] <b>Department of Physics and Center fo Computing in Science Education, University of Oslo, Oslo, Norway</b></center>
<center>[2] <b>Department of Physics and Astronomy and Facility for Rare Ion Beams, Michigan State University, East Lansing, Michigan, USA</b></center>
<br>
<p>&nbsp;<br>
<center><h4>Dec 14, 2020</h4></center> <!-- date -->
<br>
<p>

<center style="font-size:80%">
<!-- copyright --> &copy; 1999-2020, Morten Hjorth-Jensen  Email morten.hjorth-jensen@fys.uio.no. Released under CC Attribution-NonCommercial 4.0 license
</center>
</section>


<section>
<h2 id="___sec0">Overview of week 3 </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b>Topics.</b>
<ul>
<p><li> Variational Monte Carlo methods, Metropolis Algorithm, statistics and Markov Chain theory</li>
<p><li> How to structure the VMC code</li>
</ul>
</div>

<p>
<div class="alert alert-block alert-block alert-text-normal">
<b>Teaching Material, videos and written material.</b>
<ul>
<p><li> Overview video</li>
<p><li> Lecture notes and reading assignments</li>
<p><li> Recommended background literature</li>
</ul>
</div>

<h2 id="___sec1">Introduction </h2>

<h3 id="___sec2">Structure and Aims </h3>

<p>
These notebooks serve the aim of linking traditional variational Monte
Carlo VMC calculations methods with recent progress on solving
many-particle problems using Machine Learning algorithms.

<p>
Furthermore, when linking with Machine Learning algorithms, in particular
so-called Boltzmann Machines, there are interesting connections between
these algorithms and so-called <a href="https://journals.aps.org/pre/abstract/10.1103/PhysRevE.90.053304" target="_blank">Shadow Wave functions (SWFs)</a> (and references therein). The implications of the latter have been explored in various Monte Carlo calculations.

<p>
In total there are three notebooks:

<ol>
<p><li> the one you are reading now on Variational Monte Carlo methods,</li> 
<p><li> notebook 2 on Machine Learning and quantum mechanical problems and in particular on Boltzmann Machines,</li> 
<p><li> and finally notebook 3 on the link between Boltzmann machines and SWFs.</li> 
</ol>

<h3 id="___sec3">This notebook </h3>

<p>
In this notebook the aim is to give you an introduction as well as an
understanding of the basic elements that are needed in order to
develop a professional variational Monte Carlo code. We will focus on
a simple system of two particles in an oscillator trap (or
alternatively two fermions moving in a Coulombic potential). The particles can
interact via a repulsive or an attrative force.

<p>
The advantage of these systems is that for two particles (boson or
fermions) we have analytical solutions for the eigenpairs of the
non-interacting case. Furthermore, for a two- or three-dimensional
system of two electrons moving in a harmonic oscillator trap, we have
<a href="https://iopscience.iop.org/article/10.1088/0305-4470/27/3/040/meta" target="_blank">analytical solutions for the interacting case as well</a>.

<p>
Having analytical eigenpairs is an invaluable feature that allows us 
to assess the physical relevance of the trial wave functions, be
these either from a standard VMC procedure, from Boltzmann Machines or
from Shadow Wave functions.

<p>
In this notebook we start with the basics of a VMC calculation and
introduce concepts like Markov Chain Monte Carlo methods and the
Metropolis algorithm, importance sampling and Metropolis-Hastings
algorithm, resampling methods to obtain better estimates of the
statistical errors and minimization of the expectation values of the
energy and the variance. The latter is done in order to obtain the
best possible variational parameters. Furthermore it will define the
so-called <b>cost</b> function, a commonly encountered quantity in Machine
Learning algorithms. Minimizing the latter is the one which leads to
the determination of the optimal parameters in basically all Machine Learning algorithms.
For our purposes, it will serve as the first link between VMC methods and Machine Learning methods.

<p>
Topics like Markov Chain Monte Carlo and various resampling techniques
are also central to Machine Learning methods. Presenting them in the
context of VMC approaches leads hopefully to an easier starting point
for the understanding of these methods.

<p>
Finally, the reader may ask what do we actually want to achieve with
complicating life with Machine Learning methods when we can easily
study interacting systems with standard Monte Carlo approaches.  Our
hope is that by adding additional degrees of freedom via Machine
Learning algorithms, we can let the algorithms we employ learn the
parameters of the model via a given optimization algorithm. In
standard Monte Carlo calculations the practitioners end up with fine tuning
the trial wave function using all possible insights about the system
understudy. This may not always lead to the best possible ansatz and
can in the long run be rather time-consuming. In fields like nuclear
many-body physics with complicated interaction terms, guessing an
analytical form for the trial wave fuction can be difficult. Letting
the machine learn the form of the trial function or find the optimal
parameters may lead to insights about the problem which cannot be
obtained by selecting various trial wave functions.

<p>
The emerging and rapidly expanding fields of Machine Learning and Quantum Computing hold also great promise in tackling the 
dimensionality problems (the so-called dimensionality curse in many-body problems) we encounter when studying 
complicated many-body problems. 
The approach to Machine Learning we will focus on 
 is inspired by the idea of representing the wave function with
a restricted Boltzmann machine (RBM), presented recently by <a href="http://science.sciencemag.org/content/355/6325/602" target="_blank">G. Carleo and M. Troyer, Science <b>355</b>, Issue 6325, pp. 602-606 (2017)</a>. They
named such a wave function/network a <em>neural network quantum state</em> (NQS). In their article they apply it to the quantum mechanical
spin lattice systems of the Ising model and Heisenberg model, with
encouraging results.

<p>
Machine learning (ML) is an extremely rich field, in spite of its young age. The
increases we have seen during the last three decades in computational
capabilities have been followed by developments of methods and
techniques for analyzing and handling large data sets, relying heavily
on statistics, computer science and mathematics.  The field is rather
new and developing rapidly. 
Machine learning is the science of giving computers the ability to
learn without being explicitly programmed.  The idea is that there
exist generic algorithms which can be used to find patterns in a broad
class of data sets without having to write code specifically for each
problem. The algorithm will build its own logic based on the data.

<p>
Machine learning is a subfield of computer science, and is closely
related to computational statistics.  It evolved from the study of
pattern recognition in artificial intelligence (AI) research, and has
made contributions to AI tasks like computer vision, natural language
processing and speech recognition. It has also, especially in later
years, found applications in a wide variety of other areas, including
bioinformatics, economy, physics, finance and marketing.
An excellent reference we will come to back to is <a href="https://arxiv.org/abs/1803.08823" target="_blank">Mehta <em>et al.</em>, arXiv:1803.08823</a>.

<p>
Our focus will first be on the basics of VMC calculations.

<h2 id="___sec4">Basic Quantum Monte Carlo  </h2>

<p>
We start with the variational principle.
Given a hamiltonian \( H \) and a trial wave function \( \Psi_T(\boldsymbol{R};\boldsymbol{\alpha}) \), the variational principle states that the expectation value of \( \cal{E}[H] \), defined through 
<p>&nbsp;<br>
$$
   \cal {E}[H] =
   \frac{\int d\boldsymbol{R}\Psi^{\ast}_T(\boldsymbol{R};\boldsymbol{\alpha})H(\boldsymbol{R})\Psi_T(\boldsymbol{R};\boldsymbol{\alpha})}
        {\int d\boldsymbol{R}\Psi^{\ast}_T(\boldsymbol{R};\boldsymbol{\alpha})\Psi_T(\boldsymbol{R};\boldsymbol{\alpha})},
$$
<p>&nbsp;<br>

is an upper bound to the ground state energy \( E_0 \) of the hamiltonian \( H \), that is 
<p>&nbsp;<br>
$$
    E_0 \le {\cal E}[H].
$$
<p>&nbsp;<br>

<p>
In general, the integrals involved in the calculation of various
expectation values are multi-dimensional ones. Traditional integration
methods such as Gauss-Legendre quadrature will not be adequate for say the
computation of the energy of a many-body system.

<p>
Here we have defined the vector \( \boldsymbol{R} = [\boldsymbol{r}_1,\boldsymbol{r}_2,\dots,\boldsymbol{r}_n] \)  as an array that contains the positions of all particles \( n \) while the vector \( \boldsymbol{\alpha} = [\alpha_1,\alpha_2,\dots,\alpha_m] \) contains the variational parameters of the model, \( m \) in total.

<p>
The trial wave function can be expanded in the eigenstates \( \Psi_i(\boldsymbol{R}) \) 
of the hamiltonian since they form a complete set, viz.,
<p>&nbsp;<br>
$$
   \Psi_T(\boldsymbol{R};\boldsymbol{\alpha})=\sum_i a_i\Psi_i(\boldsymbol{R}),
$$
<p>&nbsp;<br>

and assuming that the set of eigenfunctions are normalized, one obtains 
<p>&nbsp;<br>
$$
     \frac{\sum_{nm}a^*_ma_n \int d\boldsymbol{R}\Psi^{\ast}_m(\boldsymbol{R})H(\boldsymbol{R})\Psi_n(\boldsymbol{R})}
        {\sum_{nm}a^*_ma_n \int d\boldsymbol{R}\Psi^{\ast}_m(\boldsymbol{R})\Psi_n(\boldsymbol{R})} =\frac{\sum_{n}a^2_n E_n}
        {\sum_{n}a^2_n} \ge E_0,
$$
<p>&nbsp;<br>

where we used that \( H(\boldsymbol{R})\Psi_n(\boldsymbol{R})=E_n\Psi_n(\boldsymbol{R}) \).
In general, the integrals involved in the calculation of various  expectation
values  are multi-dimensional ones. 
The variational principle yields the lowest energy of states with a  given symmetry.

<p>
In most cases, a wave function has only small values in large parts of 
configuration space, and a straightforward procedure which uses
homogenously distributed random points in configuration space 
will most likely lead to poor results. This may suggest that some kind
of importance sampling combined with e.g., the Metropolis algorithm 
may be  a more efficient way of obtaining the ground state energy.
The hope is then that those regions of configurations space where
the wave function assumes appreciable values are sampled more 
efficiently.

<p>
The tedious part in a VMC calculation is the search for the variational
minimum. A good knowledge of the system is required in order to carry out
reasonable VMC calculations. This is not always the case, 
and often VMC calculations 
serve rather as the starting
point for so-called diffusion Monte Carlo calculations (DMC). Diffusion Monte Carlo  is a way of
solving exactly the many-body Schroedinger equation by means of 
a stochastic procedure. A good guess on the binding energy
and its wave function is however necessary. 
A carefully performed VMC calculation can aid in this context.

<p>
The basic procedure of a Variational Monte Carlo calculations consists thus of 

<ol>
<p><li> Construct first a trial wave function \( \psi_T(\boldsymbol{R};\boldsymbol{\alpha}) \),  for a many-body system consisting of \( n \) particles located at positions  \( \boldsymbol{R}=(\boldsymbol{R}_1,\dots ,\boldsymbol{R}_n) \). The trial wave function depends on \( \alpha \) variational parameters \( \boldsymbol{\alpha}=(\alpha_1,\dots ,\alpha_M) \).</li>
<p><li> Then we evaluate the expectation value of the hamiltonian \( H \)</li> 
</ol>
<p>&nbsp;<br>
$$
   \overline{E}[\boldsymbol{\alpha}]=\frac{\int d\boldsymbol{R}\Psi^{\ast}_{T}(\boldsymbol{R},\boldsymbol{\alpha})H(\boldsymbol{R})\Psi_{T}(\boldsymbol{R},\boldsymbol{\alpha})}
        {\int d\boldsymbol{R}\Psi^{\ast}_{T}(\boldsymbol{R},\boldsymbol{\alpha})\Psi_{T}(\boldsymbol{R},\boldsymbol{\alpha})}.
$$
<p>&nbsp;<br>


<ol>
<p><li> Thereafter we vary \( \boldsymbol{\alpha} \) according to some minimization algorithm and return eventually to the first step if we are not satisfied with the results.</li>
</ol>
<p>

Here we have used the notation \( \overline{E} \) to label the expectation value of the energy.

<h3 id="___sec5">Linking with standard statistical expressions for expectation values </h3>

<p>
In order to bring in the Monte Carlo machinery, we define first a likelihood distribution, or probability density distribution (PDF). Using our ansatz for the trial wave function \( \psi_T(\boldsymbol{R};\boldsymbol{\alpha}) \) we define a PDF
<p>&nbsp;<br>
$$
   P(\boldsymbol{R})= \frac{\left|\psi_T(\boldsymbol{R};\boldsymbol{\alpha})\right|^2}{\int \left|\psi_T(\boldsymbol{R};\boldsymbol{\alpha})\right|^2d\boldsymbol{R}}.
$$
<p>&nbsp;<br>

This is our model for  probability distribution function.
The approximation to the expectation value of the Hamiltonian is now 
<p>&nbsp;<br>
$$
   \overline{E}[\boldsymbol{\alpha}] = 
   \frac{\int d\boldsymbol{R}\Psi^{\ast}_T(\boldsymbol{R};\boldsymbol{\alpha})H(\boldsymbol{R})\Psi_T(\boldsymbol{R};\boldsymbol{\alpha})}
        {\int d\boldsymbol{R}\Psi^{\ast}_T(\boldsymbol{R};\boldsymbol{\alpha})\Psi_T(\boldsymbol{R};\boldsymbol{\alpha})}.
$$
<p>&nbsp;<br>

<p>
We define a new quantity
<p>&nbsp;<br>
$$
   E_L(\boldsymbol{R};\boldsymbol{\alpha})=\frac{1}{\psi_T(\boldsymbol{R};\boldsymbol{\alpha})}H\psi_T(\boldsymbol{R};\boldsymbol{\alpha}),
\tag{1}
$$
<p>&nbsp;<br>

called the local energy, which, together with our trial PDF yields a new expression (and which look simlar to the the expressions for moments in statistics) 
<p>&nbsp;<br>
$$
  \overline{E}[\boldsymbol{\alpha}]=\int P(\boldsymbol{R})E_L(\boldsymbol{R};\boldsymbol{\alpha}) d\boldsymbol{R}\approx \frac{1}{N}\sum_{i=1}^NE_L(\boldsymbol{R_i};\boldsymbol{\alpha})
\tag{2}
$$
<p>&nbsp;<br>

with \( N \) being the number of Monte Carlo samples. The expression on the right hand side follows from Bernoulli's law of large numbers, which states that the sample mean, in the limit \( N\rightarrow \infty \) approaches the true mean

<p>
The Algorithm for performing a variational Monte Carlo calculations runs as this

<ul>

<p><li> Initialisation: Fix the number of Monte Carlo steps. Choose an initial \( \boldsymbol{R} \) and variational parameters \( \alpha \) and calculate \( \left|\psi_T^{\alpha}(\boldsymbol{R})\right|^2 \).</li>

<p><li> Initialise the energy and the variance and start the Monte Carlo calculation.</li>

<ul>

<p><li> Calculate  a trial position  \( \boldsymbol{R}_p=\boldsymbol{R}+r*step \) where \( r \) is a random variable \( r \in [0,1] \).</li>

<p><li> Metropolis algorithm to accept or reject this move  \( w = P(\boldsymbol{R}_p)/P(\boldsymbol{R}) \).</li>

<p><li> If the step is accepted, then we set \( \boldsymbol{R}=\boldsymbol{R}_p \).</li>

<p><li> Update averages</li>
</ul>
<p><li> Finish and compute final averages.</li>
</ul>
<p>

Observe that the jumping in space is governed by the variable <em>step</em>. This is called brute-force sampling and is normally replaced by what is called <b>importance sampling</b>, discussed in more detail below here.

<h3 id="___sec6">Simple example, the hydrogen atom </h3>

The radial Schroedinger equation for the hydrogen atom can be
written as (when we have gotten rid of the first derivative term in the kinetic energy and used \( rR(r)=u(r) \))
<p>&nbsp;<br>
$$
-\frac{\hbar^2}{2m}\frac{d^2 u(r)}{d r^2}-
\left(\frac{ke^2}{r}-\frac{\hbar^2l(l+1)}{2mr^2}\right)u(r)=Eu(r).
$$
<p>&nbsp;<br>

We will specialize to the case with \( l=0 \) and end up with 
<p>&nbsp;<br>
$$
-\frac{\hbar^2}{2m}\frac{d^2 u(r)}{d r^2}-
\left(\frac{ke^2}{r}\right)u(r)=Eu(r).
$$
<p>&nbsp;<br>

Then we introduce a dimensionless variable \( \rho=r/a \) where \( a \) is a constant with dimension length.
Multiplying with \( ma^2/\hbar^2 \) we can rewrite our equations as
<p>&nbsp;<br>
$$
-\frac{1}{2}\frac{d^2 u(\rho)}{d \rho^2}-
\frac{ke^2ma}{\hbar^2}\frac{u(\rho)}{\rho}-\lambda u(\rho)=0.
$$
<p>&nbsp;<br>

Since \( a \) is just a parameter we choose to set
<p>&nbsp;<br>
$$
\frac{ke^2ma}{\hbar^2}=1,
$$
<p>&nbsp;<br>

which leads to \( a=\hbar^2/mke^2 \), better known as the Bohr radius with value \( 0.053 \) nm. Scaling the equations this way does not only render our numerical treatment simpler since we avoid carrying with us all physical parameters, but we obtain also a <b>natural</b> length scale. We will see this again and again. In our discussions below with a harmonic oscillator trap, the <b>natural</b> lentgh scale with be determined by the oscillator frequency, the mass of the particle and \( \hbar \). We have also defined a dimensionless 'energy' \( \lambda = Ema^2/\hbar^2 \). 
With the rescaled quantities, the ground state energy of the hydrogen atom is \( 1/2 \). 
The equation we want to solve is now defined by the Hamiltonian
<p>&nbsp;<br>
$$
H=-\frac{1}{2}\frac{d^2 }{d \rho^2}-\frac{1}{\rho}.
$$
<p>&nbsp;<br>

<p>
As trial wave function we peep now into the analytical solution for
the hydrogen atom and use (with \( \alpha \) as a variational parameter)

<p>&nbsp;<br>
$$
   u_T^{\alpha}(\rho)=\alpha\rho \exp{-(\alpha\rho)}. 
$$
<p>&nbsp;<br>

<p>
Inserting this wave function into the expression for the
local energy \( E_L \) gives
<p>&nbsp;<br>
$$
   E_L(\rho)=-\frac{1}{\rho}-
              \frac{\alpha}{2}\left(\alpha-\frac{2}{\rho}\right).
$$
<p>&nbsp;<br>

<p>
To have analytical local energies saves us from computing numerically
the second derivative, a feature which often increases our numerical
expenditure with a factor of three or more. Integratng up the local energy (recall to bring back the PDF in the integration) gives  \( \overline{E}[\boldsymbol{\alpha}]=\alpha(\alpha/2-1) \).

<h3 id="___sec7">Second example, the harmonic oscillator in one dimension </h3>

<p>
We present here another well-known example, the harmonic oscillator in
one dimension for one particle. This will also serve the aim of
introducing our next model, namely that of interacting electrons in a
harmonic oscillator trap.

<p>
Here as well, we do have analytical solutions and the energy of the
ground state, with \( \hbar=1 \), is \( 1/2\omega \), with \( \omega \) being the
oscillator frequency. We use the following trial wave function

<p>&nbsp;<br>
$$
\psi_T(x;\alpha) = \exp{-(\frac{1}{2}\alpha^2x^2)},
$$
<p>&nbsp;<br>

which results in a local energy 
<p>&nbsp;<br>
$$
\frac{1}{2}\left(\alpha^2+x^2(1-\alpha^4)\right).
$$
<p>&nbsp;<br>

We can compare our numerically calculated energies with the exact energy as function of \( \alpha \)
<p>&nbsp;<br>
$$
\overline{E}[\alpha] = \frac{1}{4}\left(\alpha^2+\frac{1}{\alpha^2}\right).
$$
<p>&nbsp;<br>

Similarly, with the above ansatz, we can also compute the exact variance which reads
<p>&nbsp;<br>
$$
\sigma^2[\alpha]=\frac{1}{4}\left(1+(1-\alpha^4)^2\frac{3}{4\alpha^4}\right)-\overline{E}.
$$
<p>&nbsp;<br>

Our code for computing the energy of the ground state of the harmonic oscillator follows here. We start by defining directories where we store various outputs.
<p>

<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%"><span></span><span style="color: #228B22"># Common imports</span>
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">os</span>

<span style="color: #228B22"># Where to save the figures and data files</span>
PROJECT_ROOT_DIR = <span style="color: #CD5555">&quot;Results&quot;</span>
FIGURE_ID = <span style="color: #CD5555">&quot;Results/FigureFiles&quot;</span>
DATA_ID = <span style="color: #CD5555">&quot;Results/VMCHarmonic&quot;</span>

<span style="color: #8B008B; font-weight: bold">if</span> <span style="color: #8B008B">not</span> os.path.exists(PROJECT_ROOT_DIR):
    os.mkdir(PROJECT_ROOT_DIR)

<span style="color: #8B008B; font-weight: bold">if</span> <span style="color: #8B008B">not</span> os.path.exists(FIGURE_ID):
    os.makedirs(FIGURE_ID)

<span style="color: #8B008B; font-weight: bold">if</span> <span style="color: #8B008B">not</span> os.path.exists(DATA_ID):
    os.makedirs(DATA_ID)

<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">image_path</span>(fig_id):
    <span style="color: #8B008B; font-weight: bold">return</span> os.path.join(FIGURE_ID, fig_id)

<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">data_path</span>(dat_id):
    <span style="color: #8B008B; font-weight: bold">return</span> os.path.join(DATA_ID, dat_id)

<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">save_fig</span>(fig_id):
    plt.savefig(image_path(fig_id) + <span style="color: #CD5555">&quot;.png&quot;</span>, <span style="color: #658b00">format</span>=<span style="color: #CD5555">&#39;png&#39;</span>)

outfile = <span style="color: #658b00">open</span>(data_path(<span style="color: #CD5555">&quot;VMCHarmonic.dat&quot;</span>),<span style="color: #CD5555">&#39;w&#39;</span>)
</pre></div>
<p>
We proceed with the implementation of the Monte Carlo algorithm but list first the ansatz for the wave function and the expression for the local energy
<p>

<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%"><span></span><span style="color: #228B22"># VMC for the one-dimensional harmonic oscillator</span>
<span style="color: #228B22"># Brute force Metropolis, no importance sampling and no energy minimization</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">math</span> <span style="color: #8B008B; font-weight: bold">import</span> exp, sqrt
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">random</span> <span style="color: #8B008B; font-weight: bold">import</span> random, seed
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">numpy</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">np</span>
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">matplotlib.pyplot</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">plt</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">numba</span> <span style="color: #8B008B; font-weight: bold">import</span> jit
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">decimal</span> <span style="color: #8B008B; font-weight: bold">import</span> *
<span style="color: #228B22"># Trial wave function for the Harmonic oscillator in one dimension</span>
<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">WaveFunction</span>(r,alpha):
    <span style="color: #8B008B; font-weight: bold">return</span> exp(-<span style="color: #B452CD">0.5</span>*alpha*alpha*r*r)

<span style="color: #228B22"># Local energy  for the Harmonic oscillator in one dimension</span>
<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">LocalEnergy</span>(r,alpha):
    <span style="color: #8B008B; font-weight: bold">return</span> <span style="color: #B452CD">0.5</span>*r*r*(<span style="color: #B452CD">1</span>-alpha**<span style="color: #B452CD">4</span>) + <span style="color: #B452CD">0.5</span>*alpha*alpha
</pre></div>
<p>
Note that in the Metropolis algorithm there is no need to compute the
trial wave function, mainly since we are just taking the ratio of two
exponentials. It is then from a computational point view, more
convenient to compute the argument from the ratio and then calculate
the exponential. Here we have refrained from this purely of
pedagogical reasons.

<p>

<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%"><span></span><span style="color: #228B22"># The Monte Carlo sampling with the Metropolis algo</span>
<span style="color: #228B22"># The jit decorator tells Numba to compile this function.</span>
<span style="color: #228B22"># The argument types will be inferred by Numba when the function is called.</span>
<span style="color: #707a7c">@jit</span>
<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">MonteCarloSampling</span>():

    NumberMCcycles= <span style="color: #B452CD">100000</span>
    StepSize = <span style="color: #B452CD">1.0</span>
    <span style="color: #228B22"># positions</span>
    PositionOld = <span style="color: #B452CD">0.0</span>
    PositionNew = <span style="color: #B452CD">0.0</span>

    <span style="color: #228B22"># seed for rng generator</span>
    seed()
    <span style="color: #228B22"># start variational parameter</span>
    alpha = <span style="color: #B452CD">0.4</span>
    <span style="color: #8B008B; font-weight: bold">for</span> ia <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(MaxVariations):
        alpha += .<span style="color: #B452CD">05</span>
        AlphaValues[ia] = alpha
        energy = energy2 = <span style="color: #B452CD">0.0</span>
        <span style="color: #228B22">#Initial position</span>
        PositionOld = StepSize * (random() - .<span style="color: #B452CD">5</span>)
        wfold = WaveFunction(PositionOld,alpha)
        <span style="color: #228B22">#Loop over MC MCcycles</span>
        <span style="color: #8B008B; font-weight: bold">for</span> MCcycle <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(NumberMCcycles):
            <span style="color: #228B22">#Trial position </span>
            PositionNew = PositionOld + StepSize*(random() - .<span style="color: #B452CD">5</span>)
            wfnew = WaveFunction(PositionNew,alpha)
            <span style="color: #228B22">#Metropolis test to see whether we accept the move</span>
            <span style="color: #8B008B; font-weight: bold">if</span> random() &lt;= wfnew**<span style="color: #B452CD">2</span> / wfold**<span style="color: #B452CD">2</span>:
                PositionOld = PositionNew
                wfold = wfnew
            DeltaE = LocalEnergy(PositionOld,alpha)
            energy += DeltaE
            energy2 += DeltaE**<span style="color: #B452CD">2</span>
        <span style="color: #228B22">#We calculate mean, variance and error</span>
        energy /= NumberMCcycles
        energy2 /= NumberMCcycles
        variance = energy2 - energy**<span style="color: #B452CD">2</span>
        error = sqrt(variance/NumberMCcycles)
        Energies[ia] = energy    
        Variances[ia] = variance    
        outfile.write(<span style="color: #CD5555">&#39;%f %f %f %f \n&#39;</span> %(alpha,energy,variance,error))
    <span style="color: #8B008B; font-weight: bold">return</span> Energies, AlphaValues, Variances
</pre></div>
<p>
Finally, the results are presented here with the exact energies and variances as well.
<p>

<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%"><span></span><span style="color: #228B22">#Here starts the main program with variable declarations</span>
MaxVariations = <span style="color: #B452CD">20</span>
Energies = np.zeros((MaxVariations))
ExactEnergies = np.zeros((MaxVariations))
ExactVariance = np.zeros((MaxVariations))
Variances = np.zeros((MaxVariations))
AlphaValues = np.zeros(MaxVariations)
(Energies, AlphaValues, Variances) = MonteCarloSampling()
outfile.close()
ExactEnergies = <span style="color: #B452CD">0.25</span>*(AlphaValues*AlphaValues+<span style="color: #B452CD">1.0</span>/(AlphaValues*AlphaValues))
ExactVariance = <span style="color: #B452CD">0.25</span>*(<span style="color: #B452CD">1.0</span>+((<span style="color: #B452CD">1.0</span>-AlphaValues**<span style="color: #B452CD">4</span>)**<span style="color: #B452CD">2</span>)*<span style="color: #B452CD">3.0</span>/(<span style="color: #B452CD">4</span>*(AlphaValues**<span style="color: #B452CD">4</span>)))-ExactEnergies*ExactEnergies

<span style="color: #228B22">#simple subplot</span>
plt.subplot(<span style="color: #B452CD">2</span>, <span style="color: #B452CD">1</span>, <span style="color: #B452CD">1</span>)
plt.plot(AlphaValues, Energies, <span style="color: #CD5555">&#39;o-&#39;</span>,AlphaValues, ExactEnergies,<span style="color: #CD5555">&#39;r-&#39;</span>)
plt.title(<span style="color: #CD5555">&#39;Energy and variance&#39;</span>)
plt.ylabel(<span style="color: #CD5555">&#39;Dimensionless energy&#39;</span>)
plt.subplot(<span style="color: #B452CD">2</span>, <span style="color: #B452CD">1</span>, <span style="color: #B452CD">2</span>)
plt.plot(AlphaValues, Variances, <span style="color: #CD5555">&#39;.-&#39;</span>,AlphaValues, ExactVariance,<span style="color: #CD5555">&#39;r-&#39;</span>)
plt.xlabel(<span style="color: #CD5555">r&#39;$\alpha$&#39;</span>, fontsize=<span style="color: #B452CD">15</span>)
plt.ylabel(<span style="color: #CD5555">&#39;Variance&#39;</span>)
save_fig(<span style="color: #CD5555">&quot;VMCHarmonic&quot;</span>)
plt.show()
<span style="color: #228B22">#nice printout with Pandas</span>
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">pandas</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">pd</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">pandas</span> <span style="color: #8B008B; font-weight: bold">import</span> DataFrame
data ={<span style="color: #CD5555">&#39;Alpha&#39;</span>:AlphaValues, <span style="color: #CD5555">&#39;Energy&#39;</span>:Energies,<span style="color: #CD5555">&#39;Exact Energy&#39;</span>:ExactEnergies,<span style="color: #CD5555">&#39;Variance&#39;</span>:Variances,<span style="color: #CD5555">&#39;Exact Variance&#39;</span>:ExactVariance,}
frame = pd.DataFrame(data)
<span style="color: #658b00">print</span>(frame)
</pre></div>
<p>
For \( \alpha=1 \) we have the exact eigenpairs, as can be deduced from the
table here. With \( \omega=1 \), the exact energy is \( 1/2 \) a.u. with zero
variance, as it should. We see also that our computed variance follows rather well the exact variance.
Increasing the number of Monte Carlo cycles will improve our statistics (try to increase the number of Monte Carlo cycles).

<p>
The fact that the variance is exactly equal to zero when \( \alpha=1 \) is that 
we then have the exact wave function, and the action of the hamiltionan
on the wave function
<p>&nbsp;<br>
$$
   H\psi = \mathrm{constant}\times \psi,
$$
<p>&nbsp;<br>

yields just a constant. The integral which defines various 
expectation values involving moments of the hamiltonian becomes then
<p>&nbsp;<br>
$$
   \langle H^n \rangle =
   \frac{\int d\boldsymbol{R}\Psi^{\ast}_T(\boldsymbol{R})H^n(\boldsymbol{R})\Psi_T(\boldsymbol{R})}
        {\int d\boldsymbol{R}\Psi^{\ast}_T(\boldsymbol{R})\Psi_T(\boldsymbol{R})}=
\mathrm{constant}\times\frac{\int d\boldsymbol{R}\Psi^{\ast}_T(\boldsymbol{R})\Psi_T(\boldsymbol{R})}
        {\int d\boldsymbol{R}\Psi^{\ast}_T(\boldsymbol{R})\Psi_T(\boldsymbol{R})}=\mathrm{constant}.
$$
<p>&nbsp;<br>

<b>This gives an important information: the exact wave function leads to zero variance!</b>
As we will see below, many practitioners perform a minimization on both the energy and the variance.

<h2 id="___sec8">The Metropolis algorithm </h2>

<p>
Till now we have not yet discussed the derivation of the Metropolis algorithm. We assume the reader has some familiarity with the mathematics of Markov chains.

<p>
The Metropolis algorithm , see <a href="http://scitation.aip.org/content/aip/journal/jcp/21/6/10.1063/1.1699114" target="_blank">the original article</a>, was invented by Metropolis et. al
and is often simply called the Metropolis algorithm.
It is a method to sample a normalized probability
distribution by a stochastic process. We define \( \mathbf{P}_i^{(n)} \) to
be the probability for finding the system in the state \( i \) at step \( n \).
The algorithm is then

<ul>
<p><li> Sample a possible new state \( j \) with some probability \( T_{i\rightarrow j} \).</li>
<p><li> Accept the new state \( j \) with probability \( A_{i \rightarrow j} \) and use it as the next sample. With probability \( 1-A_{i\rightarrow j} \) the move is rejected and the original state \( i \) is used again as a sample.</li>
</ul>
<p>

We wish to derive the required properties of \( T \) and \( A \) such that
\( \mathbf{P}_i^{(n\rightarrow \infty)} \rightarrow p_i \) so that starting
from any distribution, the method converges to the correct distribution.
Note that the description here is for a discrete probability distribution.
Replacing probabilities \( p_i \) with expressions like \( p(x_i)dx_i \) will
take all of these over to the corresponding continuum expressions.

<p>
The dynamical equation for \( \mathbf{P}_i^{(n)} \) can be written directly from
the description above. The probability of being in the state \( i \) at step \( n \)
is given by the probability of being in any state \( j \) at the previous step,
and making an accepted transition to \( i \) added to the probability of
being in the state \( i \), making a transition to any state \( j \) and
rejecting the move:
<p>&nbsp;<br>
$$
\mathbf{P}^{(n)}_i = \sum_j \left [
\mathbf{P}^{(n-1)}_jT_{j\rightarrow i} A_{j\rightarrow i} 
+\mathbf{P}^{(n-1)}_iT_{i\rightarrow j}\left ( 1- A_{i\rightarrow j} \right)
\right ] \,.
$$
<p>&nbsp;<br>

Since the probability of making some transition must be 1,
\( \sum_j T_{i\rightarrow j} = 1 \), and the above equation becomes
<p>&nbsp;<br>
$$
\mathbf{P}^{(n)}_i = \mathbf{P}^{(n-1)}_i +
 \sum_j \left [
\mathbf{P}^{(n-1)}_jT_{j\rightarrow i} A_{j\rightarrow i} 
-\mathbf{P}^{(n-1)}_iT_{i\rightarrow j}A_{i\rightarrow j}
\right ] \,.
$$
<p>&nbsp;<br>

<p>
For large \( n \) we require that \( \mathbf{P}^{(n\rightarrow \infty)}_i = p_i \),
the desired probability distribution. Taking this limit, gives the
balance requirement
<p>&nbsp;<br>
$$
 \sum_j \left [
p_jT_{j\rightarrow i} A_{j\rightarrow i}
-p_iT_{i\rightarrow j}A_{i\rightarrow j}
\right ] = 0 \,.
$$
<p>&nbsp;<br>

The balance requirement is very weak. Typically the much stronger detailed
balance requirement is enforced, that is rather than the sum being
set to zero, we set each term separately to zero and use this
to determine the acceptance probabilities. Rearranging, the result is
<p>&nbsp;<br>
$$
\frac{ A_{j\rightarrow i}}{A_{i\rightarrow j}}
= \frac{p_iT_{i\rightarrow j}}{ p_jT_{j\rightarrow i}} \,.
$$
<p>&nbsp;<br>

<p>
The Metropolis choice is to maximize the \( A \) values, that is
<p>&nbsp;<br>
$$
A_{j \rightarrow i} = \min \left ( 1,
\frac{p_iT_{i\rightarrow j}}{ p_jT_{j\rightarrow i}}\right ).
$$
<p>&nbsp;<br>

Other choices are possible, but they all correspond to multilplying
\( A_{i\rightarrow j} \) and \( A_{j\rightarrow i} \) by the same constant
smaller than unity.\footnote{The penalty function method uses just such
a factor to compensate for \( p_i \) that are evaluated stochastically
and are therefore noisy.}

<p>
Having chosen the acceptance probabilities, we have guaranteed that
if the  \( \mathbf{P}_i^{(n)} \) has equilibrated, that is if it is equal to \( p_i \),
it will remain equilibrated. Next we need to find the circumstances for
convergence to equilibrium.

<p>
The dynamical equation can be written as
<p>&nbsp;<br>
$$
\mathbf{P}^{(n)}_i = \sum_j M_{ij}\mathbf{P}^{(n-1)}_j
$$
<p>&nbsp;<br>

with the matrix \( M \) given by
<p>&nbsp;<br>
$$
M_{ij} = \delta_{ij}\left [ 1 -\sum_k T_{i\rightarrow k} A_{i \rightarrow k}
\right ] + T_{j\rightarrow i} A_{j\rightarrow i} \,.
$$
<p>&nbsp;<br>

Summing over \( i \) shows that \( \sum_i M_{ij} = 1 \), and since
\( \sum_k T_{i\rightarrow k} = 1 \), and \( A_{i \rightarrow k} \leq 1 \), the
elements of the matrix satisfy \( M_{ij} \geq 0 \). The matrix \( M \) is therefore
a stochastic matrix.

<p>
The Metropolis method is simply the power method for computing the
right eigenvector of \( M \) with the largest magnitude eigenvalue.
By construction, the correct probability distribution is a right eigenvector
with eigenvalue 1. Therefore, for the Metropolis method to converge
to this result, we must show that \( M \) has only one eigenvalue with this
magnitude, and all other eigenvalues are smaller.

<h2 id="___sec9">The system: two electrons in a harmonic oscillator trap in two dimensions </h2>

<p>
The Hamiltonian of the quantum dot is given by
<p>&nbsp;<br>
$$ \hat{H} = \hat{H}_0 + \hat{V}, 
$$
<p>&nbsp;<br>

where \( \hat{H}_0 \) is the many-body HO Hamiltonian, and \( \hat{V} \) is the
inter-electron Coulomb interactions. In dimensionless units,
<p>&nbsp;<br>
$$ \hat{V}= \sum_{i < j}^N \frac{1}{r_{ij}},
$$
<p>&nbsp;<br>

with \( r_{ij}=\sqrt{\mathbf{r}_i^2 - \mathbf{r}_j^2} \).

<p>
This leads to the  separable Hamiltonian, with the relative motion part given by (\( r_{ij}=r \))
<p>&nbsp;<br>
$$ 
\hat{H}_r=-\nabla^2_r + \frac{1}{4}\omega^2r^2+ \frac{1}{r},
$$
<p>&nbsp;<br>

plus a standard Harmonic Oscillator problem  for the center-of-mass motion.
This system has analytical solutions in two and three dimensions (<a href="https://journals.aps.org/pra/abstract/10.1103/PhysRevA.48.3561" target="_blank">M. Taut 1993 and 1994</a>).

<p>
We want to perform  a Variational Monte Carlo calculation of the ground state of two electrons in a quantum dot well with different oscillator energies, assuming total spin \( S=0 \).
Our trial wave function has the following form
<p>&nbsp;<br>
$$
\begin{equation}
   \psi_{T}(\boldsymbol{r}_1,\boldsymbol{r}_2) = 
   C\exp{\left(-\alpha_1\omega(r_1^2+r_2^2)/2\right)}
   \exp{\left(\frac{r_{12}}{(1+\alpha_2 r_{12})}\right)}, 
\tag{3}
\end{equation}
$$
<p>&nbsp;<br>

where the $\alpha$s represent our variational parameters, two in this case.

<p>
Why does the trial function look like this? How did we get there?
<b>This will be one of our main motivations</b> for switching to Machine Learning later.

<p>
To find an ansatz for the correlated part of the wave function, it is
useful to rewrite the two-particle local energy in terms of the
relative and center-of-mass motion.  
Let us denote the distance
between the two electrons as \( r_{12} \). We omit the center-of-mass
motion since we are only interested in the case when \( r_{12}
\rightarrow 0 \). The contribution from the center-of-mass (CoM)
variable \( \boldsymbol{R}_{\mathrm{CoM}} \) gives only a finite contribution.  We
focus only on the terms that are relevant for \( r_{12} \) and for three
dimensions.

<p>
The relevant local energy becomes then 
<p>&nbsp;<br>
$$ \lim_{r_{12} \rightarrow 0}E_L(R)= \frac{1}{{\calR}_T(r_{12})}\left(2\frac{d^2}{dr_{ij}^2}+\frac{4}{r_{ij}}\frac{d}{dr_{ij}}+\frac{2}{r_{ij}}-\frac{l(l+1)}{r_{ij}^2}+2E \right){\cal R}_T(r_{12})
= 0.  
$$
<p>&nbsp;<br>

Set \( l=0 \) and we have the so-called <b>cusp</b> condition 
<p>&nbsp;<br>
$$ \frac{d {\cal R}_T(r_{12})}{dr_{12}} = -\frac{1}{2(l+1)} {\cal R}_T(r_{12})\qquad r_{12}\to 0 
$$
<p>&nbsp;<br>

<p>
The above  results in
<p>&nbsp;<br>
$$
{\cal R}_T  \propto \exp{(r_{ij}/2)}, 
$$
<p>&nbsp;<br>

for anti-parallel spins and 
<p>&nbsp;<br>
$$
{\cal R}_T  \propto \exp{(r_{ij}/4)}, 
$$
<p>&nbsp;<br>

for anti-parallel spins. 
This is the so-called cusp condition for the relative motion, resulting in a minimal requirement
for the correlation part of the wave fuction.
For general systems containing more than say two electrons, we have this
condition for each electron pair \( ij \).

<h3 id="___sec10">First code attempt for the two-electron case </h3>

<p>
First, as with the hydrogen case, we declare where to store files.
<p>

<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%"><span></span><span style="color: #228B22"># Common imports</span>
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">os</span>

<span style="color: #228B22"># Where to save the figures and data files</span>
PROJECT_ROOT_DIR = <span style="color: #CD5555">&quot;Results&quot;</span>
FIGURE_ID = <span style="color: #CD5555">&quot;Results/FigureFiles&quot;</span>
DATA_ID = <span style="color: #CD5555">&quot;Results/VMCQdotMetropolis&quot;</span>

<span style="color: #8B008B; font-weight: bold">if</span> <span style="color: #8B008B">not</span> os.path.exists(PROJECT_ROOT_DIR):
    os.mkdir(PROJECT_ROOT_DIR)

<span style="color: #8B008B; font-weight: bold">if</span> <span style="color: #8B008B">not</span> os.path.exists(FIGURE_ID):
    os.makedirs(FIGURE_ID)

<span style="color: #8B008B; font-weight: bold">if</span> <span style="color: #8B008B">not</span> os.path.exists(DATA_ID):
    os.makedirs(DATA_ID)

<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">image_path</span>(fig_id):
    <span style="color: #8B008B; font-weight: bold">return</span> os.path.join(FIGURE_ID, fig_id)

<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">data_path</span>(dat_id):
    <span style="color: #8B008B; font-weight: bold">return</span> os.path.join(DATA_ID, dat_id)

<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">save_fig</span>(fig_id):
    plt.savefig(image_path(fig_id) + <span style="color: #CD5555">&quot;.png&quot;</span>, <span style="color: #658b00">format</span>=<span style="color: #CD5555">&#39;png&#39;</span>)

outfile = <span style="color: #658b00">open</span>(data_path(<span style="color: #CD5555">&quot;VMCQdotMetropolis.dat&quot;</span>),<span style="color: #CD5555">&#39;w&#39;</span>)
</pre></div>
<p>
Thereafter we set up the analytical expressions for the wave functions and the local energy

<p>

<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%"><span></span><span style="color: #228B22"># 2-electron VMC for quantum dot system in two dimensions</span>
<span style="color: #228B22"># Brute force Metropolis, no importance sampling and no energy minimization</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">math</span> <span style="color: #8B008B; font-weight: bold">import</span> exp, sqrt
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">random</span> <span style="color: #8B008B; font-weight: bold">import</span> random, seed
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">numpy</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">np</span>
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">matplotlib.pyplot</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">plt</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">mpl_toolkits.mplot3d</span> <span style="color: #8B008B; font-weight: bold">import</span> Axes3D
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">matplotlib</span> <span style="color: #8B008B; font-weight: bold">import</span> cm
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">matplotlib.ticker</span> <span style="color: #8B008B; font-weight: bold">import</span> LinearLocator, FormatStrFormatter
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">sys</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">numba</span> <span style="color: #8B008B; font-weight: bold">import</span> jit


<span style="color: #228B22"># Trial wave function for the 2-electron quantum dot in two dims</span>
<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">WaveFunction</span>(r,alpha,beta):
    r1 = r[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">0</span>]**<span style="color: #B452CD">2</span> + r[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">1</span>]**<span style="color: #B452CD">2</span>
    r2 = r[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">0</span>]**<span style="color: #B452CD">2</span> + r[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">1</span>]**<span style="color: #B452CD">2</span>
    r12 = sqrt((r[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">0</span>]-r[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">0</span>])**<span style="color: #B452CD">2</span> + (r[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">1</span>]-r[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">1</span>])**<span style="color: #B452CD">2</span>)
    deno = r12/(<span style="color: #B452CD">1</span>+beta*r12)
    <span style="color: #8B008B; font-weight: bold">return</span> exp(-<span style="color: #B452CD">0.5</span>*alpha*(r1+r2)+deno)

<span style="color: #228B22"># Local energy  for the 2-electron quantum dot in two dims, using analytical local energy</span>
<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">LocalEnergy</span>(r,alpha,beta):
    
    r1 = (r[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">0</span>]**<span style="color: #B452CD">2</span> + r[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">1</span>]**<span style="color: #B452CD">2</span>)
    r2 = (r[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">0</span>]**<span style="color: #B452CD">2</span> + r[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">1</span>]**<span style="color: #B452CD">2</span>)
    r12 = sqrt((r[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">0</span>]-r[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">0</span>])**<span style="color: #B452CD">2</span> + (r[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">1</span>]-r[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">1</span>])**<span style="color: #B452CD">2</span>)
    deno = <span style="color: #B452CD">1.0</span>/(<span style="color: #B452CD">1</span>+beta*r12)
    deno2 = deno*deno
    <span style="color: #8B008B; font-weight: bold">return</span> <span style="color: #B452CD">0.5</span>*(<span style="color: #B452CD">1</span>-alpha*alpha)*(r1 + r2) +<span style="color: #B452CD">2.0</span>*alpha + <span style="color: #B452CD">1.0</span>/r12+deno2*(alpha*r12-deno2+<span style="color: #B452CD">2</span>*beta*deno-<span style="color: #B452CD">1.0</span>/r12)
</pre></div>
<p>
The Monte Carlo sampling without importance sampling is set up here.
<p>

<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%"><span></span><span style="color: #228B22"># The Monte Carlo sampling with the Metropolis algo</span>
<span style="color: #228B22"># The jit decorator tells Numba to compile this function.</span>
<span style="color: #228B22"># The argument types will be inferred by Numba when the function is called.</span>
<span style="color: #707a7c">@jit</span>
<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">MonteCarloSampling</span>():

    NumberMCcycles= <span style="color: #B452CD">10000</span>
    StepSize = <span style="color: #B452CD">1.0</span>
    <span style="color: #228B22"># positions</span>
    PositionOld = np.zeros((NumberParticles,Dimension), np.double)
    PositionNew = np.zeros((NumberParticles,Dimension), np.double)

    <span style="color: #228B22"># seed for rng generator</span>
    seed()
    <span style="color: #228B22"># start variational parameter</span>
    alpha = <span style="color: #B452CD">0.9</span>
    <span style="color: #8B008B; font-weight: bold">for</span> ia <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(MaxVariations):
        alpha += .<span style="color: #B452CD">025</span>
        AlphaValues[ia] = alpha
        beta = <span style="color: #B452CD">0.2</span> 
        <span style="color: #8B008B; font-weight: bold">for</span> jb <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(MaxVariations):
            beta += .<span style="color: #B452CD">01</span>
            BetaValues[jb] = beta
            energy = energy2 = <span style="color: #B452CD">0.0</span>
            DeltaE = <span style="color: #B452CD">0.0</span>
            <span style="color: #228B22">#Initial position</span>
            <span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(NumberParticles):
                <span style="color: #8B008B; font-weight: bold">for</span> j <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(Dimension):
                    PositionOld[i,j] = StepSize * (random() - .<span style="color: #B452CD">5</span>)
            wfold = WaveFunction(PositionOld,alpha,beta)

            <span style="color: #228B22">#Loop over MC MCcycles</span>
            <span style="color: #8B008B; font-weight: bold">for</span> MCcycle <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(NumberMCcycles):
                <span style="color: #228B22">#Trial position moving one particle at the time</span>
                <span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(NumberParticles):
                    <span style="color: #8B008B; font-weight: bold">for</span> j <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(Dimension):
                        PositionNew[i,j] = PositionOld[i,j] + StepSize * (random() - .<span style="color: #B452CD">5</span>)
                    wfnew = WaveFunction(PositionNew,alpha,beta)

                    <span style="color: #228B22">#Metropolis test to see whether we accept the move</span>
                    <span style="color: #8B008B; font-weight: bold">if</span> random() &lt; wfnew**<span style="color: #B452CD">2</span> / wfold**<span style="color: #B452CD">2</span>:
                       <span style="color: #8B008B; font-weight: bold">for</span> j <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(Dimension):
                           PositionOld[i,j] = PositionNew[i,j]
                       wfold = wfnew
                DeltaE = LocalEnergy(PositionOld,alpha,beta)
                energy += DeltaE
                energy2 += DeltaE**<span style="color: #B452CD">2</span>
            <span style="color: #228B22">#We calculate mean, variance and error ...</span>
            energy /= NumberMCcycles
            energy2 /= NumberMCcycles
            variance = energy2 - energy**<span style="color: #B452CD">2</span>
            error = sqrt(variance/NumberMCcycles)
            Energies[ia,jb] = energy    
            Variances[ia,jb] = variance    
            outfile.write(<span style="color: #CD5555">&#39;%f %f %f %f %f\n&#39;</span> %(alpha,beta,energy,variance,error))
    <span style="color: #8B008B; font-weight: bold">return</span> Energies, Variances, AlphaValues, BetaValues
</pre></div>
<p>
And finally comes the main part with the plots as well.
<p>

<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%"><span></span><span style="color: #228B22">#Here starts the main program with variable declarations</span>
NumberParticles = <span style="color: #B452CD">2</span>
Dimension = <span style="color: #B452CD">2</span>
MaxVariations = <span style="color: #B452CD">10</span>
Energies = np.zeros((MaxVariations,MaxVariations))
Variances = np.zeros((MaxVariations,MaxVariations))
AlphaValues = np.zeros(MaxVariations)
BetaValues = np.zeros(MaxVariations)
(Energies, Variances, AlphaValues, BetaValues) = MonteCarloSampling()
outfile.close()

<span style="color: #228B22"># Prepare for plots</span>
fig = plt.figure()
ax = fig.gca(projection=<span style="color: #CD5555">&#39;3d&#39;</span>)
<span style="color: #228B22"># Plot the surface.</span>
X, Y = np.meshgrid(AlphaValues, BetaValues)
surf = ax.plot_surface(X, Y, Energies,cmap=cm.coolwarm,linewidth=<span style="color: #B452CD">0</span>, antialiased=<span style="color: #8B008B; font-weight: bold">False</span>)
<span style="color: #228B22"># Customize the z axis.</span>
zmin = np.matrix(Energies).min()
zmax = np.matrix(Energies).max()
ax.set_zlim(zmin, zmax)
ax.set_xlabel(<span style="color: #CD5555">r&#39;$\alpha$&#39;</span>)
ax.set_ylabel(<span style="color: #CD5555">r&#39;$\beta$&#39;</span>)
ax.set_zlabel(<span style="color: #CD5555">r&#39;$\langle E \rangle$&#39;</span>)
ax.zaxis.set_major_locator(LinearLocator(<span style="color: #B452CD">10</span>))
ax.zaxis.set_major_formatter(FormatStrFormatter(<span style="color: #CD5555">&#39;%.02f&#39;</span>))
<span style="color: #228B22"># Add a color bar which maps values to colors.</span>
fig.colorbar(surf, shrink=<span style="color: #B452CD">0.5</span>, aspect=<span style="color: #B452CD">5</span>)
save_fig(<span style="color: #CD5555">&quot;QdotMetropolis&quot;</span>)
plt.show()
</pre></div>

<h2 id="___sec11">Importance sampling </h2>

<p>
The above way of performing a Monte Carlo calculation is not the most efficient one. 
We need to replace the brute force Metropolis algorithm with a walk in
coordinate space biased by the trial wave function.  This approach is
based on the Fokker-Planck equation and the Langevin equation for
generating a trajectory in coordinate space.  The link between the
Fokker-Planck equation and the Langevin equations are explained, only
partly, in the slides below.  An excellent reference on topics like
Brownian motion, Markov chains, the Fokker-Planck equation and the
Langevin equation is the text by <a href="http://www.elsevier.com/books/stochastic-processes-in-physics-and-chemistry/van-kampen/978-0-444-52965-7" target="_blank">Van Kampen</a>
Here we will focus first on the implementation part first.

<p>
For a diffusion process characterized by a time-dependent probability density \( P(x,t) \) in one dimension the Fokker-Planck
equation reads (for one particle /walker) 
<p>&nbsp;<br>
$$
   \frac{\partial P}{\partial t} = D\frac{\partial }{\partial x}\left(\frac{\partial }{\partial x} -F\right)P(x,t),
$$
<p>&nbsp;<br>

where \( F \) is a drift term and \( D \) is the diffusion coefficient.

<p>
The new positions in coordinate space are given as the solutions of the Langevin equation using Euler's method, namely,
we go from the Langevin equation
<p>&nbsp;<br>
$$ 
   \frac{\partial x(t)}{\partial t} = DF(x(t)) +\eta,
$$
<p>&nbsp;<br>

with \( \eta \) a random variable,
yielding a new position 
<p>&nbsp;<br>
$$
   y = x+DF(x)\Delta t +\xi\sqrt{\Delta t},
$$
<p>&nbsp;<br>

where \( \xi \) is gaussian random variable and \( \Delta t \) is a chosen time step. 
The quantity \( D \) is, in atomic units, equal to \( 1/2 \) and comes from the factor \( 1/2 \) in the kinetic energy operator. Note that \( \Delta t \) is to be viewed as a parameter. Values of \( \Delta t \in [0.001,0.01] \) yield in general rather stable values of the ground state energy.

<p>
The process of isotropic diffusion characterized by a time-dependent probability density \( P(\mathbf{x},t) \) obeys (as an approximation) the so-called Fokker-Planck equation 
<p>&nbsp;<br>
$$
   \frac{\partial P}{\partial t} = \sum_i D\frac{\partial }{\partial \mathbf{x_i}}\left(\frac{\partial }{\partial \mathbf{x_i}} -\mathbf{F_i}\right)P(\mathbf{x},t),
$$
<p>&nbsp;<br>

where \( \mathbf{F_i} \) is the \( i^{th} \) component of the drift term (drift velocity) caused by an external potential, and \( D \) is the diffusion coefficient. The convergence to a stationary probability density can be obtained by setting the left hand side to zero. The resulting equation will be satisfied if and only if all the terms of the sum are equal zero,
<p>&nbsp;<br>
$$
\frac{\partial^2 P}{\partial {\mathbf{x_i}^2}} = P\frac{\partial}{\partial {\mathbf{x_i}}}\mathbf{F_i} + \mathbf{F_i}\frac{\partial}{\partial {\mathbf{x_i}}}P.
$$
<p>&nbsp;<br>

<p>
The drift vector should be of the form \( \mathbf{F} = g(\mathbf{x}) \frac{\partial P}{\partial \mathbf{x}} \). Then,
<p>&nbsp;<br>
$$
\frac{\partial^2 P}{\partial {\mathbf{x_i}^2}} = P\frac{\partial g}{\partial P}\left( \frac{\partial P}{\partial {\mathbf{x}_i}}  \right)^2 + P g \frac{\partial ^2 P}{\partial {\mathbf{x}_i^2}}  + g \left( \frac{\partial P}{\partial {\mathbf{x}_i}}  \right)^2.
$$
<p>&nbsp;<br>

The condition of stationary density means that the left hand side equals zero. In other words, the terms containing first and second derivatives have to cancel each other. It is possible only if \( g = \frac{1}{P} \), which yields
<p>&nbsp;<br>
$$
\mathbf{F} = 2\frac{1}{\Psi_T}\nabla\Psi_T,
$$
<p>&nbsp;<br>

which is known as the so-called <em>quantum force</em>. This term is responsible for pushing the walker towards regions of configuration space where the trial wave function is large, increasing the efficiency of the simulation in contrast to the Metropolis algorithm where the walker has the same probability of moving in every direction.

<p>
The Fokker-Planck equation yields a (the solution to the equation) transition probability given by the Green's function
<p>&nbsp;<br>
$$
  G(y,x,\Delta t) = \frac{1}{(4\pi D\Delta t)^{3N/2}} \exp{\left(-(y-x-D\Delta t F(x))^2/4D\Delta t\right)}
$$
<p>&nbsp;<br>

which in turn means that our brute force Metropolis algorithm
<p>&nbsp;<br>
$$ 
    A(y,x) = \mathrm{min}(1,q(y,x))),
$$
<p>&nbsp;<br>

with \( q(y,x) = |\Psi_T(y)|^2/|\Psi_T(x)|^2 \) is now replaced by the <a href="http://scitation.aip.org/content/aip/journal/jcp/21/6/10.1063/1.1699114" target="_blank">Metropolis-Hastings algorithm</a>. See also  <a href="http://biomet.oxfordjournals.org/content/57/1/97.abstract" target="_blank">Hasting's original article</a>, 
<p>&nbsp;<br>
$$
q(y,x) = \frac{G(x,y,\Delta t)|\Psi_T(y)|^2}{G(y,x,\Delta t)|\Psi_T(x)|^2}
$$
<p>&nbsp;<br>

<h3 id="___sec12">Code example for the interacting case with importance sampling </h3>

<p>
We are now ready to implement importance sampling. This is done here for the two-electron case with the Coulomb interaction, as in the previous example. We have two variational parameters \( \alpha \) and \( \beta \). After the set up of files

<p>

<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%"><span></span><span style="color: #228B22"># Common imports</span>
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">os</span>

<span style="color: #228B22"># Where to save the figures and data files</span>
PROJECT_ROOT_DIR = <span style="color: #CD5555">&quot;Results&quot;</span>
FIGURE_ID = <span style="color: #CD5555">&quot;Results/FigureFiles&quot;</span>
DATA_ID = <span style="color: #CD5555">&quot;Results/VMCQdotImportance&quot;</span>

<span style="color: #8B008B; font-weight: bold">if</span> <span style="color: #8B008B">not</span> os.path.exists(PROJECT_ROOT_DIR):
    os.mkdir(PROJECT_ROOT_DIR)

<span style="color: #8B008B; font-weight: bold">if</span> <span style="color: #8B008B">not</span> os.path.exists(FIGURE_ID):
    os.makedirs(FIGURE_ID)

<span style="color: #8B008B; font-weight: bold">if</span> <span style="color: #8B008B">not</span> os.path.exists(DATA_ID):
    os.makedirs(DATA_ID)

<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">image_path</span>(fig_id):
    <span style="color: #8B008B; font-weight: bold">return</span> os.path.join(FIGURE_ID, fig_id)

<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">data_path</span>(dat_id):
    <span style="color: #8B008B; font-weight: bold">return</span> os.path.join(DATA_ID, dat_id)

<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">save_fig</span>(fig_id):
    plt.savefig(image_path(fig_id) + <span style="color: #CD5555">&quot;.png&quot;</span>, <span style="color: #658b00">format</span>=<span style="color: #CD5555">&#39;png&#39;</span>)

outfile = <span style="color: #658b00">open</span>(data_path(<span style="color: #CD5555">&quot;VMCQdotImportance.dat&quot;</span>),<span style="color: #CD5555">&#39;w&#39;</span>)
</pre></div>
<p>
we move on to the set up of the trial wave function, the analytical expression for the local energy and the analytical expression for the quantum force.
<p>

<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%"><span></span><span style="color: #228B22"># 2-electron VMC code for 2dim quantum dot with importance sampling</span>
<span style="color: #228B22"># Using gaussian rng for new positions and Metropolis- Hastings </span>
<span style="color: #228B22"># No energy minimization</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">math</span> <span style="color: #8B008B; font-weight: bold">import</span> exp, sqrt
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">random</span> <span style="color: #8B008B; font-weight: bold">import</span> random, seed, normalvariate
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">numpy</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">np</span>
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">matplotlib.pyplot</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">plt</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">mpl_toolkits.mplot3d</span> <span style="color: #8B008B; font-weight: bold">import</span> Axes3D
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">matplotlib</span> <span style="color: #8B008B; font-weight: bold">import</span> cm
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">matplotlib.ticker</span> <span style="color: #8B008B; font-weight: bold">import</span> LinearLocator, FormatStrFormatter
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">sys</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">numba</span> <span style="color: #8B008B; font-weight: bold">import</span> jit,njit


<span style="color: #228B22"># Trial wave function for the 2-electron quantum dot in two dims</span>
<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">WaveFunction</span>(r,alpha,beta):
    r1 = r[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">0</span>]**<span style="color: #B452CD">2</span> + r[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">1</span>]**<span style="color: #B452CD">2</span>
    r2 = r[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">0</span>]**<span style="color: #B452CD">2</span> + r[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">1</span>]**<span style="color: #B452CD">2</span>
    r12 = sqrt((r[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">0</span>]-r[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">0</span>])**<span style="color: #B452CD">2</span> + (r[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">1</span>]-r[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">1</span>])**<span style="color: #B452CD">2</span>)
    deno = r12/(<span style="color: #B452CD">1</span>+beta*r12)
    <span style="color: #8B008B; font-weight: bold">return</span> exp(-<span style="color: #B452CD">0.5</span>*alpha*(r1+r2)+deno)

<span style="color: #228B22"># Local energy  for the 2-electron quantum dot in two dims, using analytical local energy</span>
<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">LocalEnergy</span>(r,alpha,beta):
    
    r1 = (r[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">0</span>]**<span style="color: #B452CD">2</span> + r[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">1</span>]**<span style="color: #B452CD">2</span>)
    r2 = (r[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">0</span>]**<span style="color: #B452CD">2</span> + r[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">1</span>]**<span style="color: #B452CD">2</span>)
    r12 = sqrt((r[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">0</span>]-r[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">0</span>])**<span style="color: #B452CD">2</span> + (r[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">1</span>]-r[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">1</span>])**<span style="color: #B452CD">2</span>)
    deno = <span style="color: #B452CD">1.0</span>/(<span style="color: #B452CD">1</span>+beta*r12)
    deno2 = deno*deno
    <span style="color: #8B008B; font-weight: bold">return</span> <span style="color: #B452CD">0.5</span>*(<span style="color: #B452CD">1</span>-alpha*alpha)*(r1 + r2) +<span style="color: #B452CD">2.0</span>*alpha + <span style="color: #B452CD">1.0</span>/r12+deno2*(alpha*r12-deno2+<span style="color: #B452CD">2</span>*beta*deno-<span style="color: #B452CD">1.0</span>/r12)

<span style="color: #228B22"># Setting up the quantum force for the two-electron quantum dot, recall that it is a vector</span>
<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">QuantumForce</span>(r,alpha,beta):

    qforce = np.zeros((NumberParticles,Dimension), np.double)
    r12 = sqrt((r[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">0</span>]-r[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">0</span>])**<span style="color: #B452CD">2</span> + (r[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">1</span>]-r[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">1</span>])**<span style="color: #B452CD">2</span>)
    deno = <span style="color: #B452CD">1.0</span>/(<span style="color: #B452CD">1</span>+beta*r12)
    qforce[<span style="color: #B452CD">0</span>,:] = -<span style="color: #B452CD">2</span>*r[<span style="color: #B452CD">0</span>,:]*alpha*(r[<span style="color: #B452CD">0</span>,:]-r[<span style="color: #B452CD">1</span>,:])*deno*deno/r12
    qforce[<span style="color: #B452CD">1</span>,:] = -<span style="color: #B452CD">2</span>*r[<span style="color: #B452CD">1</span>,:]*alpha*(r[<span style="color: #B452CD">1</span>,:]-r[<span style="color: #B452CD">0</span>,:])*deno*deno/r12
    <span style="color: #8B008B; font-weight: bold">return</span> qforce
</pre></div>
<p>
The Monte Carlo sampling includes now the Metropolis-Hastings algorithm, with the additional complication of having to evaluate the <b>quantum force</b> and the Green's function which is the solution of the Fokker-Planck equation.

<p>

<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%"><span></span><span style="color: #228B22"># The Monte Carlo sampling with the Metropolis algo</span>
<span style="color: #228B22"># jit decorator tells Numba to compile this function.</span>
<span style="color: #228B22"># The argument types will be inferred by Numba when function is called.</span>
<span style="color: #707a7c">@jit</span>()
<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">MonteCarloSampling</span>():

    NumberMCcycles= <span style="color: #B452CD">100000</span>
    <span style="color: #228B22"># Parameters in the Fokker-Planck simulation of the quantum force</span>
    D = <span style="color: #B452CD">0.5</span>
    TimeStep = <span style="color: #B452CD">0.05</span>
    <span style="color: #228B22"># positions</span>
    PositionOld = np.zeros((NumberParticles,Dimension), np.double)
    PositionNew = np.zeros((NumberParticles,Dimension), np.double)
    <span style="color: #228B22"># Quantum force</span>
    QuantumForceOld = np.zeros((NumberParticles,Dimension), np.double)
    QuantumForceNew = np.zeros((NumberParticles,Dimension), np.double)

    <span style="color: #228B22"># seed for rng generator </span>
    seed()
    <span style="color: #228B22"># start variational parameter  loops, two parameters here</span>
    alpha = <span style="color: #B452CD">0.9</span>
    <span style="color: #8B008B; font-weight: bold">for</span> ia <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(MaxVariations):
        alpha += .<span style="color: #B452CD">025</span>
        AlphaValues[ia] = alpha
        beta = <span style="color: #B452CD">0.2</span> 
        <span style="color: #8B008B; font-weight: bold">for</span> jb <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(MaxVariations):
            beta += .<span style="color: #B452CD">01</span>
            BetaValues[jb] = beta
            energy = energy2 = <span style="color: #B452CD">0.0</span>
            DeltaE = <span style="color: #B452CD">0.0</span>
            <span style="color: #228B22">#Initial position</span>
            <span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(NumberParticles):
                <span style="color: #8B008B; font-weight: bold">for</span> j <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(Dimension):
                    PositionOld[i,j] = normalvariate(<span style="color: #B452CD">0.0</span>,<span style="color: #B452CD">1.0</span>)*sqrt(TimeStep)
            wfold = WaveFunction(PositionOld,alpha,beta)
            QuantumForceOld = QuantumForce(PositionOld,alpha, beta)

            <span style="color: #228B22">#Loop over MC MCcycles</span>
            <span style="color: #8B008B; font-weight: bold">for</span> MCcycle <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(NumberMCcycles):
                <span style="color: #228B22">#Trial position moving one particle at the time</span>
                <span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(NumberParticles):
                    <span style="color: #8B008B; font-weight: bold">for</span> j <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(Dimension):
                        PositionNew[i,j] = PositionOld[i,j]+normalvariate(<span style="color: #B452CD">0.0</span>,<span style="color: #B452CD">1.0</span>)*sqrt(TimeStep)+\
                                           QuantumForceOld[i,j]*TimeStep*D
                    wfnew = WaveFunction(PositionNew,alpha,beta)
                    QuantumForceNew = QuantumForce(PositionNew,alpha, beta)
                    GreensFunction = <span style="color: #B452CD">0.0</span>
                    <span style="color: #8B008B; font-weight: bold">for</span> j <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(Dimension):
                        GreensFunction += <span style="color: #B452CD">0.5</span>*(QuantumForceOld[i,j]+QuantumForceNew[i,j])*\
	                              (D*TimeStep*<span style="color: #B452CD">0.5</span>*(QuantumForceOld[i,j]-QuantumForceNew[i,j])-\
                                      PositionNew[i,j]+PositionOld[i,j])
      
                    GreensFunction = exp(GreensFunction)
                    ProbabilityRatio = GreensFunction*wfnew**<span style="color: #B452CD">2</span>/wfold**<span style="color: #B452CD">2</span>
                    <span style="color: #228B22">#Metropolis-Hastings test to see whether we accept the move</span>
                    <span style="color: #8B008B; font-weight: bold">if</span> random() &lt;= ProbabilityRatio:
                       <span style="color: #8B008B; font-weight: bold">for</span> j <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(Dimension):
                           PositionOld[i,j] = PositionNew[i,j]
                           QuantumForceOld[i,j] = QuantumForceNew[i,j]
                       wfold = wfnew
                DeltaE = LocalEnergy(PositionOld,alpha,beta)
                energy += DeltaE
                energy2 += DeltaE**<span style="color: #B452CD">2</span>
            <span style="color: #228B22"># We calculate mean, variance and error (no blocking applied)</span>
            energy /= NumberMCcycles
            energy2 /= NumberMCcycles
            variance = energy2 - energy**<span style="color: #B452CD">2</span>
            error = sqrt(variance/NumberMCcycles)
            Energies[ia,jb] = energy    
            outfile.write(<span style="color: #CD5555">&#39;%f %f %f %f %f\n&#39;</span> %(alpha,beta,energy,variance,error))
    <span style="color: #8B008B; font-weight: bold">return</span> Energies, AlphaValues, BetaValues
</pre></div>
<p>
The main part here contains the setup of the variational parameters, the energies and the variance.
<p>

<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%"><span></span><span style="color: #228B22">#Here starts the main program with variable declarations</span>
NumberParticles = <span style="color: #B452CD">2</span>
Dimension = <span style="color: #B452CD">2</span>
MaxVariations = <span style="color: #B452CD">10</span>
Energies = np.zeros((MaxVariations,MaxVariations))
AlphaValues = np.zeros(MaxVariations)
BetaValues = np.zeros(MaxVariations)
(Energies, AlphaValues, BetaValues) = MonteCarloSampling()
outfile.close()
<span style="color: #228B22"># Prepare for plots</span>
fig = plt.figure()
ax = fig.gca(projection=<span style="color: #CD5555">&#39;3d&#39;</span>)
<span style="color: #228B22"># Plot the surface.</span>
X, Y = np.meshgrid(AlphaValues, BetaValues)
surf = ax.plot_surface(X, Y, Energies,cmap=cm.coolwarm,linewidth=<span style="color: #B452CD">0</span>, antialiased=<span style="color: #8B008B; font-weight: bold">False</span>)
<span style="color: #228B22"># Customize the z axis.</span>
zmin = np.matrix(Energies).min()
zmax = np.matrix(Energies).max()
ax.set_zlim(zmin, zmax)
ax.set_xlabel(<span style="color: #CD5555">r&#39;$\alpha$&#39;</span>)
ax.set_ylabel(<span style="color: #CD5555">r&#39;$\beta$&#39;</span>)
ax.set_zlabel(<span style="color: #CD5555">r&#39;$\langle E \rangle$&#39;</span>)
ax.zaxis.set_major_locator(LinearLocator(<span style="color: #B452CD">10</span>))
ax.zaxis.set_major_formatter(FormatStrFormatter(<span style="color: #CD5555">&#39;%.02f&#39;</span>))
<span style="color: #228B22"># Add a color bar which maps values to colors.</span>
fig.colorbar(surf, shrink=<span style="color: #B452CD">0.5</span>, aspect=<span style="color: #B452CD">5</span>)
save_fig(<span style="color: #CD5555">&quot;QdotImportance&quot;</span>)
plt.show()
</pre></div>

<h2 id="___sec13">Technical aspects, improvements and how to define the cost function </h2>

<p>
The above procedure is also not the smartest one. Looping over all
variational parameters becomes expensive and we see from the previous
plot that the surface is not very smooth, indicating that we need many more
Monte Carlo cycles in order to reliably define an energy minimum.

<p>
What we can do however is to perform some preliminary calculations
with selected variational parameters (normally with less Monte Carlo
cycles than those used in a full production calculation). For every
step we evaluate the derivatives of the energy as functions of the
variational parameters. When the derivatives disappear we have
hopefully reached the global minimum.

<p>
At this point we have the optimal variational parameters and can start
our large-scale production run.  To find the optimal parameters
entails the computation of the gradients of the energy and
optimization algorithms like various <b>gradient descent</b> methods.
This is an art by itself and is discussed for example in <a href="http://compphysics.github.io/ComputationalPhysics2/doc/pub/cg/html/cg.html" target="_blank">our lectures on optimization methods</a>. We refer the reader to these notes for more details.

<p>
This part allows us also to link with the true working horse of every
Machine Learning algorithm, namely the optimization part. This
normally involves one of the stochastic gradient descent algorithms
discussed in the above lecture notes. We will come back to these topics in the second notebook.

<p>
In order to apply these optmization algortihms we anticipate partly what is to come in notebook 2 on
Boltzmann machines. Our cost (or loss) function is here given by the
expectation value of the energy as function of the variational
parameters.

<p>
To find the derivatives of the local energy expectation value as
function of the variational parameters, we can use the chain rule and
the hermiticity of the Hamiltonian.

<p>
Let us define 
<p>&nbsp;<br>
$$
\bar{E}_{\alpha_i}=\frac{d\langle  E_L\rangle}{d\alpha_i}.
$$
<p>&nbsp;<br>

as the derivative of the energy with respect to the variational parameter \( \alpha_i \)
We define also the derivative of the trial function (skipping the subindex \( T \)) as 
<p>&nbsp;<br>
$$
\bar{\Psi}_{i}=\frac{d\Psi}{d\alpha_i}.
$$
<p>&nbsp;<br>

<p>
The elements of the gradient of the local energy are then (using the
chain rule and the hermiticity of the Hamiltonian)

<p>&nbsp;<br>
$$ \bar{E}_{i}=
2\left( \langle \frac{\bar{\Psi}_{i}}{\Psi}E_L\rangle -\langle
\frac{\bar{\Psi}_{i}}{\Psi}\rangle\langle E_L \rangle\right).  
$$
<p>&nbsp;<br>

<p>
From a computational point of view it means that we need to compute
the expectation values of 
<p>&nbsp;<br>
$$ \langle
\frac{\bar{\Psi}_{i}}{\Psi}E_L\rangle, 
$$
<p>&nbsp;<br>

<p>
and

<p>&nbsp;<br>
$$ \langle
\frac{\bar{\Psi}_{i}}{\Psi}\rangle\langle E_L\rangle 
$$
<p>&nbsp;<br>

<p>
These integrals are evaluted using MC intergration (with all its possible
error sources).  We can then use methods like stochastic gradient or
other minimization methods to find the optimal variational parameters

<p>
As an alternative to the energy as cost function, we could use the variance as the cost function.
As discussed earlier, if we have the exact wave function, the variance is exactly equal to zero.
Suppose the trial function (our model) is the exact wave function.

<p>
The variance is defined as

<p>&nbsp;<br>
$$
\sigma_E = \langle E^2\rangle - \langle E\rangle^2.
$$
<p>&nbsp;<br>

Some practitioners perform Monte Carlo calculations by minimizing both the energy and the variance.

<p>
In order to minimize the variance we need the derivatives of 
<p>&nbsp;<br>
$$
\sigma_E = \langle E^2\rangle - \langle E\rangle^2,
$$
<p>&nbsp;<br>

with respect to the variational parameters. The derivatives of the variance can then be used to defined the
so-called Hessian matrix, which in turn allows us to use minimization methods like Newton's method or 
standard gradient methods.

<p>
This leads to however a more complicated expression, with obvious errors when evaluating many more integrals by Monte Carlo integration. It is normally less used, see however <a href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.94.150201" target="_blank">Filippi and Umrigar</a>. The expression becomes complicated
<p>&nbsp;<br>
$$
\bar{E}_{ij} = 2\left[ \langle (\frac{\bar{\Psi}_{ij}}{\Psi}+\frac{\bar{\Psi}_{j}}{\Psi}\frac{\bar{\Psi}_{i}}{\Psi})(E_L-\langle E\rangle)\rangle -\langle \frac{\bar{\Psi}_{i}}{\Psi}\rangle\bar{E}_j-\langle \frac{\bar{\Psi}_{j}}{\Psi}\rangle\bar{E}_i\right] +\langle \frac{\bar{\Psi}_{i}}{\Psi}E_L{_j}\rangle +\langle \frac{\bar{\Psi}_{j}}{\Psi}E_L{_i}\rangle -\langle \frac{\bar{\Psi}_{i}}{\Psi}\rangle\langle E_L{_j}\rangle \langle \frac{\bar{\Psi}_{j}}{\Psi}\rangle\langle E_L{_i}\rangle.  
$$
<p>&nbsp;<br>

<p>
Evaluating the cost function means having to evaluate the above second derivative of the energy.

<p>
Before we proceed with code examples, let us look at some simple examples, here the one-particle harmonic oscillator in one dimension. This serves as a very useful check when developing a code. The first code discussed is the two-dimensional non-interacting harmonic oscillator.

<h3 id="___sec14">Simple example </h3>

<p>
Let us illustrate what is needed in our calculations using a simple
example, the harmonic oscillator in one dimension.  For the harmonic
oscillator in one-dimension we have a trial wave function and
probability

<p>&nbsp;<br>
$$
\begin{equation*}
\psi_T(x) = e^{-\alpha^2 x^2} \qquad P_T(x)dx = \frac{e^{-2\alpha^2 x^2}dx}{\int dx e^{-2\alpha^2 x^2}}
\end{equation*}
$$
<p>&nbsp;<br>

with \( \alpha \) being the variational parameter. 
We obtain then the following local energy
<p>&nbsp;<br>
$$
\begin{equation*}
E_L[\alpha] = \alpha^2+x^2\left(\frac{1}{2}-2\alpha^2\right),
\end{equation*}
$$
<p>&nbsp;<br>

which results in the expectation value for the local energy
<p>&nbsp;<br>
$$
\begin{equation*}
\langle  E_L[\alpha]\rangle = \frac{1}{2}\alpha^2+\frac{1}{8\alpha^2}
\end{equation*}
$$
<p>&nbsp;<br>

<p>
The derivative of the energy with respect to \( \alpha \) gives
<p>&nbsp;<br>
$$
\begin{equation*}
\frac{d\langle  E_L[\alpha]\rangle}{d\alpha} = \alpha-\frac{1}{4\alpha^3}
\end{equation*}
$$
<p>&nbsp;<br>

and a second derivative which is always positive (meaning that we find a minimum)
<p>&nbsp;<br>
$$
\begin{equation*}
\frac{d^2\langle  E_L[\alpha]\rangle}{d\alpha^2} = 1+\frac{3}{4\alpha^4}
\end{equation*}
$$
<p>&nbsp;<br>

The condition
<p>&nbsp;<br>
$$
\begin{equation*}
\frac{d\langle  E_L[\alpha]\rangle}{d\alpha} = 0,
\end{equation*}
$$
<p>&nbsp;<br>

gives the optimal \( \alpha=1/\sqrt{2} \), as expected.

<p>
We can also minimize the variance. In our simple model the variance is
<p>&nbsp;<br>
$$
\begin{equation*}
\sigma^2[\alpha] = \frac{1}{2}\alpha^4-\frac{1}{4}+\frac{1}{32\alpha^4},
\end{equation*}
$$
<p>&nbsp;<br>

with first derivative
<p>&nbsp;<br>
$$
\begin{equation*}
\frac{d \sigma^2[\alpha]}{d\alpha} = 2\alpha^3-\frac{1}{8\alpha^5}
\end{equation*}
$$
<p>&nbsp;<br>

and a second derivative which is always positive (as expected for a convex function)
<p>&nbsp;<br>
$$
\begin{equation*}
\frac{d^2\sigma^2[\alpha]}{d\alpha^2} = 6\alpha^2+\frac{5}{8\alpha^6}
\end{equation*}
$$
<p>&nbsp;<br>

<p>
In general we end up computing the expectation value of the energy in
terms of some parameters \( \alpha_0,\alpha_1,\dots,\alpha_n \) and we
search for a minimum in this multi-variable parameter space.  This
leads to an energy minimization problem <em>where we need the derivative
of the energy as a function of the variational parameters</em>.

<p>
In the above example this was easy and we were able to find the
expression for the derivative by simple derivations.  However, in our
actual calculations the energy is represented by a multi-dimensional
integral with several variational parameters.
</section>



</div> <!-- class="slides" -->
</div> <!-- class="reveal" -->

<script src="reveal.js/lib/js/head.min.js"></script>
<script src="reveal.js/js/reveal.js"></script>

<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({

    // Display navigation controls in the bottom right corner
    controls: true,

    // Display progress bar (below the horiz. slider)
    progress: true,

    // Display the page number of the current slide
    slideNumber: true,

    // Push each slide change to the browser history
    history: false,

    // Enable keyboard shortcuts for navigation
    keyboard: true,

    // Enable the slide overview mode
    overview: true,

    // Vertical centering of slides
    //center: true,
    center: false,

    // Enables touch navigation on devices with touch input
    touch: true,

    // Loop the presentation
    loop: false,

    // Change the presentation direction to be RTL
    rtl: false,

    // Turns fragments on and off globally
    fragments: true,

    // Flags if the presentation is running in an embedded mode,
    // i.e. contained within a limited portion of the screen
    embedded: false,

    // Number of milliseconds between automatically proceeding to the
    // next slide, disabled when set to 0, this value can be overwritten
    // by using a data-autoslide attribute on your slides
    autoSlide: 0,

    // Stop auto-sliding after user input
    autoSlideStoppable: true,

    // Enable slide navigation via mouse wheel
    mouseWheel: false,

    // Hides the address bar on mobile devices
    hideAddressBar: true,

    // Opens links in an iframe preview overlay
    previewLinks: false,

    // Transition style
    transition: 'default', // default/cube/page/concave/zoom/linear/fade/none

    // Transition speed
    transitionSpeed: 'default', // default/fast/slow

    // Transition style for full page slide backgrounds
    backgroundTransition: 'default', // default/none/slide/concave/convex/zoom

    // Number of slides away from the current that are visible
    viewDistance: 3,

    // Parallax background image
    //parallaxBackgroundImage: '', // e.g. "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'"

    // Parallax background size
    //parallaxBackgroundSize: '' // CSS syntax, e.g. "2100px 900px"

    theme: Reveal.getQueryHash().theme, // available themes are in reveal.js/css/theme
    transition: Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/none

});

Reveal.initialize({
    dependencies: [
        // Cross-browser shim that fully implements classList - https://github.com/eligrey/classList.js/
        { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },

        // Interpret Markdown in <section> elements
        { src: 'reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
        { src: 'reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },

        // Syntax highlight for <code> elements
        { src: 'reveal.js/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },

        // Zoom in and out with Alt+click
        { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },

        // Speaker notes
        { src: 'reveal.js/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } },

        // Remote control your reveal.js presentation using a touch device
        //{ src: 'reveal.js/plugin/remotes/remotes.js', async: true, condition: function() { return !!document.body.classList; } },

        // MathJax
        //{ src: 'reveal.js/plugin/math/math.js', async: true }
    ]
});

Reveal.initialize({

    // The "normal" size of the presentation, aspect ratio will be preserved
    // when the presentation is scaled to fit different resolutions. Can be
    // specified using percentage units.
    width: 1170,  // original: 960,
    height: 700,

    // Factor of the display size that should remain empty around the content
    margin: 0.1,

    // Bounds for smallest/largest possible scale to apply to content
    minScale: 0.2,
    maxScale: 1.0

});
</script>

<!-- begin footer logo
<div style="position: absolute; bottom: 0px; left: 0; margin-left: 0px">
<img src="somelogo.png">
</div>
     end footer logo -->



</body>
</html>
