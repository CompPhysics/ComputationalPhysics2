{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- dom:TITLE: From Variational Monte Carlo to Boltzmann Machines and Machine Learning -->\n",
    "# From Variational Monte Carlo to Boltzmann Machines and Machine Learning\n",
    "<!-- dom:AUTHOR: Morten Hjorth-Jensen  Email hjensen@msu.edu  Department of Physics and Astronomy and National Superconducting Cyclotron Laboratory, Michigan State University, East Lansing, 48824 MI, USA -->\n",
    "<!-- Author: -->  \n",
    "**Morten Hjorth-Jensen  Email hjensen@msu.edu  Department of Physics and Astronomy and National Superconducting Cyclotron Laboratory, Michigan State University, East Lansing, 48824 MI, USA**\n",
    "\n",
    "Date: **Notebook 1:  Variational Monte Carlo**\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### Structure and Aims\n",
    "\n",
    "These notebooks serve the aim of linking traditional variational Monte\n",
    "Carlo VMC calculations methods with recent progress on solving\n",
    "many-particle problems using Machine Learning algorithms.\n",
    "\n",
    "Furthermore, when linking with Machine Learning algorithms, in particular\n",
    "so-called Boltzmann Machines, there are interesting connections between\n",
    "these algorithms and so-called [Shadow Wave functions (SWFs)](https://journals.aps.org/pre/abstract/10.1103/PhysRevE.90.053304) (and references therein). The implications of the latter have been explored in various Monte Carlo calculations. \n",
    "\n",
    "In total there are three notebooks:\n",
    "1. the one you are reading now on Variational Monte Carlo methods, \n",
    "\n",
    "2. notebook 2 on Machine Learning and quantum mechanical problems and in particular on Boltzmann Machines, \n",
    "\n",
    "3. and finally notebook 3 on the link between Boltzmann machines and SWFs. \n",
    "\n",
    "### This notebook\n",
    "\n",
    "In this notebook the aim is to give you an introduction as well as an\n",
    "understanding of the basic elements that are needed in order to\n",
    "develop a professional variational Monte Carlo code. We will focus on\n",
    "a simple system of two particles in an oscillator trap (or\n",
    "alternatively two fermions moving in a Coulombic potential) which can\n",
    "interact via repulsive or attrative force.\n",
    "\n",
    "The advantage of these systems is that for two particles (boson or\n",
    "fermions) we have analytical solutions for the eigenpairs for the\n",
    "non-interacting case. Furthermore, for a two- or three-dimensional\n",
    "system of two electrons moving in a harmonic oscillator trap, we have\n",
    "[analytical solutions for the interacting case as well](https://iopscience.iop.org/article/10.1088/0305-4470/27/3/040/meta).  \n",
    "\n",
    "Having analytical eigenpairs is an invaluable feature that allow us \n",
    "to assess the physical relevance of the trial wave functions, be\n",
    "these either from a standard VMC procedure, from Boltzmann Machines or\n",
    "from Shadow Wave functions.\n",
    "\n",
    "In this notebook we start with the basics of a VMC calculation and\n",
    "introduce concepts like Markov Chain Monte Carlo methods and the\n",
    "Metropolis algorithm, importance sampling and Metropolis-Hastings\n",
    "algorithm, resampling methods to obtain better estimates of the\n",
    "statistical errors and minimization of the expectation values of the\n",
    "energy and the variance. The latter is done in order to obtain the\n",
    "best possible variational parameters. Furthermore it will define the\n",
    "so-called **cost** function, a commonly encountered quantity in Machine\n",
    "Learning algorithms. Minimizing the latter is the one which leads to\n",
    "the determination of the optimal parameters in basically all Machine Learning algorithms.\n",
    "For our purposes, it will serve as the first link between VMC methods and Machine Learning methods.\n",
    "\n",
    "Topics like Markov Chain Monte Carlo and various resampling techniques\n",
    "are also central to Machine Learning methods. Presenting them in the\n",
    "context of VMC approaches leads hopefully to an easier starting point\n",
    "for the understanding of these methods.\n",
    "\n",
    "Finally, the reader may ask what do we actually want to achieve with\n",
    "complicating life with Machine Learning methods when we can easily\n",
    "study interacting systems with standard Monte Carlo approaches.  Our\n",
    "hope is that by adding additional degrees of freedom via Machine\n",
    "Learning algorithms, we can let the algorithms we employ learn the\n",
    "parameters of the model via a given optimization algorithm. In\n",
    "standard Monte Carlo calculations the practitioners end up with fine tuning\n",
    "the trial wave function using all possible insights about the system\n",
    "understudy. This may not always lead to the best possible ansatz and\n",
    "can in the long run be rather time-consuming. In fields like nuclear\n",
    "many-body physics with complicated interaction terms, guessing an\n",
    "analytical form for the trial wave fuction can be difficult. Letting\n",
    "the machine learn the form of the trial function or find the optimal\n",
    "parameters may lead to insights about the problem which cannot be\n",
    "obtained by selecting various trial wave functions.\n",
    "\n",
    "The emerging and rapidly expanding fields of Machine Learning and Quantum Computing hold also great promise in tackling the \n",
    "dimensionality problems (the so-called dimensionality curse in many-body problems) we encounter when studying \n",
    "complicated many-body problems. \n",
    "The approach to Machine Learning we will focus on \n",
    " is inspired by the idea of representing the wave function with\n",
    "a restricted Boltzmann machine (RBM), presented recently by [G. Carleo and M. Troyer, Science **355**, Issue 6325, pp. 602-606 (2017)](http://science.sciencemag.org/content/355/6325/602). They\n",
    "named such a wave function/network a *neural network quantum state* (NQS). In their article they apply it to the quantum mechanical\n",
    "spin lattice systems of the Ising model and Heisenberg model, with\n",
    "encouraging results.\n",
    "\n",
    "Machine learning (ML) is an extremely rich field, in spite of its young age. The\n",
    "increases we have seen during the last three decades in computational\n",
    "capabilities have been followed by developments of methods and\n",
    "techniques for analyzing and handling large date sets, relying heavily\n",
    "on statistics, computer science and mathematics.  The field is rather\n",
    "new and developing rapidly. \n",
    "Machine learning is the science of giving computers the ability to\n",
    "learn without being explicitly programmed.  The idea is that there\n",
    "exist generic algorithms which can be used to find patterns in a broad\n",
    "class of data sets without having to write code specifically for each\n",
    "problem. The algorithm will build its own logic based on the data.\n",
    "\n",
    "Machine learning is a subfield of computer science, and is closely\n",
    "related to computational statistics.  It evolved from the study of\n",
    "pattern recognition in artificial intelligence (AI) research, and has\n",
    "made contributions to AI tasks like computer vision, natural language\n",
    "processing and speech recognition. It has also, especially in later\n",
    "years, found applications in a wide variety of other areas, including\n",
    "bioinformatics, economy, physics, finance and marketing.\n",
    "An excellent reference we will come to back to is [Mehta *et al.*, arXiv:1803.08823](https://arxiv.org/abs/1803.08823).\n",
    "\n",
    "Our focus will first be on the basics of VMC calculations. \n",
    "\n",
    "\n",
    "\n",
    "## Basic Quantum Monte Carlo\n",
    "\n",
    "We start with the variational principle.\n",
    "Given a hamiltonian $H$ and a trial wave function $\\Psi_T(\\boldsymbol{R};\\boldsymbol{\\alpha})$, the variational principle states that the expectation value of $\\cal{E}[H]$, defined through"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\cal {E}[H] =\n",
    "   \\frac{\\int d\\boldsymbol{R}\\Psi^{\\ast}_T(\\boldsymbol{R};\\boldsymbol{\\alpha})H(\\boldsymbol{R})\\Psi_T(\\boldsymbol{R};\\boldsymbol{\\alpha})}\n",
    "        {\\int d\\boldsymbol{R}\\Psi^{\\ast}_T(\\boldsymbol{R};\\boldsymbol{\\alpha})\\Psi_T(\\boldsymbol{R};\\boldsymbol{\\alpha})},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is an upper bound to the ground state energy $E_0$ of the hamiltonian $H$, that is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "E_0 \\le {\\cal E}[H].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the integrals involved in the calculation of various\n",
    "expectation values are multi-dimensional ones. Traditional integration\n",
    "methods such as Gauss-Legendre quadrature will not be adequate for say the\n",
    "computation of the energy of a many-body system.\n",
    "\n",
    "Here we have defined the vector $\\boldsymbol{R} = [\\boldsymbol{r}_1,\\boldsymbol{r}_2,\\dots,\\boldsymbol{r}_n]$  as an array that contains the positions of all particles $n$ while the vector $\\boldsymbol{\\alpha} = [\\alpha_1,\\alpha_2,\\dots,\\alpha_m]$ contains the variational parameters of the model, $m$ in total. \n",
    "\n",
    "The trial wave function can be expanded in the eigenstates $\\Psi_i(\\boldsymbol{R})$ \n",
    "of the hamiltonian since they form a complete set, viz.,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\Psi_T(\\boldsymbol{R};\\boldsymbol{\\alpha})=\\sum_i a_i\\Psi_i(\\boldsymbol{R}),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and assuming that the set of eigenfunctions are normalized, one obtains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\sum_{nm}a^*_ma_n \\int d\\boldsymbol{R}\\Psi^{\\ast}_m(\\boldsymbol{R})H(\\boldsymbol{R})\\Psi_n(\\boldsymbol{R})}\n",
    "        {\\sum_{nm}a^*_ma_n \\int d\\boldsymbol{R}\\Psi^{\\ast}_m(\\boldsymbol{R})\\Psi_n(\\boldsymbol{R})} =\\frac{\\sum_{n}a^2_n E_n}\n",
    "        {\\sum_{n}a^2_n} \\ge E_0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where we used that $H(\\boldsymbol{R})\\Psi_n(\\boldsymbol{R})=E_n\\Psi_n(\\boldsymbol{R})$.\n",
    "In general, the integrals involved in the calculation of various  expectation\n",
    "values  are multi-dimensional ones. \n",
    "The variational principle yields the lowest energy of states with a  given symmetry.\n",
    "\n",
    "In most cases, a wave function has only small values in large parts of \n",
    "configuration space, and a straightforward procedure which uses\n",
    "homogenously distributed random points in configuration space \n",
    "will most likely lead to poor results. This may suggest that some kind\n",
    "of importance sampling combined with e.g., the Metropolis algorithm \n",
    "may be  a more efficient way of obtaining the ground state energy.\n",
    "The hope is then that those regions of configurations space where\n",
    "the wave function assumes appreciable values are sampled more \n",
    "efficiently. \n",
    "\n",
    "The tedious part in a VMC calculation is the search for the variational\n",
    "minimum. A good knowledge of the system is required in order to carry out\n",
    "reasonable VMC calculations. This is not always the case, \n",
    "and often VMC calculations \n",
    "serve rather as the starting\n",
    "point for so-called diffusion Monte Carlo calculations (DMC). Diffusion Monte Carlo  is a way of\n",
    "solving exactly the many-body Schroedinger equation by means of \n",
    "a stochastic procedure. A good guess on the binding energy\n",
    "and its wave function is however necessary. \n",
    "A carefully performed VMC calculation can aid in this context. \n",
    "\n",
    "\n",
    "The basic procedure of a Variational Monte Carlo calculations consists thus of \n",
    "\n",
    "1. Construct first a trial wave function $\\psi_T(\\boldsymbol{R};\\boldsymbol{\\alpha})$,  for a many-body system consisting of $n$ particles located at positions  $\\boldsymbol{R}=(\\boldsymbol{R}_1,\\dots ,\\boldsymbol{R}_n)$. The trial wave function depends on $\\alpha$ variational parameters $\\boldsymbol{\\alpha}=(\\alpha_1,\\dots ,\\alpha_M)$.\n",
    "\n",
    "2. Then we evaluate the expectation value of the hamiltonian $H$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\overline{E}[\\boldsymbol{\\alpha}]=\\frac{\\int d\\boldsymbol{R}\\Psi^{\\ast}_{T}(\\boldsymbol{R},\\boldsymbol{\\alpha})H(\\boldsymbol{R})\\Psi_{T}(\\boldsymbol{R},\\boldsymbol{\\alpha})}\n",
    "        {\\int d\\boldsymbol{R}\\Psi^{\\ast}_{T}(\\boldsymbol{R},\\boldsymbol{\\alpha})\\Psi_{T}(\\boldsymbol{R},\\boldsymbol{\\alpha})}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Thereafter we vary $\\boldsymbol{\\alpha}$ according to some minimization algorithm and return eventually to the first step if we are not satisfied with the results.\n",
    "\n",
    "Here we have used the notation $\\overline{E}$ to label the expectation value of the energy. \n",
    "\n",
    "### Linking with standard statistical expressions for expectation values\n",
    "\n",
    "In order to bring in the Monte Carlo machinery, we define first a likelihood distribution, or probability density distribution (PDF). Using our ansatz for the trial wave function $\\psi_T(\\boldsymbol{R};\\boldsymbol{\\alpha})$ we define a PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(\\boldsymbol{R})= \\frac{\\left|\\psi_T(\\boldsymbol{R};\\boldsymbol{\\alpha})\\right|^2}{\\int \\left|\\psi_T(\\boldsymbol{R};\\boldsymbol{\\alpha})\\right|^2d\\boldsymbol{R}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our model for  probability distribution function.\n",
    "The approximation to the expectation value of the Hamiltonian is now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\overline{E}[\\boldsymbol{\\alpha}] = \n",
    "   \\frac{\\int d\\boldsymbol{R}\\Psi^{\\ast}_T(\\boldsymbol{R};\\boldsymbol{\\alpha})H(\\boldsymbol{R})\\Psi_T(\\boldsymbol{R};\\boldsymbol{\\alpha})}\n",
    "        {\\int d\\boldsymbol{R}\\Psi^{\\ast}_T(\\boldsymbol{R};\\boldsymbol{\\alpha})\\Psi_T(\\boldsymbol{R};\\boldsymbol{\\alpha})}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a new quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:locale1\"></div>\n",
    "\n",
    "$$\n",
    "E_L(\\boldsymbol{R};\\boldsymbol{\\alpha})=\\frac{1}{\\psi_T(\\boldsymbol{R};\\boldsymbol{\\alpha})}H\\psi_T(\\boldsymbol{R};\\boldsymbol{\\alpha}),\n",
    "\\label{eq:locale1} \\tag{1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "called the local energy, which, together with our trial PDF yields a new expression (and which look simlar to the the expressions for moments in statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:vmc1\"></div>\n",
    "\n",
    "$$\n",
    "\\overline{E}[\\boldsymbol{\\alpha}]=\\int P(\\boldsymbol{R})E_L(\\boldsymbol{R};\\boldsymbol{\\alpha}) d\\boldsymbol{R}\\approx \\frac{1}{N}\\sum_{i=1}^NE_L(\\boldsymbol{R_i};\\boldsymbol{\\alpha})\n",
    "\\label{eq:vmc1} \\tag{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with $N$ being the number of Monte Carlo samples. The expresion on the right hand side follows from Bernoulli's law of large numbers, which states that the sample mean, in the limit $N\\rightarrow \\infty$ approaches the true mean \n",
    "\n",
    "The Algorithm for performing a variational Monte Carlo calculations runs as this\n",
    "\n",
    "   * Initialisation: Fix the number of Monte Carlo steps. Choose an initial $\\boldsymbol{R}$ and variational parameters $\\alpha$ and calculate $\\left|\\psi_T^{\\alpha}(\\boldsymbol{R})\\right|^2$. \n",
    "\n",
    "   * Initialise the energy and the variance and start the Monte Carlo calculation.\n",
    "\n",
    "      * Calculate  a trial position  $\\boldsymbol{R}_p=\\boldsymbol{R}+r*step$ where $r$ is a random variable $r \\in [0,1]$.\n",
    "\n",
    "      * Metropolis algorithm to accept or reject this move  $w = P(\\boldsymbol{R}_p)/P(\\boldsymbol{R})$.\n",
    "\n",
    "      * If the step is accepted, then we set $\\boldsymbol{R}=\\boldsymbol{R}_p$. \n",
    "\n",
    "      * Update averages\n",
    "\n",
    "\n",
    "   * Finish and compute final averages.\n",
    "\n",
    "Observe that the jumping in space is governed by the variable *step*. This is called brute-force sampling and is normally replaced by what is called **importance sampling**, discussed in more detail below here. \n",
    "\n",
    "\n",
    "### Simple example, the hydrogen atom\n",
    "\n",
    "The radial Schroedinger equation for the hydrogen atom can be\n",
    "written as (when we have gotten rid of the first derivative term in the kinetic energy and used $rR(r)=u(r)$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "-\\frac{\\hbar^2}{2m}\\frac{d^2 u(r)}{d r^2}-\n",
    "\\left(\\frac{ke^2}{r}-\\frac{\\hbar^2l(l+1)}{2mr^2}\\right)u(r)=Eu(r).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will specialize to the case with $l=0$ and end up with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "-\\frac{\\hbar^2}{2m}\\frac{d^2 u(r)}{d r^2}-\n",
    "\\left(\\frac{ke^2}{r}\\right)u(r)=Eu(r).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we introduce a dimensionless variable $\\rho=r/a$ where $a$ is a constant with dimension length.\n",
    "Multiplying with $ma^2/\\hbar^2$ we can rewrite our equations as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "-\\frac{1}{2}\\frac{d^2 u(\\rho)}{d \\rho^2}-\n",
    "\\frac{ke^2ma}{\\hbar^2}\\frac{u(\\rho)}{\\rho}-\\lambda u(\\rho)=0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $a$ is just a parameter we choose to set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{ke^2ma}{\\hbar^2}=1,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which leads to $a=\\hbar^2/mke^2$, better known as the Bohr radius with value $0.053$ nm. Scaling the equations this way does not only render our numerical treatment simpler since we avoid carrying with us all physical parameters, but we obtain also a **natural** length scale. We will see this again and again. In our discussions below with a harmonic oscillator trap, the **natural** lentgh scale with be determined by the oscillator frequency, the mass of the particle and $\\hbar$. We have also defined a dimensionless 'energy' $\\lambda = Ema^2/\\hbar^2$. \n",
    "With the rescaled quantities, the ground state energy of the hydrogen atom is $1/2$. \n",
    "The equation we want to solve is now defined by the Hamiltonian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "H=-\\frac{1}{2}\\frac{d^2 }{d \\rho^2}-\\frac{1}{\\rho}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As trial wave function we peep now into the analytical solution for\n",
    "the hydrogen atom and use (with $\\alpha$ as a variational parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "u_T^{\\alpha}(\\rho)=\\alpha\\rho \\exp{-(\\alpha\\rho)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting this wave function into the expression for the\n",
    "local energy $E_L$ gives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "E_L(\\rho)=-\\frac{1}{\\rho}-\n",
    "              \\frac{\\alpha}{2}\\left(\\alpha-\\frac{2}{\\rho}\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have analytical local energies saves us from computing numerically\n",
    "the second derivative, a feature which often increases our numerical\n",
    "expenditure with a factor of three or more. Integratng up the local energy (recall to bring back the PDF in the integration) gives  $\\overline{E}[\\boldsymbol{\\alpha}]=\\alpha(\\alpha/2-1)$. \n",
    "\n",
    "We are now ready to write our first VMC code. We start by including\n",
    "some generic operations on where to save our outputs (data files and figures)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Where to save the figures and data files\n",
    "PROJECT_ROOT_DIR = \"Results\"\n",
    "FIGURE_ID = \"Results/FigureFiles\"\n",
    "DATA_ID = \"Results/VMCHydrogen\"\n",
    "\n",
    "if not os.path.exists(PROJECT_ROOT_DIR):\n",
    "    os.mkdir(PROJECT_ROOT_DIR)\n",
    "\n",
    "if not os.path.exists(FIGURE_ID):\n",
    "    os.makedirs(FIGURE_ID)\n",
    "\n",
    "if not os.path.exists(DATA_ID):\n",
    "    os.makedirs(DATA_ID)\n",
    "\n",
    "def image_path(fig_id):\n",
    "    return os.path.join(FIGURE_ID, fig_id)\n",
    "\n",
    "def data_path(dat_id):\n",
    "    return os.path.join(DATA_ID, dat_id)\n",
    "\n",
    "def save_fig(fig_id):\n",
    "    plt.savefig(image_path(fig_id) + \".png\", format='png')\n",
    "\n",
    "outfile = open(data_path(\"VMCHydrogen.dat\"),'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After these declarations, we are then ready to write our first VMC code.\n",
    "We write two functions for the trial wave function and the analytical expression for the local energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# VMC for the hydrogen atom\n",
    "# Brute force Metropolis, no importance sampling and no energy minimization\n",
    "from math import exp, sqrt\n",
    "from random import random, seed\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit\n",
    "\n",
    "# Trial wave function for the hydrogen atom\n",
    "def WaveFunction(r,alpha):\n",
    "    argument = np.linalg.norm(r)\n",
    "    return alpha*argument*exp(-alpha*argument)\n",
    "\n",
    "# Local energy (analytical expression) for the hydrogen atom\n",
    "def LocalEnergy(r,alpha):\n",
    "    return (1.0/np.linalg.norm(r))*(alpha-1)-alpha*alpha*0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step is to perform the Monte Carlo sampling itself and implement the Metropolis algorithm to be discussed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Monte Carlo sampling with the Metropolis algo\n",
    "# The jit decorator tells Numba to compile this function.\n",
    "# The argument types will be inferred by Numba when the function is called.\n",
    "@jit\n",
    "def MonteCarloSampling():\n",
    "\n",
    "    NumberMCcycles= 100000\n",
    "    StepSize = 1.0\n",
    "    # positions\n",
    "    PositionOld = np.zeros((Dimension), np.double)\n",
    "    PositionNew = np.zeros((Dimension), np.double)\n",
    "\n",
    "    # seed for rng generator\n",
    "    seed()\n",
    "    # start variational parameter\n",
    "    alpha = 0.85\n",
    "    for ia in range(MaxVariations):\n",
    "        alpha += .025\n",
    "        AlphaValues[ia] = alpha\n",
    "        energy = energy2 = 0.0\n",
    "        #Initial position\n",
    "        for j in range(Dimension):\n",
    "            PositionOld[j] = StepSize * (random() - .5)\n",
    "        wfold = WaveFunction(PositionOld,alpha)\n",
    "        #Loop over MC MCcycles\n",
    "        for MCcycle in range(NumberMCcycles):\n",
    "            #Trial position \n",
    "            for j in range(Dimension):\n",
    "                PositionNew[j] = PositionOld[j] + StepSize*(random() - .5)\n",
    "            wfnew = WaveFunction(PositionNew,alpha)\n",
    "            #Metropolis test to see whether we accept the move\n",
    "            if random() <= wfnew**2 / wfold**2:\n",
    "                PositionOld = PositionNew\n",
    "                wfold = wfnew\n",
    "            DeltaE = LocalEnergy(PositionOld,alpha)\n",
    "            energy += DeltaE\n",
    "            energy2 += DeltaE**2\n",
    "        #We calculate mean, variance and error\n",
    "        energy /= NumberMCcycles\n",
    "        energy2 /= NumberMCcycles\n",
    "        variance = energy2 - energy**2\n",
    "        error = sqrt(variance/NumberMCcycles)\n",
    "        Energies[ia] = energy    \n",
    "        Variances[ia] = variance    \n",
    "        outfile.write('%f %f %f %f \\n' %(alpha,energy,variance,error))\n",
    "    return Energies, AlphaValues, Variances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we perform the calculations, plot our results and compare with the analytical results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Here starts the main program with variable declarations\n",
    "NumberParticles = 1\n",
    "Dimension = 3\n",
    "MaxVariations = 10\n",
    "Energies = np.zeros((MaxVariations))\n",
    "Variances = np.zeros((MaxVariations))\n",
    "AlphaValues = np.zeros(MaxVariations)\n",
    "ExactEnergy = np.zeros((MaxVariations))\n",
    "(Energies, AlphaValues, Variances) = MonteCarloSampling()\n",
    "ExactEnergy = AlphaValues*(AlphaValues*0.5-1.)\n",
    "outfile.close()\n",
    "#simple subplot\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(AlphaValues, Energies, 'o-',AlphaValues, ExactEnergy, 'r-')\n",
    "plt.title('Energy and variance')\n",
    "plt.ylabel('Dimensionless energy')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(AlphaValues, Variances, '.-')\n",
    "plt.xlabel(r'$\\alpha$', fontsize=15)\n",
    "plt.ylabel('Variance')\n",
    "save_fig(\"VMCHydrogen\")\n",
    "plt.show()\n",
    "#nice printout with Pandas\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "data ={'Alpha':AlphaValues, 'Energy':Energies,'ExactEnergy':ExactEnergy,'Variance':Variances}\n",
    "frame = pd.DataFrame(data)\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we note that at $\\alpha=1$ we obtain the exact result,\n",
    "and the variance is zero, as it should. Comparing with the simple\n",
    "analytical formula for the energy we see that the agreement is\n",
    "excellent.\n",
    "\n",
    "The fact that the variance is exactly equal to zero when $\\alpha=1$ is that \n",
    "we then have the exact wave function, and the action of the hamiltionan\n",
    "on the wave function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "H\\psi = \\mathrm{constant}\\times \\psi,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yields just a constant. The integral which defines various \n",
    "expectation values involving moments of the hamiltonian becomes then"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\langle H^n \\rangle =\n",
    "   \\frac{\\int d\\boldsymbol{R}\\Psi^{\\ast}_T(\\boldsymbol{R})H^n(\\boldsymbol{R})\\Psi_T(\\boldsymbol{R})}\n",
    "        {\\int d\\boldsymbol{R}\\Psi^{\\ast}_T(\\boldsymbol{R})\\Psi_T(\\boldsymbol{R})}=\n",
    "\\mathrm{constant}\\times\\frac{\\int d\\boldsymbol{R}\\Psi^{\\ast}_T(\\boldsymbol{R})\\Psi_T(\\boldsymbol{R})}\n",
    "        {\\int d\\boldsymbol{R}\\Psi^{\\ast}_T(\\boldsymbol{R})\\Psi_T(\\boldsymbol{R})}=\\mathrm{constant}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This gives an important information: the exact wave function leads to zero variance!**\n",
    "As we will see below, many practitioners perform a minimization on both the energy and the variance.\n",
    "\n",
    "## The Metropolis algorithm\n",
    "\n",
    "Till now we have not yet discussed the derivation of the Metropolis algorithm. We assume the reader has some familiarity with the mathematics of Markov chains. \n",
    "\n",
    "The Metropolis algorithm , see [the original article](http://scitation.aip.org/content/aip/journal/jcp/21/6/10.1063/1.1699114), was invented by Metropolis et. al\n",
    "and is often simply called the Metropolis algorithm.\n",
    "It is a method to sample a normalized probability\n",
    "distribution by a stochastic process. We define $\\mathbf{P}_i^{(n)}$ to\n",
    "be the probability for finding the system in the state $i$ at step $n$.\n",
    "The algorithm is then\n",
    "\n",
    "* Sample a possible new state $j$ with some probability $T_{i\\rightarrow j}$.\n",
    "\n",
    "* Accept the new state $j$ with probability $A_{i \\rightarrow j}$ and use it as the next sample. With probability $1-A_{i\\rightarrow j}$ the move is rejected and the original state $i$ is used again as a sample.\n",
    "\n",
    "We wish to derive the required properties of $T$ and $A$ such that\n",
    "$\\mathbf{P}_i^{(n\\rightarrow \\infty)} \\rightarrow p_i$ so that starting\n",
    "from any distribution, the method converges to the correct distribution.\n",
    "Note that the description here is for a discrete probability distribution.\n",
    "Replacing probabilities $p_i$ with expressions like $p(x_i)dx_i$ will\n",
    "take all of these over to the corresponding continuum expressions.\n",
    "\n",
    "The dynamical equation for $\\mathbf{P}_i^{(n)}$ can be written directly from\n",
    "the description above. The probability of being in the state $i$ at step $n$\n",
    "is given by the probability of being in any state $j$ at the previous step,\n",
    "and making an accepted transition to $i$ added to the probability of\n",
    "being in the state $i$, making a transition to any state $j$ and\n",
    "rejecting the move:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{P}^{(n)}_i = \\sum_j \\left [\n",
    "\\mathbf{P}^{(n-1)}_jT_{j\\rightarrow i} A_{j\\rightarrow i} \n",
    "+\\mathbf{P}^{(n-1)}_iT_{i\\rightarrow j}\\left ( 1- A_{i\\rightarrow j} \\right)\n",
    "\\right ] \\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the probability of making some transition must be 1,\n",
    "$\\sum_j T_{i\\rightarrow j} = 1$, and the above equation becomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{P}^{(n)}_i = \\mathbf{P}^{(n-1)}_i +\n",
    " \\sum_j \\left [\n",
    "\\mathbf{P}^{(n-1)}_jT_{j\\rightarrow i} A_{j\\rightarrow i} \n",
    "-\\mathbf{P}^{(n-1)}_iT_{i\\rightarrow j}A_{i\\rightarrow j}\n",
    "\\right ] \\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For large $n$ we require that $\\mathbf{P}^{(n\\rightarrow \\infty)}_i = p_i$,\n",
    "the desired probability distribution. Taking this limit, gives the\n",
    "balance requirement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sum_j \\left [\n",
    "p_jT_{j\\rightarrow i} A_{j\\rightarrow i}\n",
    "-p_iT_{i\\rightarrow j}A_{i\\rightarrow j}\n",
    "\\right ] = 0 \\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The balance requirement is very weak. Typically the much stronger detailed\n",
    "balance requirement is enforced, that is rather than the sum being\n",
    "set to zero, we set each term separately to zero and use this\n",
    "to determine the acceptance probabilities. Rearranging, the result is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{ A_{j\\rightarrow i}}{A_{i\\rightarrow j}}\n",
    "= \\frac{p_iT_{i\\rightarrow j}}{ p_jT_{j\\rightarrow i}} \\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Metropolis choice is to maximize the $A$ values, that is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "A_{j \\rightarrow i} = \\min \\left ( 1,\n",
    "\\frac{p_iT_{i\\rightarrow j}}{ p_jT_{j\\rightarrow i}}\\right ).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other choices are possible, but they all correspond to multilplying\n",
    "$A_{i\\rightarrow j}$ and $A_{j\\rightarrow i}$ by the same constant\n",
    "smaller than unity.\\footnote{The penalty function method uses just such\n",
    "a factor to compensate for $p_i$ that are evaluated stochastically\n",
    "and are therefore noisy.}\n",
    "\n",
    "Having chosen the acceptance probabilities, we have guaranteed that\n",
    "if the  $\\mathbf{P}_i^{(n)}$ has equilibrated, that is if it is equal to $p_i$,\n",
    "it will remain equilibrated. Next we need to find the circumstances for\n",
    "convergence to equilibrium.\n",
    "\n",
    "The dynamical equation can be written as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{P}^{(n)}_i = \\sum_j M_{ij}\\mathbf{P}^{(n-1)}_j\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with the matrix $M$ given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "M_{ij} = \\delta_{ij}\\left [ 1 -\\sum_k T_{i\\rightarrow k} A_{i \\rightarrow k}\n",
    "\\right ] + T_{j\\rightarrow i} A_{j\\rightarrow i} \\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summing over $i$ shows that $\\sum_i M_{ij} = 1$, and since\n",
    "$\\sum_k T_{i\\rightarrow k} = 1$, and $A_{i \\rightarrow k} \\leq 1$, the\n",
    "elements of the matrix satisfy $M_{ij} \\geq 0$. The matrix $M$ is therefore\n",
    "a stochastic matrix.\n",
    "\n",
    "\n",
    "The Metropolis method is simply the power method for computing the\n",
    "right eigenvector of $M$ with the largest magnitude eigenvalue.\n",
    "By construction, the correct probability distribution is a right eigenvector\n",
    "with eigenvalue 1. Therefore, for the Metropolis method to converge\n",
    "to this result, we must show that $M$ has only one eigenvalue with this\n",
    "magnitude, and all other eigenvalues are smaller.\n",
    "\n",
    "\n",
    "## The system: two electrons in a harmonic oscillator trap in two dimensions\n",
    "\n",
    "The Hamiltonian of the quantum dot is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{H} = \\hat{H}_0 + \\hat{V},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\hat{H}_0$ is the many-body HO Hamiltonian, and $\\hat{V}$ is the\n",
    "inter-electron Coulomb interactions. In dimensionless units,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{V}= \\sum_{i < j}^N \\frac{1}{r_{ij}},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with $r_{ij}=\\sqrt{\\mathbf{r}_i^2 - \\mathbf{r}_j^2}$.\n",
    "\n",
    "This leads to the  separable Hamiltonian, with the relative motion part given by ($r_{ij}=r$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{H}_r=-\\nabla^2_r + \\frac{1}{4}\\omega^2r^2+ \\frac{1}{r},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plus a standard Harmonic Oscillator problem  for the center-of-mass motion.\n",
    "This system has analytical solutions in two and three dimensions ([M. Taut 1993 and 1994](https://journals.aps.org/pra/abstract/10.1103/PhysRevA.48.3561)). \n",
    "\n",
    "We want to perform  a Variational Monte Carlo calculation of the ground state of two electrons in a quantum dot well with different oscillator energies, assuming total spin $S=0$.\n",
    "Our trial wave function has the following form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:trial\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "   \\psi_{T}(\\boldsymbol{r}_1,\\boldsymbol{r}_2) = \n",
    "   C\\exp{\\left(-\\alpha_1\\omega(r_1^2+r_2^2)/2\\right)}\n",
    "   \\exp{\\left(\\frac{r_{12}}{(1+\\alpha_2 r_{12})}\\right)}, \n",
    "\\label{eq:trial} \\tag{3}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the $\\alpha$s represent our variational parameters, two in this case.\n",
    "\n",
    "Why does the trial function look like this? How did we get there?\n",
    "**This will be one of our main motivations** for switching to Machine Learning later.\n",
    "\n",
    "\n",
    "To find an ansatz for the correlated part of the wave function, it is\n",
    "useful to rewrite the two-particle local energy in terms of the\n",
    "relative and center-of-mass motion.  \n",
    "Let us denote the distance\n",
    "between the two electrons as $r_{12}$. We omit the center-of-mass\n",
    "motion since we are only interested in the case when $r_{12}\n",
    "\\rightarrow 0$. The contribution from the center-of-mass (CoM)\n",
    "variable $\\boldsymbol{R}_{\\mathrm{CoM}}$ gives only a finite contribution.  We\n",
    "focus only on the terms that are relevant for $r_{12}$ and for three\n",
    "dimensions. \n",
    "\n",
    "The relevant local energy becomes then"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\lim_{r_{12} \\rightarrow 0}E_L(R)= \\frac{1}{{\\calR}_T(r_{12})}\\left(2\\frac{d^2}{dr_{ij}^2}+\\frac{4}{r_{ij}}\\frac{d}{dr_{ij}}+\\frac{2}{r_{ij}}-\\frac{l(l+1)}{r_{ij}^2}+2E \\right){\\cal R}_T(r_{12})\n",
    "= 0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set $l=0$ and we have the so-called **cusp** condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{d {\\cal R}_T(r_{12})}{dr_{12}} = -\\frac{1}{2(l+1)} {\\cal R}_T(r_{12})\\qquad r_{12}\\to 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above  results in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "{\\cal R}_T  \\propto \\exp{(r_{ij}/2)},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for anti-parallel spins and"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "{\\cal R}_T  \\propto \\exp{(r_{ij}/4)},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for anti-parallel spins. \n",
    "This is the so-called cusp condition for the relative motion, resulting in a minimal requirement\n",
    "for the correlation part of the wave fuction.\n",
    "For general systems containing more than say two electrons, we have this\n",
    "condition for each electron pair $ij$.\n",
    "\n",
    "### First code attempt for the two-electron case\n",
    "\n",
    "First, as with the hydrogen case, we declare where to store files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import os\n",
    "\n",
    "# Where to save the figures and data files\n",
    "PROJECT_ROOT_DIR = \"Results\"\n",
    "FIGURE_ID = \"Results/FigureFiles\"\n",
    "DATA_ID = \"Results/VMCQdotMetropolis\"\n",
    "\n",
    "if not os.path.exists(PROJECT_ROOT_DIR):\n",
    "    os.mkdir(PROJECT_ROOT_DIR)\n",
    "\n",
    "if not os.path.exists(FIGURE_ID):\n",
    "    os.makedirs(FIGURE_ID)\n",
    "\n",
    "if not os.path.exists(DATA_ID):\n",
    "    os.makedirs(DATA_ID)\n",
    "\n",
    "def image_path(fig_id):\n",
    "    return os.path.join(FIGURE_ID, fig_id)\n",
    "\n",
    "def data_path(dat_id):\n",
    "    return os.path.join(DATA_ID, dat_id)\n",
    "\n",
    "def save_fig(fig_id):\n",
    "    plt.savefig(image_path(fig_id) + \".png\", format='png')\n",
    "\n",
    "outfile = open(data_path(\"VMCQdotMetropolis.dat\"),'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thereafter we set up the analytical expressions for the wave functions and the local energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-electron VMC for quantum dot system in two dimensions\n",
    "# Brute force Metropolis, no importance sampling and no energy minimization\n",
    "from math import exp, sqrt\n",
    "from random import random, seed\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import sys\n",
    "from numba import jit\n",
    "\n",
    "\n",
    "# Trial wave function for the 2-electron quantum dot in two dims\n",
    "def WaveFunction(r,alpha,beta):\n",
    "    r1 = r[0,0]**2 + r[0,1]**2\n",
    "    r2 = r[1,0]**2 + r[1,1]**2\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = r12/(1+beta*r12)\n",
    "    return exp(-0.5*alpha*(r1+r2)+deno)\n",
    "\n",
    "# Local energy  for the 2-electron quantum dot in two dims, using analytical local energy\n",
    "def LocalEnergy(r,alpha,beta):\n",
    "    \n",
    "    r1 = (r[0,0]**2 + r[0,1]**2)\n",
    "    r2 = (r[1,0]**2 + r[1,1]**2)\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = 1.0/(1+beta*r12)\n",
    "    deno2 = deno*deno\n",
    "    return 0.5*(1-alpha*alpha)*(r1 + r2) +2.0*alpha + 1.0/r12+deno2*(alpha*r12-deno2+2*beta*deno-1.0/r12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Monte Carlo sampling without importance sampling is set up here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Monte Carlo sampling with the Metropolis algo\n",
    "# The jit decorator tells Numba to compile this function.\n",
    "# The argument types will be inferred by Numba when the function is called.\n",
    "@jit\n",
    "def MonteCarloSampling():\n",
    "\n",
    "    NumberMCcycles= 10000\n",
    "    StepSize = 1.0\n",
    "    # positions\n",
    "    PositionOld = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    PositionNew = np.zeros((NumberParticles,Dimension), np.double)\n",
    "\n",
    "    # seed for rng generator\n",
    "    seed()\n",
    "    # start variational parameter\n",
    "    alpha = 0.9\n",
    "    for ia in range(MaxVariations):\n",
    "        alpha += .025\n",
    "        AlphaValues[ia] = alpha\n",
    "        beta = 0.2 \n",
    "        for jb in range(MaxVariations):\n",
    "            beta += .01\n",
    "            BetaValues[jb] = beta\n",
    "            energy = energy2 = 0.0\n",
    "            DeltaE = 0.0\n",
    "            #Initial position\n",
    "            for i in range(NumberParticles):\n",
    "                for j in range(Dimension):\n",
    "                    PositionOld[i,j] = StepSize * (random() - .5)\n",
    "            wfold = WaveFunction(PositionOld,alpha,beta)\n",
    "\n",
    "            #Loop over MC MCcycles\n",
    "            for MCcycle in range(NumberMCcycles):\n",
    "                #Trial position moving one particle at the time\n",
    "                for i in range(NumberParticles):\n",
    "                    for j in range(Dimension):\n",
    "                        PositionNew[i,j] = PositionOld[i,j] + StepSize * (random() - .5)\n",
    "                    wfnew = WaveFunction(PositionNew,alpha,beta)\n",
    "\n",
    "                    #Metropolis test to see whether we accept the move\n",
    "                    if random() < wfnew**2 / wfold**2:\n",
    "                       for j in range(Dimension):\n",
    "                           PositionOld[i,j] = PositionNew[i,j]\n",
    "                       wfold = wfnew\n",
    "                DeltaE = LocalEnergy(PositionOld,alpha,beta)\n",
    "                energy += DeltaE\n",
    "                energy2 += DeltaE**2\n",
    "            #We calculate mean, variance and error ...\n",
    "            energy /= NumberMCcycles\n",
    "            energy2 /= NumberMCcycles\n",
    "            variance = energy2 - energy**2\n",
    "            error = sqrt(variance/NumberMCcycles)\n",
    "            Energies[ia,jb] = energy    \n",
    "            Variances[ia,jb] = variance    \n",
    "            outfile.write('%f %f %f %f %f\\n' %(alpha,beta,energy,variance,error))\n",
    "    return Energies, Variances, AlphaValues, BetaValues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally comes the main part with the plots as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here starts the main program with variable declarations\n",
    "NumberParticles = 2\n",
    "Dimension = 2\n",
    "MaxVariations = 10\n",
    "Energies = np.zeros((MaxVariations,MaxVariations))\n",
    "Variances = np.zeros((MaxVariations,MaxVariations))\n",
    "AlphaValues = np.zeros(MaxVariations)\n",
    "BetaValues = np.zeros(MaxVariations)\n",
    "(Energies, Variances, AlphaValues, BetaValues) = MonteCarloSampling()\n",
    "outfile.close()\n",
    "\n",
    "# Prepare for plots\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "# Plot the surface.\n",
    "X, Y = np.meshgrid(AlphaValues, BetaValues)\n",
    "surf = ax.plot_surface(X, Y, Energies,cmap=cm.coolwarm,linewidth=0, antialiased=False)\n",
    "# Customize the z axis.\n",
    "zmin = np.matrix(Energies).min()\n",
    "zmax = np.matrix(Energies).max()\n",
    "ax.set_zlim(zmin, zmax)\n",
    "ax.set_xlabel(r'$\\alpha$')\n",
    "ax.set_ylabel(r'$\\beta$')\n",
    "ax.set_zlabel(r'$\\langle E \\rangle$')\n",
    "ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "# Add a color bar which maps values to colors.\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "save_fig(\"QdotMetropolis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance sampling\n",
    "\n",
    "The above way of performing a Monte Carlo calculation is not the most efficient one. \n",
    "We need to replace the brute force Metropolis algorithm with a walk in\n",
    "coordinate space biased by the trial wave function.  This approach is\n",
    "based on the Fokker-Planck equation and the Langevin equation for\n",
    "generating a trajectory in coordinate space.  The link between the\n",
    "Fokker-Planck equation and the Langevin equations are explained, only\n",
    "partly, in the slides below.  An excellent reference on topics like\n",
    "Brownian motion, Markov chains, the Fokker-Planck equation and the\n",
    "Langevin equation is the text by [Van Kampen](http://www.elsevier.com/books/stochastic-processes-in-physics-and-chemistry/van-kampen/978-0-444-52965-7)\n",
    "Here we will focus first on the implementation part first.\n",
    "\n",
    "For a diffusion process characterized by a time-dependent probability density $P(x,t)$ in one dimension the Fokker-Planck\n",
    "equation reads (for one particle /walker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial P}{\\partial t} = D\\frac{\\partial }{\\partial x}\\left(\\frac{\\partial }{\\partial x} -F\\right)P(x,t),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $F$ is a drift term and $D$ is the diffusion coefficient. \n",
    "\n",
    "\n",
    "The new positions in coordinate space are given as the solutions of the Langevin equation using Euler's method, namely,\n",
    "we go from the Langevin equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial x(t)}{\\partial t} = DF(x(t)) +\\eta,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with $\\eta$ a random variable,\n",
    "yielding a new position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y = x+DF(x)\\Delta t +\\xi\\sqrt{\\Delta t},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\xi$ is gaussian random variable and $\\Delta t$ is a chosen time step. \n",
    "The quantity $D$ is, in atomic units, equal to $1/2$ and comes from the factor $1/2$ in the kinetic energy operator. Note that $\\Delta t$ is to be viewed as a parameter. Values of $\\Delta t \\in [0.001,0.01]$ yield in general rather stable values of the ground state energy.  \n",
    "\n",
    "The process of isotropic diffusion characterized by a time-dependent probability density $P(\\mathbf{x},t)$ obeys (as an approximation) the so-called Fokker-Planck equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial P}{\\partial t} = \\sum_i D\\frac{\\partial }{\\partial \\mathbf{x_i}}\\left(\\frac{\\partial }{\\partial \\mathbf{x_i}} -\\mathbf{F_i}\\right)P(\\mathbf{x},t),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\mathbf{F_i}$ is the $i^{th}$ component of the drift term (drift velocity) caused by an external potential, and $D$ is the diffusion coefficient. The convergence to a stationary probability density can be obtained by setting the left hand side to zero. The resulting equation will be satisfied if and only if all the terms of the sum are equal zero,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial^2 P}{\\partial {\\mathbf{x_i}^2}} = P\\frac{\\partial}{\\partial {\\mathbf{x_i}}}\\mathbf{F_i} + \\mathbf{F_i}\\frac{\\partial}{\\partial {\\mathbf{x_i}}}P.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The drift vector should be of the form $\\mathbf{F} = g(\\mathbf{x}) \\frac{\\partial P}{\\partial \\mathbf{x}}$. Then,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial^2 P}{\\partial {\\mathbf{x_i}^2}} = P\\frac{\\partial g}{\\partial P}\\left( \\frac{\\partial P}{\\partial {\\mathbf{x}_i}}  \\right)^2 + P g \\frac{\\partial ^2 P}{\\partial {\\mathbf{x}_i^2}}  + g \\left( \\frac{\\partial P}{\\partial {\\mathbf{x}_i}}  \\right)^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The condition of stationary density means that the left hand side equals zero. In other words, the terms containing first and second derivatives have to cancel each other. It is possible only if $g = \\frac{1}{P}$, which yields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{F} = 2\\frac{1}{\\Psi_T}\\nabla\\Psi_T,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is known as the so-called *quantum force*. This term is responsible for pushing the walker towards regions of configuration space where the trial wave function is large, increasing the efficiency of the simulation in contrast to the Metropolis algorithm where the walker has the same probability of moving in every direction.\n",
    "\n",
    "The Fokker-Planck equation yields a (the solution to the equation) transition probability given by the Green's function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "G(y,x,\\Delta t) = \\frac{1}{(4\\pi D\\Delta t)^{3N/2}} \\exp{\\left(-(y-x-D\\Delta t F(x))^2/4D\\Delta t\\right)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which in turn means that our brute force Metropolis algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "A(y,x) = \\mathrm{min}(1,q(y,x))),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with $q(y,x) = |\\Psi_T(y)|^2/|\\Psi_T(x)|^2$ is now replaced by the [Metropolis-Hastings algorithm](http://scitation.aip.org/content/aip/journal/jcp/21/6/10.1063/1.1699114). See also  [Hasting's original article](http://biomet.oxfordjournals.org/content/57/1/97.abstract),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "q(y,x) = \\frac{G(x,y,\\Delta t)|\\Psi_T(y)|^2}{G(y,x,\\Delta t)|\\Psi_T(x)|^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code example for the interacting case with importance sampling\n",
    "\n",
    "We are now ready to implement importance sampling. This is done here for the two-electron case with the Coulomb interaction, as in the previous example. We have two variational parameters $\\alpha$ and $\\beta$. After the set up of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import os\n",
    "\n",
    "# Where to save the figures and data files\n",
    "PROJECT_ROOT_DIR = \"Results\"\n",
    "FIGURE_ID = \"Results/FigureFiles\"\n",
    "DATA_ID = \"Results/VMCQdotImportance\"\n",
    "\n",
    "if not os.path.exists(PROJECT_ROOT_DIR):\n",
    "    os.mkdir(PROJECT_ROOT_DIR)\n",
    "\n",
    "if not os.path.exists(FIGURE_ID):\n",
    "    os.makedirs(FIGURE_ID)\n",
    "\n",
    "if not os.path.exists(DATA_ID):\n",
    "    os.makedirs(DATA_ID)\n",
    "\n",
    "def image_path(fig_id):\n",
    "    return os.path.join(FIGURE_ID, fig_id)\n",
    "\n",
    "def data_path(dat_id):\n",
    "    return os.path.join(DATA_ID, dat_id)\n",
    "\n",
    "def save_fig(fig_id):\n",
    "    plt.savefig(image_path(fig_id) + \".png\", format='png')\n",
    "\n",
    "outfile = open(data_path(\"VMCQdotImportance.dat\"),'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we move on to the set up of the trial wave function, the analytical expression for the local energy and the analytical expression for the quantum force."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-electron VMC code for 2dim quantum dot with importance sampling\n",
    "# Using gaussian rng for new positions and Metropolis- Hastings \n",
    "# No energy minimization\n",
    "from math import exp, sqrt\n",
    "from random import random, seed, normalvariate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import sys\n",
    "from numba import jit,njit\n",
    "\n",
    "\n",
    "# Trial wave function for the 2-electron quantum dot in two dims\n",
    "def WaveFunction(r,alpha,beta):\n",
    "    r1 = r[0,0]**2 + r[0,1]**2\n",
    "    r2 = r[1,0]**2 + r[1,1]**2\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = r12/(1+beta*r12)\n",
    "    return exp(-0.5*alpha*(r1+r2)+deno)\n",
    "\n",
    "# Local energy  for the 2-electron quantum dot in two dims, using analytical local energy\n",
    "def LocalEnergy(r,alpha,beta):\n",
    "    \n",
    "    r1 = (r[0,0]**2 + r[0,1]**2)\n",
    "    r2 = (r[1,0]**2 + r[1,1]**2)\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = 1.0/(1+beta*r12)\n",
    "    deno2 = deno*deno\n",
    "    return 0.5*(1-alpha*alpha)*(r1 + r2) +2.0*alpha + 1.0/r12+deno2*(alpha*r12-deno2+2*beta*deno-1.0/r12)\n",
    "\n",
    "# Setting up the quantum force for the two-electron quantum dot, recall that it is a vector\n",
    "def QuantumForce(r,alpha,beta):\n",
    "\n",
    "    qforce = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = 1.0/(1+beta*r12)\n",
    "    qforce[0,:] = -2*r[0,:]*alpha*(r[0,:]-r[1,:])*deno*deno/r12\n",
    "    qforce[1,:] = -2*r[1,:]*alpha*(r[1,:]-r[0,:])*deno*deno/r12\n",
    "    return qforce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Monte Carlo sampling includes now the Metropolis-Hastings algorithm, with the additional complication of having to evaluate the **quantum force** and the Green's function which is the solution of the Fokker-Planck equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Monte Carlo sampling with the Metropolis algo\n",
    "# jit decorator tells Numba to compile this function.\n",
    "# The argument types will be inferred by Numba when function is called.\n",
    "@jit()\n",
    "def MonteCarloSampling():\n",
    "\n",
    "    NumberMCcycles= 100000\n",
    "    # Parameters in the Fokker-Planck simulation of the quantum force\n",
    "    D = 0.5\n",
    "    TimeStep = 0.05\n",
    "    # positions\n",
    "    PositionOld = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    PositionNew = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    # Quantum force\n",
    "    QuantumForceOld = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    QuantumForceNew = np.zeros((NumberParticles,Dimension), np.double)\n",
    "\n",
    "    # seed for rng generator \n",
    "    seed()\n",
    "    # start variational parameter  loops, two parameters here\n",
    "    alpha = 0.9\n",
    "    for ia in range(MaxVariations):\n",
    "        alpha += .025\n",
    "        AlphaValues[ia] = alpha\n",
    "        beta = 0.2 \n",
    "        for jb in range(MaxVariations):\n",
    "            beta += .01\n",
    "            BetaValues[jb] = beta\n",
    "            energy = energy2 = 0.0\n",
    "            DeltaE = 0.0\n",
    "            #Initial position\n",
    "            for i in range(NumberParticles):\n",
    "                for j in range(Dimension):\n",
    "                    PositionOld[i,j] = normalvariate(0.0,1.0)*sqrt(TimeStep)\n",
    "            wfold = WaveFunction(PositionOld,alpha,beta)\n",
    "            QuantumForceOld = QuantumForce(PositionOld,alpha, beta)\n",
    "\n",
    "            #Loop over MC MCcycles\n",
    "            for MCcycle in range(NumberMCcycles):\n",
    "                #Trial position moving one particle at the time\n",
    "                for i in range(NumberParticles):\n",
    "                    for j in range(Dimension):\n",
    "                        PositionNew[i,j] = PositionOld[i,j]+normalvariate(0.0,1.0)*sqrt(TimeStep)+\\\n",
    "                                           QuantumForceOld[i,j]*TimeStep*D\n",
    "                    wfnew = WaveFunction(PositionNew,alpha,beta)\n",
    "                    QuantumForceNew = QuantumForce(PositionNew,alpha, beta)\n",
    "                    GreensFunction = 0.0\n",
    "                    for j in range(Dimension):\n",
    "                        GreensFunction += 0.5*(QuantumForceOld[i,j]+QuantumForceNew[i,j])*\\\n",
    "\t                              (D*TimeStep*0.5*(QuantumForceOld[i,j]-QuantumForceNew[i,j])-\\\n",
    "                                      PositionNew[i,j]+PositionOld[i,j])\n",
    "      \n",
    "                    GreensFunction = exp(GreensFunction)\n",
    "                    ProbabilityRatio = GreensFunction*wfnew**2/wfold**2\n",
    "                    #Metropolis-Hastings test to see whether we accept the move\n",
    "                    if random() <= ProbabilityRatio:\n",
    "                       for j in range(Dimension):\n",
    "                           PositionOld[i,j] = PositionNew[i,j]\n",
    "                           QuantumForceOld[i,j] = QuantumForceNew[i,j]\n",
    "                       wfold = wfnew\n",
    "                DeltaE = LocalEnergy(PositionOld,alpha,beta)\n",
    "                energy += DeltaE\n",
    "                energy2 += DeltaE**2\n",
    "            # We calculate mean, variance and error (no blocking applied)\n",
    "            energy /= NumberMCcycles\n",
    "            energy2 /= NumberMCcycles\n",
    "            variance = energy2 - energy**2\n",
    "            error = sqrt(variance/NumberMCcycles)\n",
    "            Energies[ia,jb] = energy    \n",
    "            outfile.write('%f %f %f %f %f\\n' %(alpha,beta,energy,variance,error))\n",
    "    return Energies, AlphaValues, BetaValues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main part here contains the setup of the variational parameters, the energies and the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here starts the main program with variable declarations\n",
    "NumberParticles = 2\n",
    "Dimension = 2\n",
    "MaxVariations = 10\n",
    "Energies = np.zeros((MaxVariations,MaxVariations))\n",
    "AlphaValues = np.zeros(MaxVariations)\n",
    "BetaValues = np.zeros(MaxVariations)\n",
    "(Energies, AlphaValues, BetaValues) = MonteCarloSampling()\n",
    "outfile.close()\n",
    "# Prepare for plots\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "# Plot the surface.\n",
    "X, Y = np.meshgrid(AlphaValues, BetaValues)\n",
    "surf = ax.plot_surface(X, Y, Energies,cmap=cm.coolwarm,linewidth=0, antialiased=False)\n",
    "# Customize the z axis.\n",
    "zmin = np.matrix(Energies).min()\n",
    "zmax = np.matrix(Energies).max()\n",
    "ax.set_zlim(zmin, zmax)\n",
    "ax.set_xlabel(r'$\\alpha$')\n",
    "ax.set_ylabel(r'$\\beta$')\n",
    "ax.set_zlabel(r'$\\langle E \\rangle$')\n",
    "ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "# Add a color bar which maps values to colors.\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "save_fig(\"QdotImportance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical aspects, improvements and how to define the cost function\n",
    "\n",
    "The above procedure is also not the smartest one. Looping over all\n",
    "variational parameters becomes expensive and we see from the previous\n",
    "plot that the surface is not very smooth, indicating that we need many more\n",
    "Monte Carlo cycles in order to reliably define an energy minimum. \n",
    "\n",
    "What we can do however is to perform some preliminary calculations\n",
    "with selected variational parameters (normally with less Monte Carlo\n",
    "cycles than those used in a full production calculation). For every\n",
    "step we evaluate the derivatives of the energy as functions of the\n",
    "variational parameters. When the derivatives disappear we have\n",
    "hopefully reached the global minimum.\n",
    "\n",
    "At this point we have the optimal variational parameters and can start\n",
    "our large-scale production run.  To find the optimal parameters\n",
    "entails the computation of the gradients of the energy and\n",
    "optimization algorithms like various **gradient descent** methods.\n",
    "This is an art by itself and is discussed for example in [our lectures on optimization methods](http://compphysics.github.io/ComputationalPhysics2/doc/pub/cg/html/cg.html). We refer the reader to these notes for more details.\n",
    "\n",
    "This part allows us also to link with the true working horse of every\n",
    "Machine Learning algorithm, namely the optimization part. This\n",
    "normally involves one of the stochastic gradient descent algorithms\n",
    "discussed in the above lecture notes. We will come back to these topics in the second notebook. \n",
    "\n",
    "In order to apply these optmization algortihms we anticipate partly what is to come in notebook 2 on\n",
    "Boltzmann machines. Our cost (or loss) function is here given by the\n",
    "expectation value of the energy as function of the variational\n",
    "parameters.\n",
    "\n",
    "To find the derivatives of the local energy expectation value as\n",
    "function of the variational parameters, we can use the chain rule and\n",
    "the hermiticity of the Hamiltonian.\n",
    "\n",
    "Let us define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\bar{E}_{\\alpha_i}=\\frac{d\\langle  E_L\\rangle}{d\\alpha_i}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as the derivative of the energy with respect to the variational parameter $\\alpha_i$\n",
    "We define also the derivative of the trial function (skipping the subindex $T$) as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\bar{\\Psi}_{i}=\\frac{d\\Psi}{d\\alpha_i}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elements of the gradient of the local energy are then (using the\n",
    "chain rule and the hermiticity of the Hamiltonian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\bar{E}_{i}=\n",
    "2\\left( \\langle \\frac{\\bar{\\Psi}_{i}}{\\Psi}E_L\\rangle -\\langle\n",
    "\\frac{\\bar{\\Psi}_{i}}{\\Psi}\\rangle\\langle E_L \\rangle\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a computational point of view it means that we need to compute\n",
    "the expectation values of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\langle\n",
    "\\frac{\\bar{\\Psi}_{i}}{\\Psi}E_L\\rangle,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\langle\n",
    "\\frac{\\bar{\\Psi}_{i}}{\\Psi}\\rangle\\langle E_L\\rangle\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These integrals are evaluted using MC intergration (with all its possible\n",
    "error sources).  We can then use methods like stochastic gradient or\n",
    "other minimization methods to find the optimal variational parameters\n",
    "\n",
    "\n",
    "\n",
    "As an alternative to the energy as cost function, we could use the variance as the cost function.\n",
    "As discussed earlier, if we have the exact wave function, the variance is exactly equal to zero.\n",
    "Suppose the trial function (our model) is the exact wave function. \n",
    "\n",
    "The variance is defined as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sigma_E = \\langle E^2\\rangle - \\langle E\\rangle^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some practitioners perform Monte Carlo calculations by minimizing both the energy and the variance.\n",
    "\n",
    "In order to minimize the variance we need the derivatives of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sigma_E = \\langle E^2\\rangle - \\langle E\\rangle^2,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with respect to the variational parameters. The derivatives of the variance can then be used to defined the\n",
    "so-called Hessian matrix, which in turn allows us to use minimization methods like Newton's method or \n",
    "standard gradient methods. \n",
    "\n",
    "This leads to however a more complicated expression, with obvious errors when evaluating many more integrals by Monte Carlo integration. It is normally less used, see however [Filippi and Umrigar](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.94.150201). The expression becomes complicated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\bar{E}_{ij} = 2\\left[ \\langle (\\frac{\\bar{\\Psi}_{ij}}{\\Psi}+\\frac{\\bar{\\Psi}_{j}}{\\Psi}\\frac{\\bar{\\Psi}_{i}}{\\Psi})(E_L-\\langle E\\rangle)\\rangle -\\langle \\frac{\\bar{\\Psi}_{i}}{\\Psi}\\rangle\\bar{E}_j-\\langle \\frac{\\bar{\\Psi}_{j}}{\\Psi}\\rangle\\bar{E}_i\\right] +\\langle \\frac{\\bar{\\Psi}_{i}}{\\Psi}E_L{_j}\\rangle +\\langle \\frac{\\bar{\\Psi}_{j}}{\\Psi}E_L{_i}\\rangle -\\langle \\frac{\\bar{\\Psi}_{i}}{\\Psi}\\rangle\\langle E_L{_j}\\rangle \\langle \\frac{\\bar{\\Psi}_{j}}{\\Psi}\\rangle\\langle E_L{_i}\\rangle.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the cost function means having to evaluate the above second derivative of the energy. \n",
    "\n",
    "Before we proceed with code examples, let us look at some simple examples, here the one-particle harmonic oscillator in one dimension. This serves as a very useful check when developing a code. The first code discussed is the two-dimensional non-interacting harmonic oscillator. \n",
    "\n",
    "### Simple example\n",
    "\n",
    "Let us illustrate what is needed in our calculations using a simple\n",
    "example, the harmonic oscillator in one dimension.  For the harmonic\n",
    "oscillator in one-dimension we have a trial wave function and\n",
    "probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\psi_T(x) = e^{-\\alpha^2 x^2} \\qquad P_T(x)dx = \\frac{e^{-2\\alpha^2 x^2}dx}{\\int dx e^{-2\\alpha^2 x^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with $\\alpha$ being the variational parameter. \n",
    "We obtain then the following local energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "E_L[\\alpha] = \\alpha^2+x^2\\left(\\frac{1}{2}-2\\alpha^2\\right),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which results in the expectation value for the local energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\langle  E_L[\\alpha]\\rangle = \\frac{1}{2}\\alpha^2+\\frac{1}{8\\alpha^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivative of the energy with respect to $\\alpha$ gives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{d\\langle  E_L[\\alpha]\\rangle}{d\\alpha} = \\alpha-\\frac{1}{4\\alpha^3}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and a second derivative which is always positive (meaning that we find a minimum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{d^2\\langle  E_L[\\alpha]\\rangle}{d\\alpha^2} = 1+\\frac{3}{4\\alpha^4}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{d\\langle  E_L[\\alpha]\\rangle}{d\\alpha} = 0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gives the optimal $\\alpha=1/\\sqrt{2}$, as expected.\n",
    "\n",
    "We can also minimize the variance. In our simple model the variance is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sigma^2[\\alpha] = \\frac{1}{2}\\alpha^4-\\frac{1}{4}+\\frac{1}{32\\alpha^4},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with first derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{d \\sigma^2[\\alpha]}{d\\alpha} = 2\\alpha^3-\\frac{1}{8\\alpha^5}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and a second derivative which is always positive (as expected for a convex function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{d^2\\sigma^2[\\alpha]}{d\\alpha^2} = 6\\alpha^2+\\frac{5}{8\\alpha^6}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general we end up computing the expectation value of the energy in\n",
    "terms of some parameters $\\alpha_0,\\alpha_1,\\dots,\\alpha_n$ and we\n",
    "search for a minimum in this multi-variable parameter space.  This\n",
    "leads to an energy minimization problem *where we need the derivative\n",
    "of the energy as a function of the variational parameters*.\n",
    "\n",
    "In the above example this was easy and we were able to find the\n",
    "expression for the derivative by simple derivations.  However, in our\n",
    "actual calculations the energy is represented by a multi-dimensional\n",
    "integral with several variational parameters.\n",
    "\n",
    "### Finding the minima\n",
    "\n",
    "Perhaps the most celebrated of all one-dimensional root-finding\n",
    "routines is Newton's method, also called the Newton-Raphson\n",
    "method. This method  requires the evaluation of both the\n",
    "function $f$ and its derivative $f'$ at arbitrary points. \n",
    "If you can only calculate the derivative\n",
    "numerically and/or your function is not of the smooth type, we\n",
    "normally discourage the use of this method.\n",
    "\n",
    "The Newton-Raphson formula consists geometrically of extending the\n",
    "tangent line at a current point until it crosses zero, then setting\n",
    "the next guess to the abscissa of that zero-crossing.  The mathematics\n",
    "behind this method is rather simple. Employing a Taylor expansion for\n",
    "$x$ sufficiently close to the solution $s$, we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:taylornr\"></div>\n",
    "\n",
    "$$\n",
    "f(s)=0=f(x)+(s-x)f'(x)+\\frac{(s-x)^2}{2}f''(x) +\\dots.\n",
    "    \\label{eq:taylornr} \\tag{4}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For small enough values of the function and for well-behaved\n",
    "functions, the terms beyond linear are unimportant, hence we obtain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x)+(s-x)f'(x)\\approx 0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yielding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "s\\approx x-\\frac{f(x)}{f'(x)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having in mind an iterative procedure, it is natural to start iterating with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "x_{n+1}=x_n-\\frac{f(x_n)}{f'(x_n)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is Newton-Raphson's method. It has a simple geometric\n",
    "interpretation, namely $x_{n+1}$ is the point where the tangent from\n",
    "$(x_n,f(x_n))$ crosses the $x$-axis.  Close to the solution,\n",
    "Newton-Raphson converges fast to the desired result. However, if we\n",
    "are far from a root, where the higher-order terms in the series are\n",
    "important, the Newton-Raphson formula can give grossly inaccurate\n",
    "results. For instance, the initial guess for the root might be so far\n",
    "from the true root as to let the search interval include a local\n",
    "maximum or minimum of the function.  If an iteration places a trial\n",
    "guess near such a local extremum, so that the first derivative nearly\n",
    "vanishes, then Newton-Raphson may fail totally\n",
    "\n",
    "Newton's method can be generalized to systems of several non-linear equations\n",
    "and variables. Consider the case with two equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{cc} f_1(x_1,x_2) &=0\\\\\n",
    "                     f_2(x_1,x_2) &=0,\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which we Taylor expand to obtain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{cc} 0=f_1(x_1+h_1,x_2+h_2)=&f_1(x_1,x_2)+h_1\n",
    "                     \\partial f_1/\\partial x_1+h_2\n",
    "                     \\partial f_1/\\partial x_2+\\dots\\\\\n",
    "                     0=f_2(x_1+h_1,x_2+h_2)=&f_2(x_1,x_2)+h_1\n",
    "                     \\partial f_2/\\partial x_1+h_2\n",
    "                     \\partial f_2/\\partial x_2+\\dots\n",
    "                       \\end{array}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the Jacobian matrix $\\hat{J}$ we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{J}=\\left( \\begin{array}{cc}\n",
    "                         \\partial f_1/\\partial x_1  & \\partial f_1/\\partial x_2 \\\\\n",
    "                          \\partial f_2/\\partial x_1     &\\partial f_2/\\partial x_2\n",
    "             \\end{array} \\right),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can rephrase Newton's method as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\left(\\begin{array}{c} x_1^{n+1} \\\\ x_2^{n+1} \\end{array} \\right)=\n",
    "\\left(\\begin{array}{c} x_1^{n} \\\\ x_2^{n} \\end{array} \\right)+\n",
    "\\left(\\begin{array}{c} h_1^{n} \\\\ h_2^{n} \\end{array} \\right),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where we have defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\left(\\begin{array}{c} h_1^{n} \\\\ h_2^{n} \\end{array} \\right)=\n",
    "   -{\\bf \\hat{J}}^{-1}\n",
    "   \\left(\\begin{array}{c} f_1(x_1^{n},x_2^{n}) \\\\ f_2(x_1^{n},x_2^{n}) \\end{array} \\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need thus to compute the inverse of the Jacobian matrix and it\n",
    "is to understand that difficulties  may\n",
    "arise in case $\\hat{J}$ is nearly singular.\n",
    "\n",
    "It is rather straightforward to extend the above scheme to systems of\n",
    "more than two non-linear equations. In our case, the Jacobian matrix is given by the Hessian that represents the second derivative of the cost function. \n",
    "\n",
    "If we are able to evaluate the second derivative of the energy with\n",
    "respect to the variational parameters, we can also set up the Hessian\n",
    "matrix. However, as we saw earlier, the second derivative of the\n",
    "energy with respect to these parameters involves the evaluation of\n",
    "more complicated integrals, leading in turn to more statistical\n",
    "errors.\n",
    "\n",
    "This means that we normally try to avoid evaluating the second derivative and use rather simpler methods like\n",
    "the gradient descent family of methods.\n",
    "\n",
    "### Steepest descent\n",
    "\n",
    "The basic idea of gradient descent is\n",
    "that a function $F(\\mathbf{x})$, \n",
    "$\\mathbf{x} \\equiv (x_1,\\cdots,x_n)$, decreases fastest if one goes from $\\bf {x}$ in the\n",
    "direction of the negative gradient $-\\nabla F(\\mathbf{x})$.\n",
    "\n",
    "It can be shown that if"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{x}_{k+1} = \\mathbf{x}_k - \\gamma_k \\nabla F(\\mathbf{x}_k),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with $\\gamma_k > 0$.\n",
    "\n",
    "For $\\gamma_k$ small enough, then $F(\\mathbf{x}_{k+1}) \\leq\n",
    "F(\\mathbf{x}_k)$. This means that for a sufficiently small $\\gamma_k$\n",
    "we are always moving towards smaller function values, i.e a minimum.\n",
    "\n",
    "The previous observation is the basis of the method of steepest\n",
    "descent, which is also referred to as just gradient descent (GD). One\n",
    "starts with an initial guess $\\mathbf{x}_0$ for a minimum of $F$ and\n",
    "computes new approximations according to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{x}_{k+1} = \\mathbf{x}_k - \\gamma_k \\nabla F(\\mathbf{x}_k), \\ \\ k \\geq 0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter $\\gamma_k$ is often referred to as the step length or\n",
    "the learning rate within the context of Machine Learning.\n",
    "\n",
    "\n",
    "Ideally the sequence $\\{\\mathbf{x}_k \\}_{k=0}$ converges to a global\n",
    "minimum of the function $F$. In general we do not know if we are in a\n",
    "global or local minimum. In the special case when $F$ is a convex\n",
    "function, all local minima are also global minima, so in this case\n",
    "gradient descent can converge to the global solution. The advantage of\n",
    "this scheme is that it is conceptually simple and straightforward to\n",
    "implement. However the method in this form has some severe\n",
    "limitations:\n",
    "\n",
    "In machine learing we are often faced with non-convex high dimensional\n",
    "cost functions with many local minima. Since GD is deterministic we\n",
    "will get stuck in a local minimum, if the method converges, unless we\n",
    "have a very good intial guess. This also implies that the scheme is\n",
    "sensitive to the chosen initial condition.\n",
    "\n",
    "Note that the gradient is a function of $\\mathbf{x} =\n",
    "(x_1,\\cdots,x_n)$ which makes it expensive to compute numerically.\n",
    "\n",
    "\n",
    "The gradient descent method \n",
    "is sensitive to the choice of learning rate $\\gamma_k$. This is due\n",
    "to the fact that we are only guaranteed that $F(\\mathbf{x}_{k+1}) \\leq\n",
    "F(\\mathbf{x}_k)$ for sufficiently small $\\gamma_k$. The problem is to\n",
    "determine an optimal learning rate. If the learning rate is chosen too\n",
    "small the method will take a long time to converge and if it is too\n",
    "large we can experience erratic behavior.\n",
    "\n",
    "Many of these shortcomings can be alleviated by introducing\n",
    "randomness. One such method is that of Stochastic Gradient Descent\n",
    "(SGD). This is not discussed in this notebook. \n",
    "\n",
    "\n",
    "\n",
    "### The code for two electrons in two dims with no Coulomb interaction\n",
    "\n",
    "We present here the code (including importance sampling) for finding the optimal parameter $\\alpha$ using gradient descent with a given learning rate $\\eta$. In principle we should run calculations for various learning rates. \n",
    "\n",
    "Again, we start first with set up of various files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-electron VMC code for 2dim quantum dot with importance sampling\n",
    "# No Coulomb interaction\n",
    "# Using gaussian rng for new positions and Metropolis- Hastings \n",
    "# Energy minimization using standard gradient descent \n",
    "\n",
    "# Common imports\n",
    "import os\n",
    "\n",
    "# Where to save the figures and data files\n",
    "PROJECT_ROOT_DIR = \"Results\"\n",
    "FIGURE_ID = \"Results/FigureFiles\"\n",
    "\n",
    "if not os.path.exists(PROJECT_ROOT_DIR):\n",
    "    os.mkdir(PROJECT_ROOT_DIR)\n",
    "\n",
    "if not os.path.exists(FIGURE_ID):\n",
    "    os.makedirs(FIGURE_ID)\n",
    "\n",
    "def image_path(fig_id):\n",
    "    return os.path.join(FIGURE_ID, fig_id)\n",
    "\n",
    "\n",
    "def save_fig(fig_id):\n",
    "    plt.savefig(image_path(fig_id) + \".png\", format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thereafter we define the wave function, the local energy and the quantum force.\n",
    "We include also the derivative of the wave function as function of the variational parameter $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp, sqrt\n",
    "from random import random, seed, normalvariate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import sys\n",
    "from numba import jit\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "# Trial wave function for the 2-electron quantum dot in two dims\n",
    "def WaveFunction(r,alpha):\n",
    "    r1 = r[0,0]**2 + r[0,1]**2\n",
    "    r2 = r[1,0]**2 + r[1,1]**2\n",
    "    return exp(-0.5*alpha*(r1+r2))\n",
    "\n",
    "# Local energy  for the 2-electron quantum dot in two dims, using analytical local energy\n",
    "def LocalEnergy(r,alpha):\n",
    "    \n",
    "    r1 = (r[0,0]**2 + r[0,1]**2)\n",
    "    r2 = (r[1,0]**2 + r[1,1]**2)\n",
    "    return 0.5*(1-alpha*alpha)*(r1 + r2) +2.0*alpha\n",
    "\n",
    "# Derivate of wave function ansatz as function of variational parameters\n",
    "def DerivativeWFansatz(r,alpha):\n",
    "    \n",
    "    r1 = (r[0,0]**2 + r[0,1]**2)\n",
    "    r2 = (r[1,0]**2 + r[1,1]**2)\n",
    "    WfDer = -0.5*(r1+r2)\n",
    "    return  WfDer\n",
    "\n",
    "# Setting up the quantum force for the two-electron quantum dot, recall that it is a vector\n",
    "def QuantumForce(r,alpha):\n",
    "\n",
    "    qforce = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    qforce[0,:] = -2*r[0,:]*alpha\n",
    "    qforce[1,:] = -2*r[1,:]*alpha\n",
    "    return qforce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then comes our Monte Carlo sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the derivative of the energy and the energy \n",
    "# jit decorator tells Numba to compile this function.\n",
    "# The argument types will be inferred by Numba when function is called.\n",
    "@jit\n",
    "def EnergyMinimization(alpha):\n",
    "\n",
    "    NumberMCcycles= 1000\n",
    "    # Parameters in the Fokker-Planck simulation of the quantum force\n",
    "    D = 0.5\n",
    "    TimeStep = 0.05\n",
    "    # positions\n",
    "    PositionOld = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    PositionNew = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    # Quantum force\n",
    "    QuantumForceOld = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    QuantumForceNew = np.zeros((NumberParticles,Dimension), np.double)\n",
    "\n",
    "    # seed for rng generator \n",
    "    seed()\n",
    "    energy = 0.0\n",
    "    DeltaE = 0.0\n",
    "    EnergyDer = 0.0\n",
    "    DeltaPsi = 0.0\n",
    "    DerivativePsiE = 0.0\n",
    "    #Initial position\n",
    "    for i in range(NumberParticles):\n",
    "        for j in range(Dimension):\n",
    "            PositionOld[i,j] = normalvariate(0.0,1.0)*sqrt(TimeStep)\n",
    "    wfold = WaveFunction(PositionOld,alpha)\n",
    "    QuantumForceOld = QuantumForce(PositionOld,alpha)\n",
    "\n",
    "    #Loop over MC MCcycles\n",
    "    for MCcycle in range(NumberMCcycles):\n",
    "        #Trial position moving one particle at the time\n",
    "        for i in range(NumberParticles):\n",
    "            for j in range(Dimension):\n",
    "                PositionNew[i,j] = PositionOld[i,j]+normalvariate(0.0,1.0)*sqrt(TimeStep)+\\\n",
    "                                       QuantumForceOld[i,j]*TimeStep*D\n",
    "            wfnew = WaveFunction(PositionNew,alpha)\n",
    "            QuantumForceNew = QuantumForce(PositionNew,alpha)\n",
    "            GreensFunction = 0.0\n",
    "            for j in range(Dimension):\n",
    "                GreensFunction += 0.5*(QuantumForceOld[i,j]+QuantumForceNew[i,j])*\\\n",
    "\t                              (D*TimeStep*0.5*(QuantumForceOld[i,j]-QuantumForceNew[i,j])-\\\n",
    "                                      PositionNew[i,j]+PositionOld[i,j])\n",
    "      \n",
    "            GreensFunction = 1.0#exp(GreensFunction)\n",
    "            ProbabilityRatio = GreensFunction*wfnew**2/wfold**2\n",
    "            #Metropolis-Hastings test to see whether we accept the move\n",
    "            if random() <= ProbabilityRatio:\n",
    "                for j in range(Dimension):\n",
    "                    PositionOld[i,j] = PositionNew[i,j]\n",
    "                    QuantumForceOld[i,j] = QuantumForceNew[i,j]\n",
    "                wfold = wfnew\n",
    "        DeltaE = LocalEnergy(PositionOld,alpha)\n",
    "        DerPsi = DerivativeWFansatz(PositionOld,alpha)\n",
    "        DeltaPsi +=DerPsi\n",
    "        energy += DeltaE\n",
    "        DerivativePsiE += DerPsi*DeltaE\n",
    "            \n",
    "    # We calculate mean values\n",
    "    energy /= NumberMCcycles\n",
    "    DerivativePsiE /= NumberMCcycles\n",
    "    DeltaPsi /= NumberMCcycles\n",
    "    EnergyDer  = 2*(DerivativePsiE-DeltaPsi*energy)\n",
    "    return energy, EnergyDer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, here we use the gradient descent method with a fixed learning rate and a fixed number of iterations.\n",
    "This code is meant for illustrative purposes only. We could for example add a test which stops the number of\n",
    "terations when the derivative has reached a certain by us fixed minimal value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Alpha    Energy    Derivative\n",
      "0   0.758600  1.787467 -1.763865e-01\n",
      "1   0.846793  1.876468 -1.217027e-01\n",
      "2   0.907644  1.918225 -4.921541e-02\n",
      "3   0.932252  1.931954 -3.592268e-02\n",
      "4   0.950213  1.953980 -4.268577e-02\n",
      "5   0.971556  1.971400 -1.214385e-02\n",
      "6   0.977628  1.982120 -1.421873e-02\n",
      "7   0.984738  1.984927 -6.849771e-03\n",
      "8   0.988162  1.987326 -5.928249e-03\n",
      "9   0.991127  1.990671 -4.442326e-03\n",
      "10  0.993348  1.993160 -2.885105e-03\n",
      "11  0.994790  1.995425 -2.989120e-03\n",
      "12  0.996285  1.996223 -1.717588e-03\n",
      "13  0.997144  1.997006 -1.428101e-03\n",
      "14  0.997858  1.997776 -7.873867e-04\n",
      "15  0.998251  1.998118 -7.141347e-04\n",
      "16  0.998608  1.998636 -7.111589e-04\n",
      "17  0.998964  1.998916 -4.431471e-04\n",
      "18  0.999186  1.999138 -3.513106e-04\n",
      "19  0.999361  1.999334 -3.006158e-04\n",
      "20  0.999512  1.999535 -2.495752e-04\n",
      "21  0.999636  1.999683 -2.169586e-04\n",
      "22  0.999745  1.999784 -1.630476e-04\n",
      "23  0.999826  1.999819 -8.999354e-05\n",
      "24  0.999871  1.999853 -5.394863e-05\n",
      "25  0.999898  1.999893 -4.358442e-05\n",
      "26  0.999920  1.999917 -4.420895e-05\n",
      "27  0.999942  1.999937 -2.812201e-05\n",
      "28  0.999956  1.999957 -2.013759e-05\n",
      "29  0.999966  1.999969 -1.486531e-05\n",
      "30  0.999974  1.999978 -1.911141e-05\n",
      "31  0.999983  1.999984 -6.917058e-06\n",
      "32  0.999987  1.999989 -1.021283e-05\n",
      "33  0.999992  1.999992 -4.227940e-06\n",
      "34  0.999994  1.999994 -2.804972e-06\n",
      "35  0.999995  1.999995 -1.589926e-06\n",
      "36  0.999996  1.999996 -2.069348e-06\n",
      "37  0.999997  1.999997 -1.016947e-06\n",
      "38  0.999998  1.999998 -1.045886e-06\n",
      "39  0.999998  1.999998 -1.210269e-06\n",
      "40  0.999999  1.999999 -5.034496e-07\n",
      "41  0.999999  1.999999 -4.689834e-07\n",
      "42  0.999999  1.999999 -2.507869e-07\n",
      "43  1.000000  1.999999 -1.737321e-07\n",
      "44  1.000000  2.000000 -1.690948e-07\n",
      "45  1.000000  2.000000 -1.500499e-07\n",
      "46  1.000000  2.000000 -8.840723e-08\n",
      "47  1.000000  2.000000 -1.138825e-07\n",
      "48  1.000000  2.000000 -7.202874e-08\n",
      "49  1.000000  2.000000 -5.522989e-08\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Here starts the main program with variable declarations\n",
    "NumberParticles = 2\n",
    "Dimension = 2\n",
    "# guess for variational parameters\n",
    "x0 = 0.5\n",
    "# Set up iteration using stochastic gradient method\n",
    "Energy =0 ; EnergyDer = 0\n",
    "Energy, EnergyDer = EnergyMinimization(x0)\n",
    "\n",
    "# No adaptive search for a minimum\n",
    "eta = 0.5\n",
    "Niterations = 50\n",
    "\n",
    "Energies = np.zeros(Niterations)\n",
    "EnergyDerivatives = np.zeros(Niterations)\n",
    "AlphaValues = np.zeros(Niterations)\n",
    "Totiterations = np.zeros(Niterations)\n",
    "\n",
    "for iter in range(Niterations):\n",
    "    gradients = EnergyDer\n",
    "    x0 -= eta*gradients\n",
    "    Energy, EnergyDer = EnergyMinimization(x0)\n",
    "    Energies[iter] = Energy\n",
    "    EnergyDerivatives[iter] = EnergyDer\n",
    "    AlphaValues[iter] = x0\n",
    "    Totiterations[iter] = iter\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(Totiterations, Energies, 'o-')\n",
    "plt.title('Energy and energy derivatives')\n",
    "plt.ylabel('Dimensionless energy')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(Totiterations, EnergyDerivatives, '.-')\n",
    "plt.xlabel(r'$\\mathrm{Iterations}$', fontsize=15)\n",
    "plt.ylabel('Energy derivative')\n",
    "save_fig(\"QdotNonint\")\n",
    "plt.show()\n",
    "#nice printout with Pandas\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "data ={'Alpha':AlphaValues, 'Energy':Energies,'Derivative':EnergyDerivatives}\n",
    "\n",
    "frame = pd.DataFrame(data)\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the first derivative becomes smaller and smaller and after\n",
    "some forty iterations, it is for all practical purposes almost\n",
    "vanishing. The exact energy is $2.0$ and the optimal variational\n",
    "parameter is $1.0$, as it should.\n",
    "\n",
    "Next, we extend the above code to include the Coulomb interaction and the Jastrow factor as well. This is done here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-electron VMC code for 2dim quantum dot with importance sampling\n",
    "# Using gaussian rng for new positions and Metropolis- Hastings \n",
    "# Added energy minimization\n",
    "# Common imports\n",
    "from math import exp, sqrt\n",
    "from random import random, seed, normalvariate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "# Trial wave function for the 2-electron quantum dot in two dims\n",
    "def WaveFunction(r,alpha,beta):\n",
    "    r1 = r[0,0]**2 + r[0,1]**2\n",
    "    r2 = r[1,0]**2 + r[1,1]**2\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = r12/(1+beta*r12)\n",
    "    return exp(-0.5*alpha*(r1+r2)+deno)\n",
    "\n",
    "# Local energy  for the 2-electron quantum dot in two dims, using analytical local energy\n",
    "def LocalEnergy(r,alpha,beta):\n",
    "    \n",
    "    r1 = (r[0,0]**2 + r[0,1]**2)\n",
    "    r2 = (r[1,0]**2 + r[1,1]**2)\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = 1.0/(1+beta*r12)\n",
    "    deno2 = deno*deno\n",
    "    return 0.5*(1-alpha*alpha)*(r1 + r2) +2.0*alpha + 1.0/r12+deno2*(alpha*r12-deno2+2*beta*deno-1.0/r12)\n",
    "\n",
    "# Derivate of wave function ansatz as function of variational parameters\n",
    "def DerivativeWFansatz(r,alpha,beta):\n",
    "    \n",
    "    WfDer  = np.zeros((2), np.double)\n",
    "    r1 = (r[0,0]**2 + r[0,1]**2)\n",
    "    r2 = (r[1,0]**2 + r[1,1]**2)\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = 1.0/(1+beta*r12)\n",
    "    deno2 = deno*deno\n",
    "    WfDer[0] = -0.5*(r1+r2)\n",
    "    WfDer[1] = -r12*r12*deno2\n",
    "    return  WfDer\n",
    "\n",
    "# Setting up the quantum force for the two-electron quantum dot, recall that it is a vector\n",
    "def QuantumForce(r,alpha,beta):\n",
    "\n",
    "    qforce = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = 1.0/(1+beta*r12)\n",
    "    qforce[0,:] = -2*r[0,:]*alpha*(r[0,:]-r[1,:])*deno*deno/r12\n",
    "    qforce[1,:] = -2*r[1,:]*alpha*(r[1,:]-r[0,:])*deno*deno/r12\n",
    "    return qforce\n",
    "    \n",
    "\n",
    "# Computing the derivative of the energy and the energy \n",
    "def EnergyMinimization(alpha, beta):\n",
    "\n",
    "    NumberMCcycles= 10000\n",
    "    # Parameters in the Fokker-Planck simulation of the quantum force\n",
    "    D = 0.5\n",
    "    TimeStep = 0.05\n",
    "    # positions\n",
    "    PositionOld = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    PositionNew = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    # Quantum force\n",
    "    QuantumForceOld = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    QuantumForceNew = np.zeros((NumberParticles,Dimension), np.double)\n",
    "\n",
    "    # seed for rng generator \n",
    "    seed()\n",
    "    energy = 0.0\n",
    "    DeltaE = 0.0\n",
    "    EnergyDer = np.zeros((2), np.double)\n",
    "    DeltaPsi = np.zeros((2), np.double)\n",
    "    DerivativePsiE = np.zeros((2), np.double)\n",
    "    #Initial position\n",
    "    for i in range(NumberParticles):\n",
    "        for j in range(Dimension):\n",
    "            PositionOld[i,j] = normalvariate(0.0,1.0)*sqrt(TimeStep)\n",
    "    wfold = WaveFunction(PositionOld,alpha,beta)\n",
    "    QuantumForceOld = QuantumForce(PositionOld,alpha, beta)\n",
    "\n",
    "    #Loop over MC MCcycles\n",
    "    for MCcycle in range(NumberMCcycles):\n",
    "        #Trial position moving one particle at the time\n",
    "        for i in range(NumberParticles):\n",
    "            for j in range(Dimension):\n",
    "                PositionNew[i,j] = PositionOld[i,j]+normalvariate(0.0,1.0)*sqrt(TimeStep)+\\\n",
    "                                       QuantumForceOld[i,j]*TimeStep*D\n",
    "            wfnew = WaveFunction(PositionNew,alpha,beta)\n",
    "            QuantumForceNew = QuantumForce(PositionNew,alpha, beta)\n",
    "            GreensFunction = 0.0\n",
    "            for j in range(Dimension):\n",
    "                GreensFunction += 0.5*(QuantumForceOld[i,j]+QuantumForceNew[i,j])*\\\n",
    "\t                              (D*TimeStep*0.5*(QuantumForceOld[i,j]-QuantumForceNew[i,j])-\\\n",
    "                                      PositionNew[i,j]+PositionOld[i,j])\n",
    "      \n",
    "            GreensFunction = exp(GreensFunction)\n",
    "            ProbabilityRatio = GreensFunction*wfnew**2/wfold**2\n",
    "            #Metropolis-Hastings test to see whether we accept the move\n",
    "            if random() <= ProbabilityRatio:\n",
    "                for j in range(Dimension):\n",
    "                    PositionOld[i,j] = PositionNew[i,j]\n",
    "                    QuantumForceOld[i,j] = QuantumForceNew[i,j]\n",
    "                wfold = wfnew\n",
    "        DeltaE = LocalEnergy(PositionOld,alpha,beta)\n",
    "        DerPsi = DerivativeWFansatz(PositionOld,alpha,beta)\n",
    "        DeltaPsi += DerPsi\n",
    "        energy += DeltaE\n",
    "        DerivativePsiE += DerPsi*DeltaE\n",
    "            \n",
    "    # We calculate mean values\n",
    "    energy /= NumberMCcycles\n",
    "    DerivativePsiE /= NumberMCcycles\n",
    "    DeltaPsi /= NumberMCcycles\n",
    "    EnergyDer  = 2*(DerivativePsiE-DeltaPsi*energy)\n",
    "    return energy, EnergyDer\n",
    "\n",
    "\n",
    "#Here starts the main program with variable declarations\n",
    "NumberParticles = 2\n",
    "Dimension = 2\n",
    "# guess for variational parameters\n",
    "alpha = 0.95\n",
    "beta = 0.3\n",
    "# Set up iteration using stochastic gradient method\n",
    "Energy = 0\n",
    "EDerivative = np.zeros((2), np.double)\n",
    "# Learning rate eta, max iterations, need to change to adaptive learning rate\n",
    "eta = 0.01\n",
    "MaxIterations = 50\n",
    "iter = 0\n",
    "\n",
    "Energies = np.zeros(MaxIterations)\n",
    "EnergyDerivatives1 = np.zeros(MaxIterations)\n",
    "EnergyDerivatives2 = np.zeros(MaxIterations)\n",
    "AlphaValues = np.zeros(MaxIterations)\n",
    "BetaValues = np.zeros(MaxIterations)\n",
    "\n",
    "while iter < MaxIterations:\n",
    "    Energy, EDerivative = EnergyMinimization(alpha,beta)\n",
    "    alphagradient = EDerivative[0]\n",
    "    betagradient = EDerivative[1]\n",
    "    alpha -= eta*alphagradient\n",
    "    beta -= eta*betagradient \n",
    "    Energies[iter] = Energy\n",
    "    EnergyDerivatives1[iter] = EDerivative[0] \n",
    "    EnergyDerivatives2[iter] = EDerivative[1] \n",
    "    AlphaValues[iter] = alpha\n",
    "    BetaValues[iter] = beta\n",
    "    iter += 1\n",
    "\n",
    "#nice printout with Pandas\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "pd.set_option('max_columns', 6)\n",
    "data ={'Alpha':AlphaValues,'Beta':BetaValues,'Energy':Energies,'Alpha Derivative':EnergyDerivatives1,'Beta Derivative':EnergyDerivatives2}\n",
    "\n",
    "frame = pd.DataFrame(data)\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exact energy is $3.0$ for an oscillator frequency $\\omega =1$\n",
    "(with $\\hbar =1$). We note however that with this learning rate and\n",
    "number of iterations, the energies and the derivatives are not yet\n",
    "converged.\n",
    "\n",
    "We can improve upon this by using the algorithms provided by the **optimize** package in Python.\n",
    "One of these algorithms is  BroydenFletcherGoldfarbShanno (BFGS) algorithm. \n",
    "\n",
    "The optimization problem is to minimize $f(\\mathbf {x} )$ where\n",
    "$\\mathbf {x}$ is a vector in $R^{n}$, and $f$ is a differentiable\n",
    "scalar function. There are no constraints on the values that $\\mathbf{x}$ can take.\n",
    "\n",
    "The algorithm begins at an initial estimate for the optimal value\n",
    "$\\mathbf {x}_{0}$ and proceeds iteratively to get a better estimate at\n",
    "each stage.\n",
    "\n",
    "The search direction $p_k$ at stage $k$ is given by the solution of the analogue of the Newton equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "B_{k}\\mathbf {p} _{k}=-\\nabla f(\\mathbf {x}_{k}),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $B_{k}$ is an approximation to the Hessian matrix, which is\n",
    "updated iteratively at each stage, and $\\nabla f(\\mathbf {x} _{k})$\n",
    "is the gradient of the function\n",
    "evaluated at $x_k$. \n",
    "A line search in the direction $p_k$ is then used to\n",
    "find the next point $x_{k+1}$ by minimising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f(\\mathbf {x}_{k}+\\alpha \\mathbf {p}_{k}),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "over the scalar $\\alpha > 0$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The modified code here uses the BFGS algorithm but performs now a\n",
    "production run and writes to file all average values of the\n",
    "energy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the **minimize** function returns the final values for the\n",
    "variable $\\alpha=x0[0]$ and $\\beta=x0[1]$ in the array $x$.\n",
    "\n",
    "When we have found the minimum, we use these optimal parameters to perform a production run of energies.\n",
    "The output is in turn written to file and is used, together with resampling methods like the **blocking method**,\n",
    "to obtain the best possible estimate for the standard deviation. \n",
    "\n",
    "The [sampling\n",
    "functions](https://github.com/CompPhysics/ComputationalPhysics2/tree/gh-pages/doc/Programs/Resampling)\n",
    "can be used to perform both a blocking analysis, or a standard\n",
    "bootstrap and jackknife analysis.\n",
    "\n",
    "### How do we proceed?\n",
    "\n",
    "There are several paths which can be chosen. One is to extend the\n",
    "brute force gradient descent method with an adapative stochastic\n",
    "gradient. There are several examples of this. A recent approach based\n",
    "on [the Langevin equations](https://arxiv.org/pdf/1805.09416.pdf)\n",
    "seems like a promising approach for general and possibly non-convex\n",
    "optimization problems.\n",
    "\n",
    "Here we would like to point out that our next step is now to use the\n",
    "optimal values for our variational parameters and use these as inputs\n",
    "to a production run. Here we would output values of the energy and\n",
    "perform for example a blocking analysis of the results in order to get\n",
    "a best possible estimate of the standard deviation.\n",
    "\n",
    "\n",
    "\n",
    "## Resampling analysis\n",
    "\n",
    "The next step is then to use the above data sets and perform a\n",
    "resampling analysis, either using say the Bootstrap method or the\n",
    "Blocking method. Since the data will be correlated, we would recommend\n",
    "to use the non-iid Bootstrap code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from numpy import std, mean, concatenate, arange, loadtxt, zeros, ceil\n",
    "from numpy.random import randint\n",
    "from time import time\n",
    "\n",
    "\n",
    "def tsboot(data,statistic,R,l):\n",
    "    t = zeros(R); n = len(data); k = int(ceil(float(n)/l));\n",
    "    inds = arange(n); t0 = time()\n",
    "    \n",
    "    # time series bootstrap\n",
    "    for i in range(R):\n",
    "        # construct bootstrap sample from\n",
    "        # k chunks of data. The chunksize is l\n",
    "        _data = concatenate([data[j:j+l] for j in randint(0,n-l,k)])[0:n];\n",
    "        t[i] = statistic(_data)\n",
    "\n",
    "    # analysis\n",
    "    print (\"Runtime: %g sec\" % (time()-t0)); print (\"Bootstrap Statistics :\")\n",
    "    print (\"original           bias      std. error\")\n",
    "    print (\"%8g %14g %15g\" % (statistic(data), \\\n",
    "                             mean(t) - statistic(data), \\\n",
    "                             std(t) ))\n",
    "    return t\n",
    "\n",
    "\n",
    "\n",
    "# data\n",
    "T0 = time()\n",
    "X = loadtxt(\"Energies.dat\")\n",
    "\n",
    "# statistic to be estimated. Takes two args.\n",
    "# arg1: the data\n",
    "def stat(data):\n",
    "    return mean(data)\n",
    "\n",
    "print (\"Data loaded in %g sec\" % (time() - T0))\n",
    "t = tsboot(X, stat, 2**12, 2**10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blocking code, based on the article of [Marius Jonsson](https://journals.aps.org/pre/abstract/10.1103/PhysRevE.98.043304) is given here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import log2, zeros, mean, var, sum, loadtxt, arange, array, cumsum, dot, transpose, diagonal\n",
    "from numpy.linalg import inv\n",
    "\n",
    "def block(x):\n",
    "    # preliminaries\n",
    "    n = len(x)\n",
    "    d = int(log2(n))\n",
    "    s, gamma = zeros(d), zeros(d)\n",
    "    mu = mean(x)\n",
    "\n",
    "    # estimate the auto-covariance and variances \n",
    "    # for each blocking transformation\n",
    "    for i in arange(0,d):\n",
    "        n = len(x)\n",
    "        # estimate autocovariance of x\n",
    "        gamma[i] = (n)**(-1)*sum( (x[0:(n-1)]-mu)*(x[1:n]-mu) )\n",
    "        # estimate variance of x\n",
    "        s[i] = var(x)\n",
    "        # perform blocking transformation\n",
    "        x = 0.5*(x[0::2] + x[1::2])\n",
    "   \n",
    "    # generate the test observator M_k from the theorem\n",
    "    M = (cumsum( ((gamma/s)**2*2**arange(1,d+1)[::-1])[::-1] )  )[::-1]\n",
    "\n",
    "    # we need a list of magic numbers\n",
    "    q =array([6.634897,9.210340, 11.344867, 13.276704, 15.086272, 16.811894, 18.475307, 20.090235, 21.665994, 23.209251, 24.724970, 26.216967, 27.688250, 29.141238, 30.577914, 31.999927, 33.408664, 34.805306, 36.190869, 37.566235, 38.932173, 40.289360, 41.638398, 42.979820, 44.314105, 45.641683, 46.962942, 48.278236, 49.587884, 50.892181])\n",
    "\n",
    "    # use the above table to determine when we should have stopped blocking\n",
    "    for k in arange(0,d):\n",
    "        if(M[k] < q[k]):\n",
    "            break\n",
    "    if (k >= d-1):\n",
    "        print(\"Warning: Use more data\")\n",
    "    return s[k]/2**(d-k)\n",
    "\n",
    "\n",
    "x = loadtxt(\"Energies.dat\")\n",
    "print(block(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
