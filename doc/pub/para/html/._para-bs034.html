<!--
Automatically generated HTML file from DocOnce source
(https://github.com/hplgit/doconce/)
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/hplgit/doconce/" />
<meta name="description" content="Computational Physics Lectures: How to optimize codes, from vectorization to parallelization">

<title>Computational Physics Lectures: How to optimize codes, from vectorization to parallelization</title>

<!-- Bootstrap style: bootstrap -->
<link href="http://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="http://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->

<style type="text/css">

/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}

/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>


</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Content', 2, None, '___sec0'),
              ('Optimization and profiling', 2, None, '___sec1'),
              ('More on optimization', 2, None, '___sec2'),
              ('Optimization and profiling', 2, None, '___sec3'),
              ('Optimization and debugging', 2, None, '___sec4'),
              ('Other hints', 2, None, '___sec5'),
              ('Vectorization and the basic idea behind parallel computing',
               2,
               None,
               '___sec6'),
              ('A rough classification of hardware models',
               2,
               None,
               '___sec7'),
              ('Shared memory and distributed memory', 2, None, '___sec8'),
              ('Different parallel programming paradigms',
               2,
               None,
               '___sec9'),
              ('Different parallel programming paradigms',
               2,
               None,
               '___sec10'),
              ('What is vectorization?', 2, None, '___sec11'),
              ('Number of elements that can acted upon', 2, None, '___sec12'),
              ('Number of elements that can acted upon, examples',
               2,
               None,
               '___sec13'),
              ('Operation counts for scalar operation', 2, None, '___sec14'),
              ('Number of elements that can acted upon, examples',
               2,
               None,
               '___sec15'),
              ('Number of operations when vectorized', 2, None, '___sec16'),
              ('"A simple test case with and without vectorization":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/Classes/cpp/program7.cpp"',
               2,
               None,
               '___sec17'),
              ('Compiling with and without vectorization',
               2,
               None,
               '___sec18'),
              ('Compiling with and without vectorization using clang',
               2,
               None,
               '___sec19'),
              ('Automatic vectorization and vectorization inhibitors, criteria',
               2,
               None,
               '___sec20'),
              ('Automatic vectorization and vectorization inhibitors, exit criteria',
               2,
               None,
               '___sec21'),
              ('Automatic vectorization and vectorization inhibitors, straight-line code',
               2,
               None,
               '___sec22'),
              ('Automatic vectorization and vectorization inhibitors, nested loops',
               2,
               None,
               '___sec23'),
              ('Automatic vectorization and vectorization inhibitors, function calls',
               2,
               None,
               '___sec24'),
              ('Automatic vectorization and vectorization inhibitors, data dependencies',
               2,
               None,
               '___sec25'),
              ('Automatic vectorization and vectorization inhibitors, more data dependencies',
               2,
               None,
               '___sec26'),
              ('Automatic vectorization and vectorization inhibitors, memory stride',
               2,
               None,
               '___sec27'),
              ('Memory management', 2, None, '___sec28'),
              ('Memory and communication', 2, None, '___sec29'),
              ('Measuring performance', 2, None, '___sec30'),
              ('Problems with measuring time', 2, None, '___sec31'),
              ('Problems with cold start', 2, None, '___sec32'),
              ('Problems with smart compilers', 2, None, '___sec33'),
              ('Problems with interference', 2, None, '___sec34'),
              ('Problems with measuring performance', 2, None, '___sec35'),
              ('Thomas algorithm for tridiagonal linear algebra equations',
               2,
               None,
               '___sec36'),
              ('Thomas algorithm, forward substitution', 2, None, '___sec37'),
              ('Thomas algorithm, backward substitution',
               2,
               None,
               '___sec38'),
              ('Thomas algorithm and counting of operations (floating point and memory)',
               2,
               None,
               '___sec39'),
              ('"Example: Transpose of a matrix":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/Classes/cpp/program8.cpp"',
               2,
               None,
               '___sec40'),
              ('"Matrix-matrix multiplication":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/Classes/cpp/program9.cpp"',
               2,
               None,
               '___sec41'),
              ('How do we define speedup? Simplest form',
               2,
               None,
               '___sec42'),
              ('How do we define speedup? Correct baseline',
               2,
               None,
               '___sec43'),
              ('Parallel  speedup', 2, None, '___sec44'),
              ('Speedup and memory', 2, None, '___sec45'),
              ('Upper bounds on speedup', 2, None, '___sec46'),
              ("Amdahl's law", 2, None, '___sec47'),
              ('How much is parallelizable', 2, None, '___sec48'),
              ("Today's situation of parallel computing",
               2,
               None,
               '___sec49'),
              ('Overhead present in parallel computing', 2, None, '___sec50'),
              ('Parallelizing a sequential algorithm', 2, None, '___sec51'),
              ('Strategies', 2, None, '___sec52'),
              ('How do I run MPI on a PC/Laptop? MPI', 2, None, '___sec53'),
              ('Can I do it on my own PC/laptop? OpenMP installation',
               2,
               None,
               '___sec54'),
              ('Installing MPI', 2, None, '___sec55'),
              ('Installing MPI and using Qt', 2, None, '___sec56'),
              ('Using "Smaug":"http://comp-phys.net/cluster-info/using-smaug/", the CompPhys computing cluster',
               2,
               None,
               '___sec57'),
              ('What is OpenMP', 2, None, '___sec58'),
              ('Getting started, things to remember', 2, None, '___sec59'),
              ('OpenMP syntax', 2, None, '___sec60'),
              ('Different OpenMP styles of parallelism', 2, None, '___sec61'),
              ('General code structure', 2, None, '___sec62'),
              ('Parallel region', 2, None, '___sec63'),
              ('Hello world, not again, please!', 2, None, '___sec64'),
              ('Hello world, yet another variant', 2, None, '___sec65'),
              ('Important OpenMP library routines', 2, None, '___sec66'),
              ('Private variables', 2, None, '___sec67'),
              ('Master region', 2, None, '___sec68'),
              ('Parallel for loop', 2, None, '___sec69'),
              ('Parallel computations and loops', 2, None, '___sec70'),
              ('Scheduling of  loop computations', 2, None, '___sec71'),
              ('Example code for loop scheduling', 2, None, '___sec72'),
              ('Example code for loop scheduling, guided instead of dynamic',
               2,
               None,
               '___sec73'),
              ('More on Parallel for loop', 2, None, '___sec74'),
              ('What can happen with this loop?', 2, None, '___sec75'),
              ('Inner product', 2, None, '___sec76'),
              ('Different threads do different tasks', 2, None, '___sec77'),
              ('Single execution', 2, None, '___sec78'),
              ('Coordination and synchronization', 2, None, '___sec79'),
              ('Data scope', 2, None, '___sec80'),
              ('Some remarks', 2, None, '___sec81'),
              ('Parallelizing nested for-loops', 2, None, '___sec82'),
              ('Nested parallelism', 2, None, '___sec83'),
              ('Parallel tasks', 2, None, '___sec84'),
              ('Common mistakes', 2, None, '___sec85'),
              ('Not all computations are simple', 2, None, '___sec86'),
              ('Not all computations are simple, competing threads',
               2,
               None,
               '___sec87'),
              ('How to find the max value using OpenMP', 2, None, '___sec88'),
              ('Then deal with the race conditions', 2, None, '___sec89'),
              ('What can slow down OpenMP performance?', 2, None, '___sec90'),
              ('What can slow down OpenMP performance?', 2, None, '___sec91'),
              ('Find the max location for each thread', 2, None, '___sec92'),
              ('Combine the values from each thread', 2, None, '___sec93'),
              ('"Matrix-matrix multiplication":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/ParallelizationOpenMP/OpenMPvectornorm.cpp"',
               2,
               None,
               '___sec94'),
              ('"Matrix-matrix multiplication":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/ParallelizationOpenMP/OpenMPmatrixmatrixmult.cpp"',
               2,
               None,
               '___sec95'),
              ('What is Message Passing Interface (MPI)?',
               2,
               None,
               '___sec96'),
              ('Going Parallel with MPI', 2, None, '___sec97'),
              ('MPI is a library', 2, None, '___sec98'),
              ('Bindings to MPI routines', 2, None, '___sec99'),
              ('Communicator', 2, None, '___sec100'),
              ('Some of the most  important MPI functions',
               2,
               None,
               '___sec101'),
              ('"The first MPI C/C++ program":"https://github.com/CompPhysics/ComputationalPhysics2/blob/gh-pages/doc/Programs/LecturePrograms/programs/MPI/chapter07/program2.cpp"',
               2,
               None,
               '___sec102'),
              ('The Fortran program', 2, None, '___sec103'),
              ('Note 1', 2, None, '___sec104'),
              ('"Ordered output with MPIBarrier":"https://github.com/CompPhysics/ComputationalPhysics2/blob/gh-pages/doc/Programs/LecturePrograms/programs/MPI/chapter07/program3.cpp"',
               2,
               None,
               '___sec105'),
              ('Note 2', 2, None, '___sec106'),
              ('"Ordered output":"https://github.com/CompPhysics/ComputationalPhysics2/blob/gh-pages/doc/Programs/LecturePrograms/programs/MPI/chapter07/program4.cpp"',
               2,
               None,
               '___sec107'),
              ('Note 3', 2, None, '___sec108'),
              ('Note 4', 2, None, '___sec109'),
              ('"Numerical integration in parallel":"https://github.com/CompPhysics/ComputationalPhysics2/blob/gh-pages/doc/Programs/LecturePrograms/programs/MPI/chapter07/program6.cpp"',
               2,
               None,
               '___sec110'),
              ('Dissection of trapezoidal rule with $MPI\\_reduce$',
               2,
               None,
               '___sec111'),
              ('Dissection of trapezoidal rule', 2, None, '___sec112'),
              ('Integrating with _MPI_', 2, None, '___sec113'),
              ('How do I use $MPI\\_reduce$?', 2, None, '___sec114'),
              ('More on $MPI\\_Reduce$', 2, None, '___sec115'),
              ('Dissection of trapezoidal rule', 2, None, '___sec116'),
              ('Dissection of trapezoidal rule', 2, None, '___sec117'),
              ('"The quantum dot program for two electrons":"https://github.com/CompPhysics/ComputationalPhysics2/blob/gh-pages/doc/Programs/ParallelizationMPI/MPIvmcqdot.cpp"',
               2,
               None,
               '___sec118')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript"
 src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



    
<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="para-bs.html">Computational Physics Lectures: How to optimize codes, from vectorization to parallelization</a>
  </div>

  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._para-bs001.html#___sec0" style="font-size: 80%;">Content</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs002.html#___sec1" style="font-size: 80%;">Optimization and profiling</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs003.html#___sec2" style="font-size: 80%;">More on optimization</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs004.html#___sec3" style="font-size: 80%;">Optimization and profiling</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs005.html#___sec4" style="font-size: 80%;">Optimization and debugging</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs006.html#___sec5" style="font-size: 80%;">Other hints</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs007.html#___sec6" style="font-size: 80%;">Vectorization and the basic idea behind parallel computing</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs008.html#___sec7" style="font-size: 80%;">A rough classification of hardware models</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs009.html#___sec8" style="font-size: 80%;">Shared memory and distributed memory</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs010.html#___sec9" style="font-size: 80%;">Different parallel programming paradigms</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs011.html#___sec10" style="font-size: 80%;">Different parallel programming paradigms</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs012.html#___sec11" style="font-size: 80%;">What is vectorization?</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs013.html#___sec12" style="font-size: 80%;">Number of elements that can acted upon</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs014.html#___sec13" style="font-size: 80%;">Number of elements that can acted upon, examples</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs015.html#___sec14" style="font-size: 80%;">Operation counts for scalar operation</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs016.html#___sec15" style="font-size: 80%;">Number of elements that can acted upon, examples</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs017.html#___sec16" style="font-size: 80%;">Number of operations when vectorized</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs018.html#___sec17" style="font-size: 80%;">"A simple test case with and without vectorization":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/Classes/cpp/program7.cpp"</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs019.html#___sec18" style="font-size: 80%;">Compiling with and without vectorization</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs020.html#___sec19" style="font-size: 80%;">Compiling with and without vectorization using clang</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs021.html#___sec20" style="font-size: 80%;">Automatic vectorization and vectorization inhibitors, criteria</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs022.html#___sec21" style="font-size: 80%;">Automatic vectorization and vectorization inhibitors, exit criteria</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs023.html#___sec22" style="font-size: 80%;">Automatic vectorization and vectorization inhibitors, straight-line code</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs024.html#___sec23" style="font-size: 80%;">Automatic vectorization and vectorization inhibitors, nested loops</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs025.html#___sec24" style="font-size: 80%;">Automatic vectorization and vectorization inhibitors, function calls</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs026.html#___sec25" style="font-size: 80%;">Automatic vectorization and vectorization inhibitors, data dependencies</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs027.html#___sec26" style="font-size: 80%;">Automatic vectorization and vectorization inhibitors, more data dependencies</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs028.html#___sec27" style="font-size: 80%;">Automatic vectorization and vectorization inhibitors, memory stride</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs029.html#___sec28" style="font-size: 80%;">Memory management</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs030.html#___sec29" style="font-size: 80%;">Memory and communication</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs031.html#___sec30" style="font-size: 80%;">Measuring performance</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs032.html#___sec31" style="font-size: 80%;">Problems with measuring time</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs033.html#___sec32" style="font-size: 80%;">Problems with cold start</a></li>
     <!-- navigation toc: --> <li><a href="#___sec33" style="font-size: 80%;">Problems with smart compilers</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs035.html#___sec34" style="font-size: 80%;">Problems with interference</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs036.html#___sec35" style="font-size: 80%;">Problems with measuring performance</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs037.html#___sec36" style="font-size: 80%;">Thomas algorithm for tridiagonal linear algebra equations</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs038.html#___sec37" style="font-size: 80%;">Thomas algorithm, forward substitution</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs039.html#___sec38" style="font-size: 80%;">Thomas algorithm, backward substitution</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs040.html#___sec39" style="font-size: 80%;">Thomas algorithm and counting of operations (floating point and memory)</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs041.html#___sec40" style="font-size: 80%;">"Example: Transpose of a matrix":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/Classes/cpp/program8.cpp"</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs042.html#___sec41" style="font-size: 80%;">"Matrix-matrix multiplication":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/Classes/cpp/program9.cpp"</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs043.html#___sec42" style="font-size: 80%;">How do we define speedup? Simplest form</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs044.html#___sec43" style="font-size: 80%;">How do we define speedup? Correct baseline</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs045.html#___sec44" style="font-size: 80%;">Parallel  speedup</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs046.html#___sec45" style="font-size: 80%;">Speedup and memory</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs047.html#___sec46" style="font-size: 80%;">Upper bounds on speedup</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs048.html#___sec47" style="font-size: 80%;">Amdahl's law</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs049.html#___sec48" style="font-size: 80%;">How much is parallelizable</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs050.html#___sec49" style="font-size: 80%;">Today's situation of parallel computing</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs051.html#___sec50" style="font-size: 80%;">Overhead present in parallel computing</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs052.html#___sec51" style="font-size: 80%;">Parallelizing a sequential algorithm</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs053.html#___sec52" style="font-size: 80%;">Strategies</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs054.html#___sec53" style="font-size: 80%;">How do I run MPI on a PC/Laptop? MPI</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs055.html#___sec54" style="font-size: 80%;">Can I do it on my own PC/laptop? OpenMP installation</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs056.html#___sec55" style="font-size: 80%;">Installing MPI</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs057.html#___sec56" style="font-size: 80%;">Installing MPI and using Qt</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs058.html#___sec57" style="font-size: 80%;">Using "Smaug":"http://comp-phys.net/cluster-info/using-smaug/", the CompPhys computing cluster</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs059.html#___sec58" style="font-size: 80%;">What is OpenMP</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs060.html#___sec59" style="font-size: 80%;">Getting started, things to remember</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs061.html#___sec60" style="font-size: 80%;">OpenMP syntax</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs062.html#___sec61" style="font-size: 80%;">Different OpenMP styles of parallelism</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs063.html#___sec62" style="font-size: 80%;">General code structure</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs064.html#___sec63" style="font-size: 80%;">Parallel region</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs065.html#___sec64" style="font-size: 80%;">Hello world, not again, please!</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs066.html#___sec65" style="font-size: 80%;">Hello world, yet another variant</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs067.html#___sec66" style="font-size: 80%;">Important OpenMP library routines</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs068.html#___sec67" style="font-size: 80%;">Private variables</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs069.html#___sec68" style="font-size: 80%;">Master region</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs070.html#___sec69" style="font-size: 80%;">Parallel for loop</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs071.html#___sec70" style="font-size: 80%;">Parallel computations and loops</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs072.html#___sec71" style="font-size: 80%;">Scheduling of  loop computations</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs073.html#___sec72" style="font-size: 80%;">Example code for loop scheduling</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs074.html#___sec73" style="font-size: 80%;">Example code for loop scheduling, guided instead of dynamic</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs075.html#___sec74" style="font-size: 80%;">More on Parallel for loop</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs076.html#___sec75" style="font-size: 80%;">What can happen with this loop?</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs077.html#___sec76" style="font-size: 80%;">Inner product</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs078.html#___sec77" style="font-size: 80%;">Different threads do different tasks</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs079.html#___sec78" style="font-size: 80%;">Single execution</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs080.html#___sec79" style="font-size: 80%;">Coordination and synchronization</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs081.html#___sec80" style="font-size: 80%;">Data scope</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs082.html#___sec81" style="font-size: 80%;">Some remarks</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs083.html#___sec82" style="font-size: 80%;">Parallelizing nested for-loops</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs084.html#___sec83" style="font-size: 80%;">Nested parallelism</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs085.html#___sec84" style="font-size: 80%;">Parallel tasks</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs086.html#___sec85" style="font-size: 80%;">Common mistakes</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs087.html#___sec86" style="font-size: 80%;">Not all computations are simple</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs088.html#___sec87" style="font-size: 80%;">Not all computations are simple, competing threads</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs089.html#___sec88" style="font-size: 80%;">How to find the max value using OpenMP</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs090.html#___sec89" style="font-size: 80%;">Then deal with the race conditions</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs091.html#___sec90" style="font-size: 80%;">What can slow down OpenMP performance?</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs092.html#___sec91" style="font-size: 80%;">What can slow down OpenMP performance?</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs093.html#___sec92" style="font-size: 80%;">Find the max location for each thread</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs094.html#___sec93" style="font-size: 80%;">Combine the values from each thread</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs095.html#___sec94" style="font-size: 80%;">"Matrix-matrix multiplication":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/ParallelizationOpenMP/OpenMPvectornorm.cpp"</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs096.html#___sec95" style="font-size: 80%;">"Matrix-matrix multiplication":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/ParallelizationOpenMP/OpenMPmatrixmatrixmult.cpp"</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs097.html#___sec96" style="font-size: 80%;">What is Message Passing Interface (MPI)?</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs098.html#___sec97" style="font-size: 80%;">Going Parallel with MPI</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs099.html#___sec98" style="font-size: 80%;">MPI is a library</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs100.html#___sec99" style="font-size: 80%;">Bindings to MPI routines</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs101.html#___sec100" style="font-size: 80%;">Communicator</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs102.html#___sec101" style="font-size: 80%;">Some of the most  important MPI functions</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs103.html#___sec102" style="font-size: 80%;">"The first MPI C/C++ program":"https://github.com/CompPhysics/ComputationalPhysics2/blob/gh-pages/doc/Programs/LecturePrograms/programs/MPI/chapter07/program2.cpp"</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs104.html#___sec103" style="font-size: 80%;">The Fortran program</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs105.html#___sec104" style="font-size: 80%;">Note 1</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs106.html#___sec105" style="font-size: 80%;">"Ordered output with MPIBarrier":"https://github.com/CompPhysics/ComputationalPhysics2/blob/gh-pages/doc/Programs/LecturePrograms/programs/MPI/chapter07/program3.cpp"</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs107.html#___sec106" style="font-size: 80%;">Note 2</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs108.html#___sec107" style="font-size: 80%;">"Ordered output":"https://github.com/CompPhysics/ComputationalPhysics2/blob/gh-pages/doc/Programs/LecturePrograms/programs/MPI/chapter07/program4.cpp"</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs109.html#___sec108" style="font-size: 80%;">Note 3</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs110.html#___sec109" style="font-size: 80%;">Note 4</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs111.html#___sec110" style="font-size: 80%;">"Numerical integration in parallel":"https://github.com/CompPhysics/ComputationalPhysics2/blob/gh-pages/doc/Programs/LecturePrograms/programs/MPI/chapter07/program6.cpp"</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs112.html#___sec111" style="font-size: 80%;">Dissection of trapezoidal rule with \( MPI\_reduce \)</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs113.html#___sec112" style="font-size: 80%;">Dissection of trapezoidal rule</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs114.html#___sec113" style="font-size: 80%;">Integrating with <b>MPI</b></a></li>
     <!-- navigation toc: --> <li><a href="._para-bs115.html#___sec114" style="font-size: 80%;">How do I use \( MPI\_reduce \)?</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs116.html#___sec115" style="font-size: 80%;">More on \( MPI\_Reduce \)</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs117.html#___sec116" style="font-size: 80%;">Dissection of trapezoidal rule</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs118.html#___sec117" style="font-size: 80%;">Dissection of trapezoidal rule</a></li>
     <!-- navigation toc: --> <li><a href="._para-bs119.html#___sec118" style="font-size: 80%;">"The quantum dot program for two electrons":"https://github.com/CompPhysics/ComputationalPhysics2/blob/gh-pages/doc/Programs/ParallelizationMPI/MPIvmcqdot.cpp"</a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->

<div class="container">

<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->

<a name="part0034"></a>
<!-- !split -->

<h2 id="___sec33" class="anchor">Problems with smart compilers </h2>

<ol>
<li> If the result of the computation is not used, the compiler may eliminate the code</li>
<li> Performance will look impossibly fantastic</li>
<li> Even worse, eliminate some of the code so the performance looks plausible</li>
<li> Ensure that the results are (or may be) used.</li>
</ol>

<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._para-bs033.html">&laquo;</a></li>
  <li><a href="._para-bs000.html">1</a></li>
  <li><a href="">...</a></li>
  <li><a href="._para-bs026.html">27</a></li>
  <li><a href="._para-bs027.html">28</a></li>
  <li><a href="._para-bs028.html">29</a></li>
  <li><a href="._para-bs029.html">30</a></li>
  <li><a href="._para-bs030.html">31</a></li>
  <li><a href="._para-bs031.html">32</a></li>
  <li><a href="._para-bs032.html">33</a></li>
  <li><a href="._para-bs033.html">34</a></li>
  <li class="active"><a href="._para-bs034.html">35</a></li>
  <li><a href="._para-bs035.html">36</a></li>
  <li><a href="._para-bs036.html">37</a></li>
  <li><a href="._para-bs037.html">38</a></li>
  <li><a href="._para-bs038.html">39</a></li>
  <li><a href="._para-bs039.html">40</a></li>
  <li><a href="._para-bs040.html">41</a></li>
  <li><a href="._para-bs041.html">42</a></li>
  <li><a href="._para-bs042.html">43</a></li>
  <li><a href="._para-bs043.html">44</a></li>
  <li><a href="">...</a></li>
  <li><a href="._para-bs119.html">120</a></li>
  <li><a href="._para-bs035.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->

</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="http://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>

<!-- Bootstrap footer
<footer>
<a href="http://..."><img width="250" align=right src="http://..."></a>
</footer>
-->


<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>


</body>
</html>
    

