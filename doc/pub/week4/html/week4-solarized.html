<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html week4.do.txt --pygments_html_style=perldoc --html_style=solarized3 --html_links_in_new_window --html_output=week4-solarized --no_mako
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Week 6: Importance Sampling and Metropolis-Hastings' algorithm">
<title>Week 6: Importance Sampling and Metropolis-Hastings' algorithm</title>
<link href="https://cdn.rawgit.com/doconce/doconce/master/bundled/html_styles/style_solarized_box/css/solarized_light_code.css" rel="stylesheet" type="text/css" title="light"/>
<script src="https://cdn.rawgit.com/doconce/doconce/master/bundled/html_styles/style_solarized_box/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<link href="https://thomasf.github.io/solarized-css/solarized-light.min.css" rel="stylesheet">
<style type="text/css">
h1 {color: #b58900;}  /* yellow */
/* h1 {color: #cb4b16;}  orange */
/* h1 {color: #d33682;}  magenta, the original choice of thomasf */
code { padding: 0px; background-color: inherit; }
pre {
  border: 0pt solid #93a1a1;
  box-shadow: none;
}
.alert-text-small   { font-size: 80%;  }
.alert-text-large   { font-size: 130%; }
.alert-text-normal  { font-size: 90%;  }
.alert {
  padding:8px 35px 8px 14px; margin-bottom:18px;
  text-shadow:0 1px 0 rgba(255,255,255,0.5);
  border:1px solid #93a1a1;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  -moz-border-radius: 4px;
  color: #555;
  background-color: #eee8d5;
  background-position: 10px 5px;
  background-repeat: no-repeat;
  background-size: 38px;
  padding-left: 55px;
  width: 75%;
 }
.alert-block {padding-top:14px; padding-bottom:14px}
.alert-block > p, .alert-block > ul {margin-bottom:1em}
.alert li {margin-top: 1em}
.alert-block p+p {margin-top:5px}
.alert-notice { background-image: url(https://cdn.rawgit.com/doconce/doconce/master/bundled/html_images/small_yellow_notice.png); }
.alert-summary  { background-image:url(https://cdn.rawgit.com/doconce/doconce/master/bundled/html_images/small_yellow_summary.png); }
.alert-warning { background-image: url(https://cdn.rawgit.com/doconce/doconce/master/bundled/html_images/small_yellow_warning.png); }
.alert-question {background-image:url(https://cdn.rawgit.com/doconce/doconce/master/bundled/html_images/small_yellow_question.png); }
div { text-align: justify; text-justify: inter-word; }
.tab {
  padding-left: 1.5em;
}
div.toc p,a {
  line-height: 1.3;
  margin-top: 1.1;
  margin-bottom: 1.1;
}
</style>
</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Overview of week 6, February 5-9, 2024',
               2,
               None,
               'overview-of-week-6-february-5-9-2024'),
              ('Importance sampling and  overview of what needs to be coded, '
               'reminder from last week',
               2,
               None,
               'importance-sampling-and-overview-of-what-needs-to-be-coded-reminder-from-last-week'),
              ('Importance sampling', 2, None, 'importance-sampling'),
              ('Importance sampling', 2, None, 'importance-sampling'),
              ('Importance sampling', 2, None, 'importance-sampling'),
              ('Importance sampling', 2, None, 'importance-sampling'),
              ('Code example for the interacting case with importance sampling',
               2,
               None,
               'code-example-for-the-interacting-case-with-importance-sampling'),
              ('Importance sampling, Fokker-Planck and Langevin equations',
               2,
               None,
               'importance-sampling-fokker-planck-and-langevin-equations'),
              ('Importance sampling, Fokker-Planck and Langevin equations',
               2,
               None,
               'importance-sampling-fokker-planck-and-langevin-equations'),
              ('Importance sampling, Fokker-Planck and Langevin equations',
               2,
               None,
               'importance-sampling-fokker-planck-and-langevin-equations'),
              ('Importance sampling, Fokker-Planck and Langevin equations',
               2,
               None,
               'importance-sampling-fokker-planck-and-langevin-equations'),
              ('Importance sampling, Fokker-Planck and Langevin equations',
               2,
               None,
               'importance-sampling-fokker-planck-and-langevin-equations'),
              ('Importance sampling, Fokker-Planck and Langevin equations',
               2,
               None,
               'importance-sampling-fokker-planck-and-langevin-equations'),
              ('Importance sampling, Fokker-Planck and Langevin equations',
               2,
               None,
               'importance-sampling-fokker-planck-and-langevin-equations'),
              ('Importance sampling, Fokker-Planck and Langevin equations',
               2,
               None,
               'importance-sampling-fokker-planck-and-langevin-equations'),
              ('Importance sampling, Fokker-Planck and Langevin equations',
               2,
               None,
               'importance-sampling-fokker-planck-and-langevin-equations'),
              ('Importance sampling, Fokker-Planck and Langevin equations',
               2,
               None,
               'importance-sampling-fokker-planck-and-langevin-equations'),
              ('Importance sampling, Fokker-Planck and Langevin equations',
               2,
               None,
               'importance-sampling-fokker-planck-and-langevin-equations'),
              ('Importance sampling, Fokker-Planck and Langevin equations',
               2,
               None,
               'importance-sampling-fokker-planck-and-langevin-equations'),
              ('Importance sampling, Fokker-Planck and Langevin equations',
               2,
               None,
               'importance-sampling-fokker-planck-and-langevin-equations'),
              ('Importance sampling, Fokker-Planck and Langevin equations',
               2,
               None,
               'importance-sampling-fokker-planck-and-langevin-equations'),
              ('Importance sampling, Fokker-Planck and Langevin equations',
               2,
               None,
               'importance-sampling-fokker-planck-and-langevin-equations'),
              ('Importance sampling, Fokker-Planck and Langevin equations',
               2,
               None,
               'importance-sampling-fokker-planck-and-langevin-equations'),
              ('Importance sampling, Fokker-Planck and Langevin equations',
               2,
               None,
               'importance-sampling-fokker-planck-and-langevin-equations'),
              ('Importance sampling, Fokker-Planck and Langevin equations',
               2,
               None,
               'importance-sampling-fokker-planck-and-langevin-equations'),
              ('Importance sampling, Fokker-Planck and Langevin equations',
               2,
               None,
               'importance-sampling-fokker-planck-and-langevin-equations'),
              ('Importance sampling, Fokker-Planck and Langevin equations',
               2,
               None,
               'importance-sampling-fokker-planck-and-langevin-equations'),
              ('Importance sampling, Fokker-Planck and Langevin equations',
               2,
               None,
               'importance-sampling-fokker-planck-and-langevin-equations'),
              ('Importance sampling, Fokker-Planck and Langevin equations',
               2,
               None,
               'importance-sampling-fokker-planck-and-langevin-equations'),
              ('Importance sampling, Fokker-Planck and Langevin equations',
               2,
               None,
               'importance-sampling-fokker-planck-and-langevin-equations'),
              ('Importance sampling, Fokker-Planck and Langevin equations',
               2,
               None,
               'importance-sampling-fokker-planck-and-langevin-equations'),
              ('Importance sampling, Fokker-Planck and Langevin equations',
               2,
               None,
               'importance-sampling-fokker-planck-and-langevin-equations'),
              ('Importance sampling, Fokker-Planck and Langevin equations',
               2,
               None,
               'importance-sampling-fokker-planck-and-langevin-equations'),
              ('Importance sampling, Fokker-Planck and Langevin equations',
               2,
               None,
               'importance-sampling-fokker-planck-and-langevin-equations'),
              ('Importance sampling, programming elements',
               2,
               None,
               'importance-sampling-programming-elements'),
              ('Importance sampling, program elements',
               2,
               None,
               'importance-sampling-program-elements'),
              ('Importance sampling', 2, None, 'importance-sampling'),
              ('Importance sampling', 2, None, 'importance-sampling'),
              ('Importance sampling', 2, None, 'importance-sampling'),
              ('Importance sampling', 2, None, 'importance-sampling'),
              ('Importance sampling', 2, None, 'importance-sampling'),
              ('Importance sampling', 2, None, 'importance-sampling'),
              ('Importance sampling', 2, None, 'importance-sampling'),
              ('Importance sampling', 2, None, 'importance-sampling'),
              ('Importance sampling', 2, None, 'importance-sampling'),
              ('Importance sampling', 2, None, 'importance-sampling'),
              ('Importance sampling', 2, None, 'importance-sampling'),
              ('Importance sampling', 2, None, 'importance-sampling')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "AMS"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- ------------------- main content ---------------------- -->
<center>
<h1>Week 6: Importance Sampling and Metropolis-Hastings' algorithm</h1>
</center>  <!-- document title -->

<!-- author(s): Morten Hjorth-Jensen  Email morten.hjorth-jensen@fys.uio.no -->
<center>
<b>Morten Hjorth-Jensen  Email morten.hjorth-jensen@fys.uio.no</b> [1, 2]
</center>
<!-- institution(s) -->
<center>
[1] <b>Department of Physics and Center fo Computing in Science Education, University of Oslo, Oslo, Norway</b>
</center>
<center>
[2] <b>Department of Physics and Astronomy and Facility for Rare Ion Beams, Michigan State University, East Lansing, Michigan, USA</b>
</center>
<br>
<center>
<h4>February 5-9, 2024</h4>
</center> <!-- date -->
<br>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="overview-of-week-6-february-5-9-2024">Overview of week 6, February 5-9, 2024 </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b>Topics</b>
<p>
<ul>
<li> Short repetition from last week</li>
<li> Mathematical and computational details of importance sampling and Fokker-Planck and Langevin equations</li>
</ul>
</div>


<div class="alert alert-block alert-block alert-text-normal">
<b>Teaching Material, videos and written material</b>
<p>
<ul>
<li> These lecture notes</li>
<li> <a href="https://youtu.be/" target="_blank">Video of lecture TBA</a></li>
<li> <a href="https://github.com/CompPhysics/ComputationalPhysics2/blob/gh-pages/doc/HandWrittenNotes/2024/NotesFebruary9.pdf" target="_blank">Handwritten notes tba</a></li>
</ul>
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-and-overview-of-what-needs-to-be-coded-reminder-from-last-week">Importance sampling and  overview of what needs to be coded, reminder from last week </h2>

<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>

<p>For a diffusion process characterized by a time-dependent probability density \( P(x,t) \) in one dimension the Fokker-Planck
equation reads (for one particle /walker) 
</p>
$$
   \frac{\partial P}{\partial t} = D\frac{\partial }{\partial x}\left(\frac{\partial }{\partial x} -F\right)P(x,t),
$$

<p>where \( F \) is a drift term and \( D \) is the diffusion coefficient. </p>
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling">Importance sampling </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
<p>The new positions in coordinate space are given as the solutions of the Langevin equation using Euler's method, namely,
we go from the Langevin equation
</p>
$$ 
   \frac{\partial x(t)}{\partial t} = DF(x(t)) +\eta,
$$

<p>with \( \eta \) a random variable,
yielding a new position 
</p>
$$
   y = x+DF(x)\Delta t +\xi\sqrt{\Delta t},
$$

<p>where \( \xi \) is gaussian random variable and \( \Delta t \) is a chosen time step. 
The quantity \( D \) is, in atomic units, equal to \( 1/2 \) and comes from the factor \( 1/2 \) in the kinetic energy operator. Note that \( \Delta t \) is to be viewed as a parameter. Values of \( \Delta t \in [0.001,0.01] \) yield in general rather stable values of the ground state energy.  
</p>
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling">Importance sampling </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
<p>The process of isotropic diffusion characterized by a time-dependent probability density \( P(\mathbf{x},t) \) obeys (as an approximation) the so-called Fokker-Planck equation </p>
$$
   \frac{\partial P}{\partial t} = \sum_i D\frac{\partial }{\partial \mathbf{x_i}}\left(\frac{\partial }{\partial \mathbf{x_i}} -\mathbf{F_i}\right)P(\mathbf{x},t),
$$

<p>where \( \mathbf{F_i} \) is the \( i^{th} \) component of the drift term (drift velocity) caused by an external potential, and \( D \) is the diffusion coefficient. The convergence to a stationary probability density can be obtained by setting the left hand side to zero. The resulting equation will be satisfied if and only if all the terms of the sum are equal zero,</p>
$$
\frac{\partial^2 P}{\partial {\mathbf{x_i}^2}} = P\frac{\partial}{\partial {\mathbf{x_i}}}\mathbf{F_i} + \mathbf{F_i}\frac{\partial}{\partial {\mathbf{x_i}}}P.
$$
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling">Importance sampling </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
<p>The drift vector should be of the form \( \mathbf{F} = g(\mathbf{x}) \frac{\partial P}{\partial \mathbf{x}} \). Then,</p>
$$
\frac{\partial^2 P}{\partial {\mathbf{x_i}^2}} = P\frac{\partial g}{\partial P}\left( \frac{\partial P}{\partial {\mathbf{x}_i}}  \right)^2 + P g \frac{\partial ^2 P}{\partial {\mathbf{x}_i^2}}  + g \left( \frac{\partial P}{\partial {\mathbf{x}_i}}  \right)^2.
$$

<p>The condition of stationary density means that the left hand side equals zero. In other words, the terms containing first and second derivatives have to cancel each other. It is possible only if \( g = \frac{1}{P} \), which yields</p>
$$
\mathbf{F} = 2\frac{1}{\Psi_T}\nabla\Psi_T,
$$

<p>which is known as the so-called <em>quantum force</em>. This term is responsible for pushing the walker towards regions of configuration space where the trial wave function is large, increasing the efficiency of the simulation in contrast to the Metropolis algorithm where the walker has the same probability of moving in every direction.</p>
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling">Importance sampling </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
<p>The Fokker-Planck equation yields a (the solution to the equation) transition probability given by the Green's function</p>
$$
  G(y,x,\Delta t) = \frac{1}{(4\pi D\Delta t)^{3N/2}} \exp{\left(-(y-x-D\Delta t F(x))^2/4D\Delta t\right)}
$$

<p>which in turn means that our brute force Metropolis algorithm</p>
$$ 
    A(y,x) = \mathrm{min}(1,q(y,x))),
$$

<p>with \( q(y,x) = |\Psi_T(y)|^2/|\Psi_T(x)|^2 \) is now replaced by the <a href="http://scitation.aip.org/content/aip/journal/jcp/21/6/10.1063/1.1699114" target="_blank">Metropolis-Hastings algorithm</a> as well as <a href="http://biomet.oxfordjournals.org/content/57/1/97.abstract" target="_blank">Hasting's article</a>, </p>
$$
q(y,x) = \frac{G(x,y,\Delta t)|\Psi_T(y)|^2}{G(y,x,\Delta t)|\Psi_T(x)|^2}
$$
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="code-example-for-the-interacting-case-with-importance-sampling">Code example for the interacting case with importance sampling </h2>

<p>We are now ready to implement importance sampling. This is done here for the two-electron case with the Coulomb interaction, as in the previous example. We have two variational parameters \( \alpha \) and \( \beta \). After the set up of files</p>


<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #eeeedd">
  <pre style="line-height: 125%;"><span style="color: #228B22"># Common imports</span>
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">os</span>

<span style="color: #228B22"># Where to save the figures and data files</span>
PROJECT_ROOT_DIR = <span style="color: #CD5555">&quot;Results&quot;</span>
FIGURE_ID = <span style="color: #CD5555">&quot;Results/FigureFiles&quot;</span>
DATA_ID = <span style="color: #CD5555">&quot;Results/VMCQdotImportance&quot;</span>

<span style="color: #8B008B; font-weight: bold">if</span> <span style="color: #8B008B">not</span> os.path.exists(PROJECT_ROOT_DIR):
    os.mkdir(PROJECT_ROOT_DIR)

<span style="color: #8B008B; font-weight: bold">if</span> <span style="color: #8B008B">not</span> os.path.exists(FIGURE_ID):
    os.makedirs(FIGURE_ID)

<span style="color: #8B008B; font-weight: bold">if</span> <span style="color: #8B008B">not</span> os.path.exists(DATA_ID):
    os.makedirs(DATA_ID)

<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">image_path</span>(fig_id):
    <span style="color: #8B008B; font-weight: bold">return</span> os.path.join(FIGURE_ID, fig_id)

<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">data_path</span>(dat_id):
    <span style="color: #8B008B; font-weight: bold">return</span> os.path.join(DATA_ID, dat_id)

<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">save_fig</span>(fig_id):
    plt.savefig(image_path(fig_id) + <span style="color: #CD5555">&quot;.png&quot;</span>, <span style="color: #658b00">format</span>=<span style="color: #CD5555">&#39;png&#39;</span>)

outfile = <span style="color: #658b00">open</span>(data_path(<span style="color: #CD5555">&quot;VMCQdotImportance.dat&quot;</span>),<span style="color: #CD5555">&#39;w&#39;</span>)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>

<p>we move on to the set up of the trial wave function, the analytical expression for the local energy and the analytical expression for the quantum force.</p>

<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #eeeedd">
  <pre style="line-height: 125%;"><span style="color: #228B22"># 2-electron VMC code for 2dim quantum dot with importance sampling</span>
<span style="color: #228B22"># Using gaussian rng for new positions and Metropolis- Hastings </span>
<span style="color: #228B22"># No energy minimization</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">math</span> <span style="color: #8B008B; font-weight: bold">import</span> exp, sqrt
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">random</span> <span style="color: #8B008B; font-weight: bold">import</span> random, seed, normalvariate
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">numpy</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">np</span>
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">matplotlib.pyplot</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">plt</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">mpl_toolkits.mplot3d</span> <span style="color: #8B008B; font-weight: bold">import</span> Axes3D
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">matplotlib</span> <span style="color: #8B008B; font-weight: bold">import</span> cm
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">matplotlib.ticker</span> <span style="color: #8B008B; font-weight: bold">import</span> LinearLocator, FormatStrFormatter
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">sys</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">numba</span> <span style="color: #8B008B; font-weight: bold">import</span> jit,njit


<span style="color: #228B22"># Trial wave function for the 2-electron quantum dot in two dims</span>
<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">WaveFunction</span>(r,alpha,beta):
    r1 = r[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">0</span>]**<span style="color: #B452CD">2</span> + r[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">1</span>]**<span style="color: #B452CD">2</span>
    r2 = r[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">0</span>]**<span style="color: #B452CD">2</span> + r[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">1</span>]**<span style="color: #B452CD">2</span>
    r12 = sqrt((r[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">0</span>]-r[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">0</span>])**<span style="color: #B452CD">2</span> + (r[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">1</span>]-r[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">1</span>])**<span style="color: #B452CD">2</span>)
    deno = r12/(<span style="color: #B452CD">1</span>+beta*r12)
    <span style="color: #8B008B; font-weight: bold">return</span> exp(-<span style="color: #B452CD">0.5</span>*alpha*(r1+r2)+deno)

<span style="color: #228B22"># Local energy  for the 2-electron quantum dot in two dims, using analytical local energy</span>
<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">LocalEnergy</span>(r,alpha,beta):
    
    r1 = (r[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">0</span>]**<span style="color: #B452CD">2</span> + r[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">1</span>]**<span style="color: #B452CD">2</span>)
    r2 = (r[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">0</span>]**<span style="color: #B452CD">2</span> + r[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">1</span>]**<span style="color: #B452CD">2</span>)
    r12 = sqrt((r[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">0</span>]-r[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">0</span>])**<span style="color: #B452CD">2</span> + (r[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">1</span>]-r[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">1</span>])**<span style="color: #B452CD">2</span>)
    deno = <span style="color: #B452CD">1.0</span>/(<span style="color: #B452CD">1</span>+beta*r12)
    deno2 = deno*deno
    <span style="color: #8B008B; font-weight: bold">return</span> <span style="color: #B452CD">0.5</span>*(<span style="color: #B452CD">1</span>-alpha*alpha)*(r1 + r2) +<span style="color: #B452CD">2.0</span>*alpha + <span style="color: #B452CD">1.0</span>/r12+deno2*(alpha*r12-deno2+<span style="color: #B452CD">2</span>*beta*deno-<span style="color: #B452CD">1.0</span>/r12)

<span style="color: #228B22"># Setting up the quantum force for the two-electron quantum dot, recall that it is a vector</span>
<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">QuantumForce</span>(r,alpha,beta):

    qforce = np.zeros((NumberParticles,Dimension), np.double)
    r12 = sqrt((r[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">0</span>]-r[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">0</span>])**<span style="color: #B452CD">2</span> + (r[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">1</span>]-r[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">1</span>])**<span style="color: #B452CD">2</span>)
    deno = <span style="color: #B452CD">1.0</span>/(<span style="color: #B452CD">1</span>+beta*r12)
    qforce[<span style="color: #B452CD">0</span>,:] = -<span style="color: #B452CD">2</span>*r[<span style="color: #B452CD">0</span>,:]*alpha*(r[<span style="color: #B452CD">0</span>,:]-r[<span style="color: #B452CD">1</span>,:])*deno*deno/r12
    qforce[<span style="color: #B452CD">1</span>,:] = -<span style="color: #B452CD">2</span>*r[<span style="color: #B452CD">1</span>,:]*alpha*(r[<span style="color: #B452CD">1</span>,:]-r[<span style="color: #B452CD">0</span>,:])*deno*deno/r12
    <span style="color: #8B008B; font-weight: bold">return</span> qforce
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>

<p>The Monte Carlo sampling includes now the Metropolis-Hastings algorithm, with the additional complication of having to evaluate the <b>quantum force</b> and the Green's function which is the solution of the Fokker-Planck equation.</p>


<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #eeeedd">
  <pre style="line-height: 125%;"><span style="color: #228B22"># The Monte Carlo sampling with the Metropolis algo</span>
<span style="color: #228B22"># jit decorator tells Numba to compile this function.</span>
<span style="color: #228B22"># The argument types will be inferred by Numba when function is called.</span>
<span style="color: #707a7c">@jit</span>()
<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">MonteCarloSampling</span>():

    NumberMCcycles= <span style="color: #B452CD">100000</span>
    <span style="color: #228B22"># Parameters in the Fokker-Planck simulation of the quantum force</span>
    D = <span style="color: #B452CD">0.5</span>
    TimeStep = <span style="color: #B452CD">0.05</span>
    <span style="color: #228B22"># positions</span>
    PositionOld = np.zeros((NumberParticles,Dimension), np.double)
    PositionNew = np.zeros((NumberParticles,Dimension), np.double)
    <span style="color: #228B22"># Quantum force</span>
    QuantumForceOld = np.zeros((NumberParticles,Dimension), np.double)
    QuantumForceNew = np.zeros((NumberParticles,Dimension), np.double)

    <span style="color: #228B22"># seed for rng generator </span>
    seed()
    <span style="color: #228B22"># start variational parameter  loops, two parameters here</span>
    alpha = <span style="color: #B452CD">0.9</span>
    <span style="color: #8B008B; font-weight: bold">for</span> ia <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(MaxVariations):
        alpha += <span style="color: #B452CD">.025</span>
        AlphaValues[ia] = alpha
        beta = <span style="color: #B452CD">0.2</span> 
        <span style="color: #8B008B; font-weight: bold">for</span> jb <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(MaxVariations):
            beta += <span style="color: #B452CD">.01</span>
            BetaValues[jb] = beta
            energy = energy2 = <span style="color: #B452CD">0.0</span>
            DeltaE = <span style="color: #B452CD">0.0</span>
            <span style="color: #228B22">#Initial position</span>
            <span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(NumberParticles):
                <span style="color: #8B008B; font-weight: bold">for</span> j <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(Dimension):
                    PositionOld[i,j] = normalvariate(<span style="color: #B452CD">0.0</span>,<span style="color: #B452CD">1.0</span>)*sqrt(TimeStep)
            wfold = WaveFunction(PositionOld,alpha,beta)
            QuantumForceOld = QuantumForce(PositionOld,alpha, beta)

            <span style="color: #228B22">#Loop over MC MCcycles</span>
            <span style="color: #8B008B; font-weight: bold">for</span> MCcycle <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(NumberMCcycles):
                <span style="color: #228B22">#Trial position moving one particle at the time</span>
                <span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(NumberParticles):
                    <span style="color: #8B008B; font-weight: bold">for</span> j <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(Dimension):
                        PositionNew[i,j] = PositionOld[i,j]+normalvariate(<span style="color: #B452CD">0.0</span>,<span style="color: #B452CD">1.0</span>)*sqrt(TimeStep)+\
                                           QuantumForceOld[i,j]*TimeStep*D
                    wfnew = WaveFunction(PositionNew,alpha,beta)
                    QuantumForceNew = QuantumForce(PositionNew,alpha, beta)
                    GreensFunction = <span style="color: #B452CD">0.0</span>
                    <span style="color: #8B008B; font-weight: bold">for</span> j <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(Dimension):
                        GreensFunction += <span style="color: #B452CD">0.5</span>*(QuantumForceOld[i,j]+QuantumForceNew[i,j])*\
	                              (D*TimeStep*<span style="color: #B452CD">0.5</span>*(QuantumForceOld[i,j]-QuantumForceNew[i,j])-\
                                      PositionNew[i,j]+PositionOld[i,j])
      
                    GreensFunction = exp(GreensFunction)
                    ProbabilityRatio = GreensFunction*wfnew**<span style="color: #B452CD">2</span>/wfold**<span style="color: #B452CD">2</span>
                    <span style="color: #228B22">#Metropolis-Hastings test to see whether we accept the move</span>
                    <span style="color: #8B008B; font-weight: bold">if</span> random() &lt;= ProbabilityRatio:
                       <span style="color: #8B008B; font-weight: bold">for</span> j <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(Dimension):
                           PositionOld[i,j] = PositionNew[i,j]
                           QuantumForceOld[i,j] = QuantumForceNew[i,j]
                       wfold = wfnew
                DeltaE = LocalEnergy(PositionOld,alpha,beta)
                energy += DeltaE
                energy2 += DeltaE**<span style="color: #B452CD">2</span>
            <span style="color: #228B22"># We calculate mean, variance and error (no blocking applied)</span>
            energy /= NumberMCcycles
            energy2 /= NumberMCcycles
            variance = energy2 - energy**<span style="color: #B452CD">2</span>
            error = sqrt(variance/NumberMCcycles)
            Energies[ia,jb] = energy    
            outfile.write(<span style="color: #CD5555">&#39;%f %f %f %f %f\n&#39;</span> %(alpha,beta,energy,variance,error))
    <span style="color: #8B008B; font-weight: bold">return</span> Energies, AlphaValues, BetaValues
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>

<p>The main part here contains the setup of the variational parameters, the energies and the variance.</p>

<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #eeeedd">
  <pre style="line-height: 125%;"><span style="color: #228B22">#Here starts the main program with variable declarations</span>
NumberParticles = <span style="color: #B452CD">2</span>
Dimension = <span style="color: #B452CD">2</span>
MaxVariations = <span style="color: #B452CD">10</span>
Energies = np.zeros((MaxVariations,MaxVariations))
AlphaValues = np.zeros(MaxVariations)
BetaValues = np.zeros(MaxVariations)
(Energies, AlphaValues, BetaValues) = MonteCarloSampling()
outfile.close()
<span style="color: #228B22"># Prepare for plots</span>
fig = plt.figure()
ax = fig.gca(projection=<span style="color: #CD5555">&#39;3d&#39;</span>)
<span style="color: #228B22"># Plot the surface.</span>
X, Y = np.meshgrid(AlphaValues, BetaValues)
surf = ax.plot_surface(X, Y, Energies,cmap=cm.coolwarm,linewidth=<span style="color: #B452CD">0</span>, antialiased=<span style="color: #8B008B; font-weight: bold">False</span>)
<span style="color: #228B22"># Customize the z axis.</span>
zmin = np.matrix(Energies).min()
zmax = np.matrix(Energies).max()
ax.set_zlim(zmin, zmax)
ax.set_xlabel(<span style="color: #CD5555">r&#39;$\alpha$&#39;</span>)
ax.set_ylabel(<span style="color: #CD5555">r&#39;$\beta$&#39;</span>)
ax.set_zlabel(<span style="color: #CD5555">r&#39;$\langle E \rangle$&#39;</span>)
ax.zaxis.set_major_locator(LinearLocator(<span style="color: #B452CD">10</span>))
ax.zaxis.set_major_formatter(FormatStrFormatter(<span style="color: #CD5555">&#39;%.02f&#39;</span>))
<span style="color: #228B22"># Add a color bar which maps values to colors.</span>
fig.colorbar(surf, shrink=<span style="color: #B452CD">0.5</span>, aspect=<span style="color: #B452CD">5</span>)
save_fig(<span style="color: #CD5555">&quot;QdotImportance&quot;</span>)
plt.show()
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-fokker-planck-and-langevin-equations">Importance sampling, Fokker-Planck and Langevin equations </h2>

<p>A stochastic process is simply a function of two variables, one is the
time, the other is a stochastic variable \( X \), defined by specifying
</p>

<ol>
<li> the set \( \left\{x\right\} \) of possible values for \( X \);</li>
<li> the probability distribution, \( w_X(x) \),  over this set, or briefly \( w(x) \)</li>
</ol>
<p>The set of values \( \left\{x\right\} \) for \( X \) may be discrete, or
continuous. If the set of values is continuous, then \( w_X (x) \) is a
probability density so that \( w_X (x)dx \) is the probability that one
finds the stochastic variable \( X \) to have values in the range \( [x, x +dx] \) .
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-fokker-planck-and-langevin-equations">Importance sampling, Fokker-Planck and Langevin equations </h2>

<p>An arbitrary number of other stochastic variables may be derived from
\( X \). For example, any \( Y \) given by a mapping of \( X \), is also a
stochastic variable. The mapping may also be time-dependent, that is,
the mapping depends on an additional variable \( t \)
</p>
$$ Y_X (t) = f(X, t).
$$

<p>The quantity \( Y_X (t) \) is called a random function,
or, since \( t \) often is time, a stochastic process. A stochastic
process is a function of two variables, one is the time, the other is
a stochastic variable \( X \). Let \( x \) be one of the possible values of
\( X \) then
</p>
$$ y(t) = f (x, t), $$

<p>is a function of \( t \), called a
sample function or realization of the process.  In physics one
considers the stochastic process to be an ensemble of such sample
functions.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-fokker-planck-and-langevin-equations">Importance sampling, Fokker-Planck and Langevin equations </h2>

<p>For many physical systems initial distributions of a stochastic
variable \( y \) tend to equilibrium distributions: \( w(y, t)\rightarrow
w_0(y) \) as \( t\rightarrow\infty \). In equilibrium detailed balance
constrains the transition rates
</p>
$$
     W(y\rightarrow y')w(y ) = W(y'\rightarrow y)w_0 (y),
$$

<p>where \( W(y'\rightarrow y) \) is the probability, per unit time, that the
system changes from a state \( |y\rangle \) , characterized by the value
\( y \) for the stochastic variable \( Y \) , to a state \( |y'\rangle \).
</p>

<p>Note that for a system in equilibrium the transition rate
\( W(y'\rightarrow y) \) and the reverse \( W(y\rightarrow y') \) may be very
different.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-fokker-planck-and-langevin-equations">Importance sampling, Fokker-Planck and Langevin equations </h2>

<p>Consider, for instance, a simple system that has only two energy
levels \( \epsilon_0 = 0 \) and \( \epsilon_1 = \Delta E \).
</p>

<p>For a system governed by the Boltzmann distribution we find (the partition function has been taken out)</p>
$$
     W(0\rightarrow 1)\exp{-(\epsilon_0/kT)} = W(1\rightarrow 0)\exp{-(\epsilon_1/kT)}.
$$

<p>We get then</p>
$$
     \frac{W(1\rightarrow 0)}{W(0 \rightarrow 1)}=\exp{-(\Delta E/kT)},
$$

<p>which goes to zero when \( T \) tends to zero.</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-fokker-planck-and-langevin-equations">Importance sampling, Fokker-Planck and Langevin equations </h2>

<p>If we assume a discrete set of events,
our initial probability
distribution function can be  given by 
</p>
$$
   w_i(0) = \delta_{i,0},
$$

<p>and its time-development after a given time step \( \Delta t=\epsilon \) is</p>
$$ 
   w_i(t) = \sum_{j}W(j\rightarrow i)w_j(t=0).
$$

<p>The continuous analog to \( w_i(0) \) is</p>
$$
   w(\mathbf{x})\rightarrow \delta(\mathbf{x}),
$$

<p>where we now have generalized the one-dimensional position \( x \) to a generic-dimensional  
vector \( \mathbf{x} \). The Kroenecker \( \delta \) function is replaced by the \( \delta \) distribution
function \( \delta(\mathbf{x}) \) at  \( t=0 \).  
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-fokker-planck-and-langevin-equations">Importance sampling, Fokker-Planck and Langevin equations </h2>

<p>The transition from a state \( j \) to a state \( i \) is now replaced by a transition
to a state with position \( \mathbf{y} \) from a state with position \( \mathbf{x} \). 
The discrete sum of transition probabilities can then be replaced by an integral
and we obtain the new distribution at a time \( t+\Delta t \) as 
</p>
$$
   w(\mathbf{y},t+\Delta t)= \int W(\mathbf{y},t+\Delta t| \mathbf{x},t)w(\mathbf{x},t)d\mathbf{x},
$$

<p>and after \( m \) time steps we have</p>
$$
   w(\mathbf{y},t+m\Delta t)= \int W(\mathbf{y},t+m\Delta t| \mathbf{x},t)w(\mathbf{x},t)d\mathbf{x}.
$$

<p>When equilibrium is reached we have</p>
$$
   w(\mathbf{y})= \int W(\mathbf{y}|\mathbf{x}, t)w(\mathbf{x})d\mathbf{x},
$$

<p>that is no time-dependence. Note our change of notation for \( W \)</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-fokker-planck-and-langevin-equations">Importance sampling, Fokker-Planck and Langevin equations </h2>

<p>We can solve the equation for \( w(\mathbf{y},t) \) by making a Fourier transform to
momentum space. 
The PDF \( w(\mathbf{x},t) \) is related to its Fourier transform
\( \tilde{w}(\mathbf{k},t) \) through
</p>
$$
   w(\mathbf{x},t) = \int_{-\infty}^{\infty}d\mathbf{k} \exp{(i\mathbf{kx})}\tilde{w}(\mathbf{k},t),
$$

<p>and using the definition of the 
\( \delta \)-function 
</p>
$$
   \delta(\mathbf{x}) = \frac{1}{2\pi} \int_{-\infty}^{\infty}d\mathbf{k} \exp{(i\mathbf{kx})},
$$

<p> we see that</p>
$$
   \tilde{w}(\mathbf{k},0)=1/2\pi.
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-fokker-planck-and-langevin-equations">Importance sampling, Fokker-Planck and Langevin equations </h2>

<p>We can then use the Fourier-transformed diffusion equation </p>
$$
    \frac{\partial \tilde{w}(\mathbf{k},t)}{\partial t} = -D\mathbf{k}^2\tilde{w}(\mathbf{k},t),
$$

<p>with the obvious solution</p>
$$
   \tilde{w}(\mathbf{k},t)=\tilde{w}(\mathbf{k},0)\exp{\left[-(D\mathbf{k}^2t)\right)}=
    \frac{1}{2\pi}\exp{\left[-(D\mathbf{k}^2t)\right]}. 
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-fokker-planck-and-langevin-equations">Importance sampling, Fokker-Planck and Langevin equations </h2>

<p>With the Fourier transform we obtain </p>
$$
   w(\mathbf{x},t)=\int_{-\infty}^{\infty}d\mathbf{k} \exp{\left[i\mathbf{kx}\right]}\frac{1}{2\pi}\exp{\left[-(D\mathbf{k}^2t)\right]}=
    \frac{1}{\sqrt{4\pi Dt}}\exp{\left[-(\mathbf{x}^2/4Dt)\right]}, 
$$

<p>with the normalization condition</p>
$$
   \int_{-\infty}^{\infty}w(\mathbf{x},t)d\mathbf{x}=1.
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-fokker-planck-and-langevin-equations">Importance sampling, Fokker-Planck and Langevin equations </h2>

<p>The solution represents the probability of finding
our random walker at position \( \mathbf{x} \) at time \( t \) if the initial distribution 
was placed at \( \mathbf{x}=0 \) at \( t=0 \). 
</p>

<p>There is another interesting feature worth observing. The discrete transition probability \( W \)
itself is given by a binomial distribution.
The results from the central limit theorem state that 
transition probability in the limit \( n\rightarrow \infty \) converges to the normal 
distribution. It is then possible to show that
</p>
$$
    W(il-jl,n\epsilon)\rightarrow W(\mathbf{y},t+\Delta t|\mathbf{x},t)=
    \frac{1}{\sqrt{4\pi D\Delta t}}\exp{\left[-((\mathbf{y}-\mathbf{x})^2/4D\Delta t)\right]},
$$

<p>and that it satisfies the normalization condition and is itself a solution
to the diffusion equation.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-fokker-planck-and-langevin-equations">Importance sampling, Fokker-Planck and Langevin equations </h2>

<p>Let us now assume that we have three PDFs for times \( t_0 < t' < t \), that is
\( w(\mathbf{x}_0,t_0) \), \( w(\mathbf{x}',t') \) and \( w(\mathbf{x},t) \).
We have then  
</p>
$$
   w(\mathbf{x},t)= \int_{-\infty}^{\infty} W(\mathbf{x}.t|\mathbf{x}'.t')w(\mathbf{x}',t')d\mathbf{x}',
$$

<p>and</p>
$$
   w(\mathbf{x},t)= \int_{-\infty}^{\infty} W(\mathbf{x}.t|\mathbf{x}_0.t_0)w(\mathbf{x}_0,t_0)d\mathbf{x}_0,
$$

<p>and</p>
$$
   w(\mathbf{x}',t')= \int_{-\infty}^{\infty} W(\mathbf{x}'.t'|\mathbf{x}_0,t_0)w(\mathbf{x}_0,t_0)d\mathbf{x}_0.
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-fokker-planck-and-langevin-equations">Importance sampling, Fokker-Planck and Langevin equations </h2>

<p>We can combine these equations and arrive at the famous Einstein-Smoluchenski-Kolmogorov-Chapman (ESKC) relation</p>
$$
 W(\mathbf{x}t|\mathbf{x}_0t_0)  = \int_{-\infty}^{\infty} W(\mathbf{x},t|\mathbf{x}',t')W(\mathbf{x}',t'|\mathbf{x}_0,t_0)d\mathbf{x}'.
$$

<p>We can replace the spatial dependence with a dependence upon say the velocity
(or momentum), that is we have
</p>
$$
 W(\mathbf{v},t|\mathbf{v}_0,t_0)  = \int_{-\infty}^{\infty} W(\mathbf{v},t|\mathbf{v}',t')W(\mathbf{v}',t'|\mathbf{v}_0,t_0)d\mathbf{x}'.
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-fokker-planck-and-langevin-equations">Importance sampling, Fokker-Planck and Langevin equations </h2>

<p>We will now derive the Fokker-Planck equation. 
We start from the ESKC equation
</p>
$$
 W(\mathbf{x},t|\mathbf{x}_0,t_0)  = \int_{-\infty}^{\infty} W(\mathbf{x},t|\mathbf{x}',t')W(\mathbf{x}',t'|\mathbf{x}_0,t_0)d\mathbf{x}'.
$$

<p>Define \( s=t'-t_0 \), \( \tau=t-t' \) and \( t-t_0=s+\tau \). We have then</p>
$$
 W(\mathbf{x},s+\tau|\mathbf{x}_0)  = \int_{-\infty}^{\infty} W(\mathbf{x},\tau|\mathbf{x}')W(\mathbf{x}',s|\mathbf{x}_0)d\mathbf{x}'.
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-fokker-planck-and-langevin-equations">Importance sampling, Fokker-Planck and Langevin equations </h2>

<p>Assume now that \( \tau \) is very small so that we can make an expansion in terms of a small step \( xi \), with \( \mathbf{x}'=\mathbf{x}-\xi \), that is</p>
$$
 W(\mathbf{x},s|\mathbf{x}_0)+\frac{\partial W}{\partial s}\tau +O(\tau^2) = \int_{-\infty}^{\infty} W(\mathbf{x},\tau|\mathbf{x}-\xi)W(\mathbf{x}-\xi,s|\mathbf{x}_0)d\mathbf{x}'.
$$

<p>We assume that \( W(\mathbf{x},\tau|\mathbf{x}-\xi) \) takes non-negligible values only when \( \xi \) is small. This is just another way of stating the Master equation!!</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-fokker-planck-and-langevin-equations">Importance sampling, Fokker-Planck and Langevin equations </h2>

<p>We say thus that \( \mathbf{x} \) changes only by a small amount in the time interval \( \tau \). 
This means that we can make a Taylor expansion in terms of \( \xi \), that is we
expand
</p>
$$
W(\mathbf{x},\tau|\mathbf{x}-\xi)W(\mathbf{x}-\xi,s|\mathbf{x}_0) =
\sum_{n=0}^{\infty}\frac{(-\xi)^n}{n!}\frac{\partial^n}{\partial x^n}\left[W(\mathbf{x}+\xi,\tau|\mathbf{x})W(\mathbf{x},s|\mathbf{x}_0)
\right].
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-fokker-planck-and-langevin-equations">Importance sampling, Fokker-Planck and Langevin equations </h2>

<p>We can then rewrite the ESKC equation as </p>
$$
\frac{\partial W}{\partial s}\tau=-W(\mathbf{x},s|\mathbf{x}_0)+
\sum_{n=0}^{\infty}\frac{(-\xi)^n}{n!}\frac{\partial^n}{\partial x^n}
\left[W(\mathbf{x},s|\mathbf{x}_0)\int_{-\infty}^{\infty} \xi^nW(\mathbf{x}+\xi,\tau|\mathbf{x})d\xi\right].
$$

<p>We have neglected higher powers of \( \tau \) and have used that for \( n=0 \) 
we get simply \( W(\mathbf{x},s|\mathbf{x}_0) \) due to normalization.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-fokker-planck-and-langevin-equations">Importance sampling, Fokker-Planck and Langevin equations </h2>

<p>We say thus that \( \mathbf{x} \) changes only by a small amount in the time interval \( \tau \). 
This means that we can make a Taylor expansion in terms of \( \xi \), that is we
expand
</p>
$$
W(\mathbf{x},\tau|\mathbf{x}-\xi)W(\mathbf{x}-\xi,s|\mathbf{x}_0) =
\sum_{n=0}^{\infty}\frac{(-\xi)^n}{n!}\frac{\partial^n}{\partial x^n}\left[W(\mathbf{x}+\xi,\tau|\mathbf{x})W(\mathbf{x},s|\mathbf{x}_0)
\right].
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-fokker-planck-and-langevin-equations">Importance sampling, Fokker-Planck and Langevin equations </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
<p>We can then rewrite the ESKC equation as </p>
$$
\frac{\partial W(\mathbf{x},s|\mathbf{x}_0)}{\partial s}\tau=-W(\mathbf{x},s|\mathbf{x}_0)+
\sum_{n=0}^{\infty}\frac{(-\xi)^n}{n!}\frac{\partial^n}{\partial x^n}
\left[W(\mathbf{x},s|\mathbf{x}_0)\int_{-\infty}^{\infty} \xi^nW(\mathbf{x}+\xi,\tau|\mathbf{x})d\xi\right].
$$

<p>We have neglected higher powers of \( \tau \) and have used that for \( n=0 \) 
we get simply \( W(\mathbf{x},s|\mathbf{x}_0) \) due to normalization.
</p>
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-fokker-planck-and-langevin-equations">Importance sampling, Fokker-Planck and Langevin equations </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
<p>We simplify the above by introducing the moments </p>
$$
M_n=\frac{1}{\tau}\int_{-\infty}^{\infty} \xi^nW(\mathbf{x}+\xi,\tau|\mathbf{x})d\xi=
\frac{\langle [\Delta x(\tau)]^n\rangle}{\tau},
$$

<p>resulting in</p>
$$
\frac{\partial W(\mathbf{x},s|\mathbf{x}_0)}{\partial s}=
\sum_{n=1}^{\infty}\frac{(-\xi)^n}{n!}\frac{\partial^n}{\partial x^n}
\left[W(\mathbf{x},s|\mathbf{x}_0)M_n\right].
$$
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-fokker-planck-and-langevin-equations">Importance sampling, Fokker-Planck and Langevin equations </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
<p>When \( \tau \rightarrow 0 \) we assume that \( \langle [\Delta x(\tau)]^n\rangle \rightarrow 0 \) more rapidly than \( \tau \) itself if \( n > 2 \). 
When \( \tau \) is much larger than the standard correlation time of 
system then \( M_n \) for \( n > 2 \) can normally be neglected.
This means that fluctuations become negligible at large time scales.
</p>

<p>If we neglect such terms we can rewrite the ESKC equation as </p>
$$
\frac{\partial W(\mathbf{x},s|\mathbf{x}_0)}{\partial s}=
-\frac{\partial M_1W(\mathbf{x},s|\mathbf{x}_0)}{\partial x}+
\frac{1}{2}\frac{\partial^2 M_2W(\mathbf{x},s|\mathbf{x}_0)}{\partial x^2}.
$$
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-fokker-planck-and-langevin-equations">Importance sampling, Fokker-Planck and Langevin equations </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
<p>In a more compact form we have</p>
$$
\frac{\partial W}{\partial s}=
-\frac{\partial M_1W}{\partial x}+
\frac{1}{2}\frac{\partial^2 M_2W}{\partial x^2},
$$

<p>which is the Fokker-Planck equation!  It is trivial to replace 
position with velocity (momentum).
</p>
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-fokker-planck-and-langevin-equations">Importance sampling, Fokker-Planck and Langevin equations </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b>Langevin equation</b>
<p>
<p>Consider a particle  suspended in a liquid. On its path through the liquid it will continuously collide with the liquid molecules. Because on average the particle  will collide more often on the front side than on the back side, it will experience a systematic force proportional with its velocity, and directed opposite to its velocity. Besides this systematic force the particle  will experience a stochastic force  \( \mathbf{F}(t) \). 
The equations of motion are 
</p>
<ul>
<li> \( \frac{d\mathbf{r}}{dt}=\mathbf{v} \) and</li> 
<li> \( \frac{d\mathbf{v}}{dt}=-\xi \mathbf{v}+\mathbf{F} \).</li>
</ul>
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-fokker-planck-and-langevin-equations">Importance sampling, Fokker-Planck and Langevin equations </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b>Langevin equation</b>
<p>
<p>From hydrodynamics  we know that the friction constant  \( \xi \) is given by</p>
$$
\xi =6\pi \eta a/m 
$$

<p>where \( \eta \) is the viscosity  of the solvent and a is the radius of the particle .</p>

<p>Solving the second equation in the previous slide we get </p>
$$
\mathbf{v}(t)=\mathbf{v}_{0}e^{-\xi t}+\int_{0}^{t}d\tau e^{-\xi (t-\tau )}\mathbf{F }(\tau ). 
$$
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-fokker-planck-and-langevin-equations">Importance sampling, Fokker-Planck and Langevin equations </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b>Langevin equation</b>
<p>
<p>If we want to get some useful information out of this, we have to average over all possible realizations of 
\( \mathbf{F}(t) \), with the initial velocity as a condition. A useful quantity for example is
</p>
$$ 
\langle \mathbf{v}(t)\cdot \mathbf{v}(t)\rangle_{\mathbf{v}_{0}}=v_{0}^{-\xi 2t}
+2\int_{0}^{t}d\tau e^{-\xi (2t-\tau)}\mathbf{v}_{0}\cdot \langle \mathbf{F}(\tau )\rangle_{\mathbf{v}_{0}}
$$

$$  	  	
 +\int_{0}^{t}d\tau ^{\prime }\int_{0}^{t}d\tau e^{-\xi (2t-\tau -\tau ^{\prime })}
\langle \mathbf{F}(\tau )\cdot \mathbf{F}(\tau ^{\prime })\rangle_{ \mathbf{v}_{0}}.
$$
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-fokker-planck-and-langevin-equations">Importance sampling, Fokker-Planck and Langevin equations </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b>Langevin equation</b>
<p>
<p>In order to continue we have to make some assumptions about the conditional averages of the stochastic forces. 
In view of the chaotic character of the stochastic forces the following 
assumptions seem to be appropriate
</p>
$$ 
\langle \mathbf{F}(t)\rangle=0, 
$$

<p>and</p>
$$
\langle \mathbf{F}(t)\cdot \mathbf{F}(t^{\prime })\rangle_{\mathbf{v}_{0}}=  C_{\mathbf{v}_{0}}\delta (t-t^{\prime }).
$$

<p>We omit the subscript \( \mathbf{v}_{0} \), when the quantity of interest turns out to be independent of \( \mathbf{v}_{0} \). Using the last three equations we get</p>
$$
\langle \mathbf{v}(t)\cdot \mathbf{v}(t)\rangle_{\mathbf{v}_{0}}=v_{0}^{2}e^{-2\xi t}+\frac{C_{\mathbf{v}_{0}}}{2\xi }(1-e^{-2\xi t}).
$$

<p>For large t this should be equal to 3kT/m, from which it follows that</p>
$$
\langle \mathbf{F}(t)\cdot \mathbf{F}(t^{\prime })\rangle =6\frac{kT}{m}\xi \delta (t-t^{\prime }). 
$$

<p>This result is called the fluctuation-dissipation theorem .</p>
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-fokker-planck-and-langevin-equations">Importance sampling, Fokker-Planck and Langevin equations </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b>Langevin equation</b>
<p>
<p>Integrating </p>
$$ 
\mathbf{v}(t)=\mathbf{v}_{0}e^{-\xi t}+\int_{0}^{t}d\tau e^{-\xi (t-\tau )}\mathbf{F }(\tau ), 
$$

<p>we get</p>
$$
\mathbf{r}(t)=\mathbf{r}_{0}+\mathbf{v}_{0}\frac{1}{\xi }(1-e^{-\xi t})+
\int_0^td\tau \int_0^{\tau}\tau ^{\prime } e^{-\xi (\tau -\tau ^{\prime })}\mathbf{F}(\tau ^{\prime }), 
$$

<p>from which we calculate the mean square displacement </p>
$$
\langle ( \mathbf{r}(t)-\mathbf{r}_{0})^{2}\rangle _{\mathbf{v}_{0}}=\frac{v_0^2}{\xi}(1-e^{-\xi t})^{2}+\frac{3kT}{m\xi ^{2}}(2\xi t-3+4e^{-\xi t}-e^{-2\xi t}). 
$$
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-fokker-planck-and-langevin-equations">Importance sampling, Fokker-Planck and Langevin equations </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b>Langevin equation</b>
<p>
<p>For very large \( t \) this becomes</p>
$$
\langle (\mathbf{r}(t)-\mathbf{r}_{0})^{2}\rangle =\frac{6kT}{m\xi }t 
$$

<p>from which we get the Einstein relation  </p>
$$ 
D= \frac{kT}{m\xi } 
$$

<p>where we have used \( \langle (\mathbf{r}(t)-\mathbf{r}_{0})^{2}\rangle =6Dt \).</p>
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-programming-elements">Importance sampling, programming elements </h2>

<p>The general derivative formula of the Jastrow factor (or the ansatz for the correlated part of the wave function) is (the subscript \( C \) stands for Correlation)</p>
$$
\frac{1}{\Psi_C}\frac{\partial \Psi_C}{\partial x_k} =
\sum_{i=1}^{k-1}\frac{\partial g_{ik}}{\partial x_k}
+
\sum_{i=k+1}^{N}\frac{\partial g_{ki}}{\partial x_k}
$$

<p>However, 
with our written in way which can be reused later as
</p>
$$
\Psi_C=\prod_{i < j}g(r_{ij})= \exp{\left\{\sum_{i < j}f(r_{ij})\right\}},
$$

<p>the gradient needed for the quantum force and local energy is easy to compute.  
The function \( f(r_{ij}) \) will depends on the system under study. In the equations below we will keep this general form.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling-program-elements">Importance sampling, program elements </h2>

<p>In the Metropolis/Hasting algorithm, the <em>acceptance ratio</em> determines the probability for a particle  to be accepted at a new position. The ratio of the trial wave functions evaluated at the new and current positions is given by (\( OB \) for the onebody  part)</p>
$$
R \equiv \frac{\Psi_{T}^{new}}{\Psi_{T}^{old}} = 
\frac{\Psi_{OB}^{new}}{\Psi_{OB}^{old}}\frac{\Psi_{C}^{new}}{\Psi_{C}^{old}}
$$

<p>Here \( \Psi_{OB} \) is our onebody part (Slater determinant or product of boson single-particle states)  while \( \Psi_{C} \) is our correlation function, or Jastrow factor. 
We need to optimize the \( \nabla \Psi_T / \Psi_T \) ratio and the second derivative as well, that is
the \( \mathbf{\nabla}^2 \Psi_T/\Psi_T \) ratio. The first is needed when we compute the so-called quantum force in importance sampling.
The second is needed when we compute the kinetic energy term of the local energy.
</p>
$$
\frac{\mathbf{\mathbf{\nabla}}  \Psi}{\Psi}  = \frac{\mathbf{\nabla}  (\Psi_{OB} \, \Psi_{C})}{\Psi_{OB} \, \Psi_{C}}  =  \frac{ \Psi_C \mathbf{\nabla}  \Psi_{OB} + \Psi_{OB} \mathbf{\nabla}  \Psi_{C}}{\Psi_{OB} \Psi_{C}} = \frac{\mathbf{\nabla}  \Psi_{OB}}{\Psi_{OB}} + \frac{\mathbf{\nabla}   \Psi_C}{ \Psi_C}
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling">Importance sampling </h2>

<p>The expectation value of the kinetic energy expressed in scaled units  for particle  \( i \) is </p>
$$
 \langle \hat{K}_i \rangle = -\frac{1}{2}\frac{\langle\Psi|\mathbf{\nabla}_{i}^2|\Psi \rangle}{\langle\Psi|\Psi \rangle},
$$

$$
\hat{K}_i = -\frac{1}{2}\frac{\mathbf{\nabla}_{i}^{2} \Psi}{\Psi}.
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling">Importance sampling </h2>

<p>The second derivative which enters the definition of the local energy is </p>
$$
\frac{\mathbf{\nabla}^2 \Psi}{\Psi}=\frac{\mathbf{\nabla}^2 \Psi_{OB}}{\Psi_{OB}} + \frac{\mathbf{\nabla}^2  \Psi_C}{ \Psi_C} + 2 \frac{\mathbf{\nabla}  \Psi_{OB}}{\Psi_{OB}}\cdot\frac{\mathbf{\nabla}   \Psi_C}{ \Psi_C}
$$

<p>We discuss here how to calculate these quantities in an optimal way.</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling">Importance sampling </h2>

<p>We have defined the correlated function as</p>
$$
\Psi_C=\prod_{i < j}g(r_{ij})=\prod_{i < j}^Ng(r_{ij})= \prod_{i=1}^N\prod_{j=i+1}^Ng(r_{ij}),
$$

<p>with 
\( r_{ij}=|\mathbf{r}_i-\mathbf{r}_j|=\sqrt{(x_i-x_j)^2+(y_i-y_j)^2+(z_i-z_j)^2} \) in three dimensions or
\( r_{ij}=|\mathbf{r}_i-\mathbf{r}_j|=\sqrt{(x_i-x_j)^2+(y_i-y_j)^2} \) if we work with two-dimensional systems.
</p>

<p>In our particular case we have</p>
$$
\Psi_C=\prod_{i < j}g(r_{ij})=\exp{\left\{\sum_{i < j}f(r_{ij})\right\}}.
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling">Importance sampling </h2>

<p>The total number of different relative distances \( r_{ij} \) is \( N(N-1)/2 \). In a matrix storage format, the relative distances  form a strictly upper triangular matrix</p>
$$
 \mathbf{r} \equiv \begin{pmatrix}
  0 & r_{1,2} & r_{1,3} & \cdots & r_{1,N} \\
  \vdots & 0       & r_{2,3} & \cdots & r_{2,N} \\
  \vdots & \vdots  & 0  & \ddots & \vdots  \\
  \vdots & \vdots  & \vdots  & \ddots  & r_{N-1,N} \\
  0 & 0  & 0  & \cdots  & 0
 \end{pmatrix}.
$$

<p>This applies to  \( \mathbf{g} = \mathbf{g}(r_{ij}) \) as well. </p>

<p>In our algorithm we will move one particle  at the time, say the \( kth \)-particle.  This sampling will be seen to be particularly efficient when we are going to compute a Slater determinant. </p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling">Importance sampling </h2>

<p>We have that the ratio between Jastrow factors \( R_C \) is given by</p>
$$
R_{C} = \frac{\Psi_{C}^\mathrm{new}}{\Psi_{C}^\mathrm{cur}} =
\prod_{i=1}^{k-1}\frac{g_{ik}^\mathrm{new}}{g_{ik}^\mathrm{cur}}
\prod_{i=k+1}^{N}\frac{ g_{ki}^\mathrm{new}} {g_{ki}^\mathrm{cur}}.
$$

<p>For the Pade-Jastrow form</p>
$$
 R_{C} = \frac{\Psi_{C}^\mathrm{new}}{\Psi_{C}^\mathrm{cur}} = 
\frac{\exp{U_{new}}}{\exp{U_{cur}}} = \exp{\Delta U},
$$

<p>where</p>
$$
\Delta U =
\sum_{i=1}^{k-1}\big(f_{ik}^\mathrm{new}-f_{ik}^\mathrm{cur}\big)
+
\sum_{i=k+1}^{N}\big(f_{ki}^\mathrm{new}-f_{ki}^\mathrm{cur}\big)
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling">Importance sampling </h2>

<p>One needs to develop a special algorithm 
that runs only through the elements of the upper triangular
matrix \( \mathbf{g} \) and have \( k \) as an index. 
</p>

<p>The expression to be derived in the following is of interest when computing the quantum force and the kinetic energy. It has the form</p>
$$
\frac{\mathbf{\nabla}_i\Psi_C}{\Psi_C} = \frac{1}{\Psi_C}\frac{\partial \Psi_C}{\partial x_i},
$$

<p>for all dimensions and with \( i \) running over all particles.</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling">Importance sampling </h2>

<p>For the first derivative only \( N-1 \) terms survive the ratio because the \( g \)-terms that are not differentiated cancel with their corresponding ones in the denominator. Then,</p>
$$
\frac{1}{\Psi_C}\frac{\partial \Psi_C}{\partial x_k} =
\sum_{i=1}^{k-1}\frac{1}{g_{ik}}\frac{\partial g_{ik}}{\partial x_k}
+
\sum_{i=k+1}^{N}\frac{1}{g_{ki}}\frac{\partial g_{ki}}{\partial x_k}.
$$

<p>An equivalent equation is obtained for the exponential form after replacing \( g_{ij} \) by \( \exp(f_{ij}) \), yielding:</p>
$$
\frac{1}{\Psi_C}\frac{\partial \Psi_C}{\partial x_k} =
\sum_{i=1}^{k-1}\frac{\partial g_{ik}}{\partial x_k}
+
\sum_{i=k+1}^{N}\frac{\partial g_{ki}}{\partial x_k},
$$

<p>with both expressions scaling as \( \mathcal{O}(N) \).</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling">Importance sampling </h2>

<p>Using the identity </p>
$$
\frac{\partial}{\partial x_i}g_{ij} = -\frac{\partial}{\partial x_j}g_{ij},
$$

<p>we get expressions where all the derivatives acting on the particle  are represented by the <em>second</em> index of \( g \):</p>
$$
\frac{1}{\Psi_C}\frac{\partial \Psi_C}{\partial x_k} =
\sum_{i=1}^{k-1}\frac{1}{g_{ik}}\frac{\partial g_{ik}}{\partial x_k}
-\sum_{i=k+1}^{N}\frac{1}{g_{ki}}\frac{\partial g_{ki}}{\partial x_i},
$$

<p>and for the exponential case:</p>
$$
\frac{1}{\Psi_C}\frac{\partial \Psi_C}{\partial x_k} =
\sum_{i=1}^{k-1}\frac{\partial g_{ik}}{\partial x_k}
-\sum_{i=k+1}^{N}\frac{\partial g_{ki}}{\partial x_i}.
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling">Importance sampling </h2>

<p>For correlation forms depending only on the scalar distances \( r_{ij} \) we can use the chain rule. Noting that </p>
$$
\frac{\partial g_{ij}}{\partial x_j} = \frac{\partial g_{ij}}{\partial r_{ij}} \frac{\partial r_{ij}}{\partial x_j} = \frac{x_j - x_i}{r_{ij}} \frac{\partial g_{ij}}{\partial r_{ij}},
$$

<p>we arrive at</p>
$$
\frac{1}{\Psi_C}\frac{\partial \Psi_C}{\partial x_k} = 
\sum_{i=1}^{k-1}\frac{1}{g_{ik}} \frac{\mathbf{r_{ik}}}{r_{ik}} \frac{\partial g_{ik}}{\partial r_{ik}}
-\sum_{i=k+1}^{N}\frac{1}{g_{ki}}\frac{\mathbf{r_{ki}}}{r_{ki}}\frac{\partial g_{ki}}{\partial r_{ki}}.
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling">Importance sampling </h2>

<p>Note that for the Pade-Jastrow form we can set \( g_{ij} \equiv g(r_{ij}) = e^{f(r_{ij})} = e^{f_{ij}} \) and </p>
$$
\frac{\partial g_{ij}}{\partial r_{ij}} = g_{ij} \frac{\partial f_{ij}}{\partial r_{ij}}.
$$

<p>Therefore, </p>
$$
\frac{1}{\Psi_{C}}\frac{\partial \Psi_{C}}{\partial x_k} =
\sum_{i=1}^{k-1}\frac{\mathbf{r_{ik}}}{r_{ik}}\frac{\partial f_{ik}}{\partial r_{ik}}
-\sum_{i=k+1}^{N}\frac{\mathbf{r_{ki}}}{r_{ki}}\frac{\partial f_{ki}}{\partial r_{ki}},
$$

<p>where </p>
$$
 \mathbf{r}_{ij} = |\mathbf{r}_j - \mathbf{r}_i| = (x_j - x_i)\mathbf{e}_1 + (y_j - y_i)\mathbf{e}_2 + (z_j - z_i)\mathbf{e}_3
$$

<p>is the relative distance. </p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling">Importance sampling </h2>

<p>The second derivative of the Jastrow factor divided by the Jastrow factor (the way it enters the kinetic energy) is</p>
$$
\left[\frac{\mathbf{\nabla}^2 \Psi_C}{\Psi_C}\right]_x =\  
2\sum_{k=1}^{N}
\sum_{i=1}^{k-1}\frac{\partial^2 g_{ik}}{\partial x_k^2}\ +\ 
\sum_{k=1}^N
\left(
\sum_{i=1}^{k-1}\frac{\partial g_{ik}}{\partial x_k} -
\sum_{i=k+1}^{N}\frac{\partial g_{ki}}{\partial x_i}
\right)^2
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="importance-sampling">Importance sampling </h2>

<p>But we have a simple form for the function, namely</p>
$$
\Psi_{C}=\prod_{i < j}\exp{f(r_{ij})},
$$

<p>and it is easy to see that for particle  \( k \)
we have
</p>
$$
  \frac{\mathbf{\nabla}^2_k \Psi_C}{\Psi_C }=
\sum_{ij\ne k}\frac{(\mathbf{r}_k-\mathbf{r}_i)(\mathbf{r}_k-\mathbf{r}_j)}{r_{ki}r_{kj}}f'(r_{ki})f'(r_{kj})+
\sum_{j\ne k}\left( f''(r_{kj})+\frac{2}{r_{kj}}f'(r_{kj})\right)
$$


<!-- ------------------- end of main content --------------- -->
<center style="font-size:80%">
<!-- copyright --> &copy; 1999-2024, Morten Hjorth-Jensen  Email morten.hjorth-jensen@fys.uio.no. Released under CC Attribution-NonCommercial 4.0 license
</center>
</body>
</html>

