<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html week9.do.txt --pygments_html_style=default --html_style=bloodish --html_links_in_new_window --html_output=week9 --no_mako
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Week 11, March 11-15: Resampling Techniques, Bootstrap and Blocking">
<title>Week 11, March 11-15: Resampling Techniques, Bootstrap and Blocking</title>
<style type="text/css">
/* bloodish style */
body {
  font-family: Helvetica, Verdana, Arial, Sans-serif;
  color: #404040;
  background: #ffffff;
}
h1 { font-size: 1.8em; color: #8A0808; }
h2 { font-size: 1.6em; color: #8A0808; }
h3 { font-size: 1.4em; color: #8A0808; }
h4 { font-size: 1.2em; color: #8A0808; }
a { color: #8A0808; text-decoration:none; }
tt { font-family: "Courier New", Courier; }
p { text-indent: 0px; }
hr { border: 0; width: 80%; border-bottom: 1px solid #aaa}
p.caption { width: 80%; font-style: normal; text-align: left; }
hr.figure { border: 0; width: 80%; border-bottom: 1px solid #aaa; }div.highlight {
    border: 1px solid #cfcfcf;
    border-radius: 2px;
    line-height: 1.21429em;
}
div.cell {
    width: 100%;
    padding: 5px 5px 5px 0;
    margin: 0;
    outline: none;
}
div.input {
    page-break-inside: avoid;
    box-orient: horizontal;
    box-align: stretch;
    display: flex;
    flex-direction: row;
    align-items: stretch;
}
div.inner_cell {
    box-orient: vertical;
    box-align: stretch;
    display: flex;
    flex-direction: column;
    align-items: stretch;
    box-flex: 1;
    flex: 1;
}
div.input_area {
    border: 1px solid #cfcfcf;
    border-radius: 4px;
    background: #f7f7f7;
    line-height: 1.21429em;
}
div.input_area > div.highlight {
    margin: .4em;
    border: none;
    padding: 0;
    background-color: transparent;
}
div.output_wrapper {
    position: relative;
    box-orient: vertical;
    box-align: stretch;
    display: flex;
    flex-direction: column;
    align-items: stretch;
}
.output {
    box-orient: vertical;
    box-align: stretch;
    display: flex;
    flex-direction: column;
    align-items: stretch;
}
div.output_area {
    padding: 0;
    page-break-inside: avoid;
    box-orient: horizontal;
    box-align: stretch;
    display: flex;
    flex-direction: row;
    align-items: stretch;
}
div.output_subarea {
    padding: .4em .4em 0 .4em;
    box-flex: 1;
    flex: 1;
}
div.output_text {
    text-align: left;
    color: #000;
    line-height: 1.21429em;
}
.alert-text-small   { font-size: 80%;  }
.alert-text-large   { font-size: 130%; }
.alert-text-normal  { font-size: 90%;  }
.alert {
  padding:8px 35px 8px 14px; margin-bottom:18px;
  text-shadow:0 1px 0 rgba(255,255,255,0.5);
  border:1px solid #bababa;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  -moz-border-radius: 4px;
  color: #555;
  background-color: #f8f8f8;
  background-position: 10px 5px;
  background-repeat: no-repeat;
  background-size: 38px;
  padding-left: 55px;
  width: 75%;
 }
.alert-block {padding-top:14px; padding-bottom:14px}
.alert-block > p, .alert-block > ul {margin-bottom:1em}
.alert li {margin-top: 1em}
.alert-block p+p {margin-top:5px}
.alert-notice { background-image: url(https://cdn.rawgit.com/doconce/doconce/master/bundled/html_images/small_gray_notice.png); }
.alert-summary  { background-image:url(https://cdn.rawgit.com/doconce/doconce/master/bundled/html_images/small_gray_summary.png); }
.alert-warning { background-image: url(https://cdn.rawgit.com/doconce/doconce/master/bundled/html_images/small_gray_warning.png); }
.alert-question {background-image:url(https://cdn.rawgit.com/doconce/doconce/master/bundled/html_images/small_gray_question.png); }
div { text-align: justify; text-justify: inter-word; }
.tab {
  padding-left: 1.5em;
}
div.toc p,a {
  line-height: 1.3;
  margin-top: 1.1;
  margin-bottom: 1.1;
}
</style>
</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Overview of week 11, March 11-15',
               2,
               None,
               'overview-of-week-11-march-11-15'),
              ('Why resampling methods ?', 2, None, 'why-resampling-methods'),
              ('Statistical analysis', 2, None, 'statistical-analysis'),
              ('And why do we use such methods?',
               2,
               None,
               'and-why-do-we-use-such-methods'),
              ('Central limit theorem', 2, None, 'central-limit-theorem'),
              ('Running many measurements',
               2,
               None,
               'running-many-measurements'),
              ('Adding more definitions', 2, None, 'adding-more-definitions'),
              ('Further rewriting', 2, None, 'further-rewriting'),
              ('The covariance term', 2, None, 'the-covariance-term'),
              ('Rewriting the covariance term',
               2,
               None,
               'rewriting-the-covariance-term'),
              ('Introducing the correlation function',
               2,
               None,
               'introducing-the-correlation-function'),
              ('Statistics, wrapping up from last week',
               2,
               None,
               'statistics-wrapping-up-from-last-week'),
              ('Statistics, final expression',
               2,
               None,
               'statistics-final-expression'),
              ('Statistics, effective number of correlations',
               2,
               None,
               'statistics-effective-number-of-correlations'),
              ('Can we understand this? Time Auto-correlation Function',
               2,
               None,
               'can-we-understand-this-time-auto-correlation-function'),
              ('Time Auto-correlation Function',
               2,
               None,
               'time-auto-correlation-function'),
              ('Time Auto-correlation Function',
               2,
               None,
               'time-auto-correlation-function'),
              ('Time Auto-correlation Function',
               2,
               None,
               'time-auto-correlation-function'),
              ('Time Auto-correlation Function',
               2,
               None,
               'time-auto-correlation-function'),
              ('Time Auto-correlation Function',
               2,
               None,
               'time-auto-correlation-function'),
              ('Correlation Time', 2, None, 'correlation-time'),
              ('Resampling methods: Blocking',
               2,
               None,
               'resampling-methods-blocking'),
              ('Blocking Transformations', 2, None, 'blocking-transformations'),
              ('Blocking Transformations', 2, None, 'blocking-transformations'),
              ('Blocking Transformations, getting there',
               2,
               None,
               'blocking-transformations-getting-there'),
              ('Blocking Transformations, final expressions',
               2,
               None,
               'blocking-transformations-final-expressions'),
              ('Example code form last week',
               2,
               None,
               'example-code-form-last-week'),
              ('Resampling analysis', 2, None, 'resampling-analysis')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "AMS"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- ------------------- main content ---------------------- -->
<center>
<h1>Week 11, March 11-15: Resampling Techniques, Bootstrap and Blocking</h1>
</center>  <!-- document title -->

<!-- author(s): Morten Hjorth-Jensen  Email morten.hjorth-jensen@fys.uio.no -->
<center>
<b>Morten Hjorth-Jensen  Email morten.hjorth-jensen@fys.uio.no</b> [1, 2]
</center>
<!-- institution(s) -->
<center>
[1] <b>Department of Physics and Center fo Computing in Science Education, University of Oslo, Oslo, Norway</b>
</center>
<center>
[2] <b>Department of Physics and Astronomy and Facility for Rare Ion Beams, Michigan State University, East Lansing, Michigan, USA</b>
</center>
<br>
<center>
<h4>March 11-15</h4>
</center> <!-- date -->
<br>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="overview-of-week-11-march-11-15">Overview of week 11, March 11-15 </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b>Topics</b>
<p>
<ol>
<li> Reminder from last week about statistical observables, the central limit theorem and bootstrapping, see notes from last week</li>
<li> Resampling TechniquesL Blocking</li> 
<li> Discussion of onebody densities</li>
<li> Start discussion on optimization and parallelization
<!-- * <a href="https://youtu.be/" target="_blank">Video of lecture TBA</a> -->
<!-- * <a href="https://github.com/CompPhysics/ComputationalPhysics2/blob/gh-pages/doc/HandWrittenNotes/2024/NotesMarch22.pdf" target="_blank">Handwritten notes</a> --></li>
</ol>
</div>


<div class="alert alert-block alert-block alert-text-normal">
<b>Teaching Material, videos and written material</b>
<p>
<ul>
<li> Overview video on the <a href="https://www.youtube.com/watch?v=O_Fj4q8lgmc&ab_channel=MarinStatsLectures-RProgramming%26Statistics" target="_blank">Bootstrap method</a></li>
<li> <a href="https://www.duo.uio.no/bitstream/handle/10852/68360/PhysRevE.98.043304.pdf?sequence=2&isAllowed=y" target="_blank">Marius Johnson's Master thesis on the Blocking Method</a></li>
</ul>
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="why-resampling-methods">Why resampling methods ? </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b>Statistical analysis</b>
<p>
<ul>
<li> Our simulations can be treated as <em>computer experiments</em>. This is particularly the case for Monte Carlo methods</li>
<li> The results can be analysed with the same statistical tools as we would use analysing experimental data.</li>
<li> As in all experiments, we are looking for expectation values and an estimate of how accurate they are, i.e., possible sources for errors.</li>
</ul>
</div>
    

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="statistical-analysis">Statistical analysis </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
<ul>
<li> As in other experiments, many numerical  experiments have two classes of errors:
<ol type="a"></li>
<li> Statistical errors</li>
<li> Systematical errors</li>
</ol>
<li> Statistical errors can be estimated using standard tools from statistics</li>
<li> Systematical errors are method specific and must be treated differently from case to case.</li> 
</ul>
</div>
    

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="and-why-do-we-use-such-methods">And why do we use such methods? </h2>

<p>As you will see below, due to correlations between various
measurements, we need to evaluate the so-called covariance in order to
establish a proper evaluation of the total variance and the thereby
the standard deviation of a given expectation value.
</p>

<p>The covariance however, leads to an evaluation of a double sum over the various stochastic variables. This becomes computationally too expensive to evaluate.
Methods like the Bootstrap, the Jackknife and/or Blocking allow us to circumvent this problem. 
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="central-limit-theorem">Central limit theorem </h2>

<p>Last week we derived the central limit theorem with the following assumptions:</p>

<div class="alert alert-block alert-block alert-text-normal">
<b>Measurement \( i \)</b>
<p>
<p>We assumed that each individual measurement \( x_{ij} \) is represented by stochastic variables which independent and identically distributed (iid).
This defined the sample mean of of experiment \( i \) with \( n \) samples as
</p>
$$
\overline{x}_i=\frac{1}{n}\sum_{j} x_{ij}.
$$

<p>and the sample variance</p>
$$
\sigma^2_i=\frac{1}{n}\sum_{j} \left(x_{ij}-\overline{x}_i\right)^2.
$$
</div>

<p>Note that we use \( n \) instead of \( n-1 \) in the definition of
variance. The sample variance and mean are not necessarily equal to
the exact values we would get if we knew the corresponding probability
distribution.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="running-many-measurements">Running many measurements </h2>

<div class="alert alert-block alert-block alert-text-normal">
<b>Adding \( m \) measurements \( i \)</b>
<p>
<p>With the assumption that the average measurements \( i \) are also defined as  iid stochastic variables and have the same probability function \( p \),
we defined the total average over \( m \) experiments as
</p>
$$
\overline{X}=\frac{1}{m}\sum_{i} \overline{x}_{i}.
$$

<p>and the total variance</p>
$$
\sigma^2_{m}=\frac{1}{m}\sum_{i} \left( \overline{x}_{i}-\overline{X}\right)^2.
$$
</div>

<p>These are the quantities we used in showing that if the individual mean values are iid stochastic variables, then in the limit \( m\rightarrow \infty \), the distribution for \( \overline{X} \) is given by a Gaussian distribution with variance \( \sigma^2_m \).</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="adding-more-definitions">Adding more definitions </h2>

<p>The total sample variance over the \( mn \) measurements is defined as</p>
$$
\sigma^2=\frac{1}{mn}\sum_{i=1}^{m} \sum_{j=1}^{n}\left(x_{ij}-\overline{X}\right)^2.
$$

<p>We have from the equation for \( \sigma_m^2 \) </p>
$$
\overline{x}_i-\overline{X}=\frac{1}{n}\sum_{j=1}^{n}\left(x_{i}-\overline{X}\right),
$$

<p>and introducing the centered value \( \tilde{x}_{ij}=x_{ij}-\overline{X} \), we can rewrite \( \sigma_m^2 \) as</p>
$$
\sigma^2_{m}=\frac{1}{m}\sum_{i} \left( \overline{x}_{i}-\overline{X}\right)^2=\frac{1}{m}\sum_{i=1}^{m}\left[ \frac{i}{n}\sum_{j=1}^{n}\tilde{x}_{ij}\right]^2.
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="further-rewriting">Further rewriting </h2>

<p>We can rewrite the latter in terms of a sum over diagonal elements only and another sum which contains the non-diagonal elements</p>
$$
\begin{align*}
\sigma^2_{m}& =\frac{1}{m}\sum_{i=1}^{m}\left[ \frac{i}{n}\sum_{j=1}^{n}\tilde{x}_{ij}\right]^2 \\
            & = \frac{1}{mn^2}\sum_{i=1}^{m} \sum_{j=1}^{n}\tilde{x}_{ij}^2+\frac{2}{mn^2}\sum_{i=1}^{m} \sum_{j < k}^{n}\tilde{x}_{ij}\tilde{x}_{ik}.
\end{align*}
$$

<p>The first term on the last rhs is nothing but the total sample variance \( \sigma^2 \) divided by \( m \). The second term represents the covariance.</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="the-covariance-term">The covariance term  </h2>

<p>Using the definition of the total sample variance we have</p>
$$
\begin{align*}
\sigma^2_{m}& = \frac{\sigma^2}{m}+\frac{2}{mn^2}\sum_{i=1}^{m} \sum_{j < k}^{n}\tilde{x}_{ij}\tilde{x}_{ik}.
\end{align*}
$$

<p>The first term is what we have used till now in order to estimate the
standard deviation. However, the second term which gives us a measure
of the correlations between different stochastic events, can result in
contributions which give rise to a larger standard deviation and
variance \( \sigma_m^2 \). Note also the evaluation of the second term
leads to a double sum over all events. If we run a VMC calculation
with say \( 10^9 \) Monte carlo samples, the latter term would lead to
\( 10^{18} \) function evaluations. We don't want to, by obvious reasons, to venture into that many evaluations.
</p>

<p>Note also that if our stochastic events are iid then the covariance terms is zero.</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="rewriting-the-covariance-term">Rewriting the covariance term  </h2>

<p>We introduce now a variable \( d=\vert j-k\vert  \) and rewrite </p>
$$
\frac{2}{mn^2}\sum_{i=1}^{m} \sum_{j < k}^{n}\tilde{x}_{ij}\tilde{x}_{ik},
$$

<p>in terms of a function</p>
$$
f_d=\frac{2}{mn}\sum_{i=1}^{m} \sum_{k=1}^{n-d}\tilde{x}_{ik}\tilde{x}_{i(k+d)}.
$$

<p>We note that for \( d= \) we have</p>
$$
f_0=\frac{2}{mn}\sum_{i=1}^{m} \sum_{k=1}^{n}\tilde{x}_{ik}\tilde{x}_{i(k)}=\sigma^2!
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="introducing-the-correlation-function">Introducing the correlation function </h2>

<p>We introduce then a correlation function \( \kappa_d=f_d/\sigma^2 \). Note that \( \kappa_0 =1 \).  We rewrite the variance \( \sigma_m^2 \) as</p>
$$
\begin{align*}
\sigma^2_{m}& = \frac{\sigma^2}{m}\left[1+2\sum_{d=1}^{n-1} \kappa_d\right].
\end{align*}
$$

<p>The code here shows the evolution of \( \kappa_d \) as a function of \( d \) for a series of random numbers. We see that the function \( \kappa_d \) approaches \( 0 \) as \( d\rightarrow \infty \).</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="statistics-wrapping-up-from-last-week">Statistics, wrapping up from last week </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
<p>Let us analyze the problem by splitting up the correlation term into
partial sums of the form:
</p>
$$
f_d = \frac{1}{n-d}\sum_{k=1}^{n-d}(x_k - \bar x_n)(x_{k+d} - \bar x_n)
$$

<p>The correlation term of the error can now be rewritten in terms of
\( f_d \)
</p>
$$
\frac{2}{n}\sum_{k < l} (x_k - \bar x_n)(x_l - \bar x_n) =
2\sum_{d=1}^{n-1} f_d
$$

<p>The value of \( f_d \) reflects the correlation between measurements
separated by the distance \( d \) in the sample samples.  Notice that for
\( d=0 \), \( f \) is just the sample variance, \( \mathrm{var}(x) \). If we divide \( f_d \)
by \( \mathrm{var}(x) \), we arrive at the so called <em>autocorrelation function</em>
</p>
$$
\kappa_d = \frac{f_d}{\mathrm{var}(x)}
$$

<p>which gives us a useful measure of pairwise correlations
starting always at \( 1 \) for \( d=0 \).
</p>
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="statistics-final-expression">Statistics, final expression </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
<p>The sample error can now be
written in terms of the autocorrelation function:
</p>

$$
\begin{align}
\mathrm{err}_X^2 &=
\frac{1}{n}\mathrm{var}(x)+\frac{2}{n}\cdot\mathrm{var}(x)\sum_{d=1}^{n-1}
\frac{f_d}{\mathrm{var}(x)}\nonumber\\ &=&
\left(1+2\sum_{d=1}^{n-1}\kappa_d\right)\frac{1}{n}\mathrm{var}(x)\nonumber\\
&=\frac{\tau}{n}\cdot\mathrm{var}(x)
\label{_auto1}
\end{align}

$$

<p>and we see that \( \mathrm{err}_X \) can be expressed in terms the
uncorrelated sample variance times a correction factor \( \tau \) which
accounts for the correlation between measurements. We call this
correction factor the <em>autocorrelation time</em>:
</p>
$$
\begin{equation}
\tau = 1+2\sum_{d=1}^{n-1}\kappa_d
\label{eq:autocorrelation_time}
\end{equation}
$$
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="statistics-effective-number-of-correlations">Statistics, effective number of correlations </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
<p>For a correlation free experiment, \( \tau \)
equals 1.
</p>

<p>We can interpret a sequential
correlation as an effective reduction of the number of measurements by
a factor \( \tau \). The effective number of measurements becomes:
</p>
$$
n_\mathrm{eff} = \frac{n}{\tau}
$$

<p>To neglect the autocorrelation time \( \tau \) will always cause our
simple uncorrelated estimate of \( \mathrm{err}_X^2\approx \mathrm{var}(x)/n \) to
be less than the true sample error. The estimate of the error will be
too <em>good</em>. On the other hand, the calculation of the full
autocorrelation time poses an efficiency problem if the set of
measurements is very large.
</p>
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="can-we-understand-this-time-auto-correlation-function">Can we understand this? Time Auto-correlation Function </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>

<p>The so-called time-displacement autocorrelation \( \phi(t) \) for a quantity \( \mathbf{M} \) is given by</p>
$$
\phi(t) = \int dt' \left[\mathbf{M}(t')-\langle \mathbf{M} \rangle\right]\left[\mathbf{M}(t'+t)-\langle \mathbf{M} \rangle\right],
$$

<p>which can be rewritten as </p>
$$
\phi(t) = \int dt' \left[\mathbf{M}(t')\mathbf{M}(t'+t)-\langle \mathbf{M} \rangle^2\right],
$$

<p>where \( \langle \mathbf{M} \rangle \) is the average value and
\( \mathbf{M}(t) \) its instantaneous value. We can discretize this function as follows, where we used our
set of computed values \( \mathbf{M}(t) \) for a set of discretized times (our Monte Carlo cycles corresponding to moving all electrons?)
</p>
$$
\phi(t)  = \frac{1}{t_{\mathrm{max}}-t}\sum_{t'=0}^{t_{\mathrm{max}}-t}\mathbf{M}(t')\mathbf{M}(t'+t)
-\frac{1}{t_{\mathrm{max}}-t}\sum_{t'=0}^{t_{\mathrm{max}}-t}\mathbf{M}(t')\times
\frac{1}{t_{\mathrm{max}}-t}\sum_{t'=0}^{t_{\mathrm{max}}-t}\mathbf{M}(t'+t).
\label{eq:phitf}
$$
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="time-auto-correlation-function">Time Auto-correlation Function </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>

<p>One should be careful with times close to \( t_{\mathrm{max}} \), the upper limit of the sums 
becomes small and we end up integrating over a rather small time interval. This means that the statistical
error in \( \phi(t) \) due to the random nature of the fluctuations in \( \mathbf{M}(t) \) can become large.
</p>

<p>One should therefore choose \( t \ll t_{\mathrm{max}} \).</p>

<p>Note that the variable \( \mathbf{M} \) can be any expectation values of interest.</p>

<p>The time-correlation function gives a measure of the correlation between the various values of the variable 
at a time \( t' \) and a time \( t'+t \). If we multiply the values of \( \mathbf{M} \) at these two different times,
we will get a positive contribution if they are fluctuating in the same direction, or a negative value
if they fluctuate in the opposite direction. If we then integrate over time, or use the discretized version of, the time correlation function \( \phi(t) \) should take a non-zero value if the fluctuations are 
correlated, else it should gradually go to zero. For times a long way apart 
the different values of \( \mathbf{M} \)  are most likely 
uncorrelated and \( \phi(t) \) should be zero.
</p>
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="time-auto-correlation-function">Time Auto-correlation Function </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
<p>We can derive the correlation time by observing that our Metropolis algorithm is based on a random
walk in the space of all  possible spin configurations. 
Our probability 
distribution function \( \mathbf{\hat{w}}(t) \) after a given number of time steps \( t \) could be written as
</p>
$$
   \mathbf{\hat{w}}(t) = \mathbf{\hat{W}^t\hat{w}}(0),
$$

<p>with \( \mathbf{\hat{w}}(0) \) the distribution at \( t=0 \) and \( \mathbf{\hat{W}} \) representing the 
transition probability matrix. 
We can always expand \( \mathbf{\hat{w}}(0) \) in terms of the right eigenvectors of 
\( \mathbf{\hat{v}} \) of \( \mathbf{\hat{W}} \) as 
</p>
$$
    \mathbf{\hat{w}}(0)  = \sum_i\alpha_i\mathbf{\hat{v}}_i,
$$

<p>resulting in </p>
$$
   \mathbf{\hat{w}}(t) = \mathbf{\hat{W}}^t\mathbf{\hat{w}}(0)=\mathbf{\hat{W}}^t\sum_i\alpha_i\mathbf{\hat{v}}_i=
\sum_i\lambda_i^t\alpha_i\mathbf{\hat{v}}_i,
$$

<p>with \( \lambda_i \) the \( i^{\mathrm{th}} \) eigenvalue corresponding to  
the eigenvector \( \mathbf{\hat{v}}_i \). 
</p>
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="time-auto-correlation-function">Time Auto-correlation Function </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
<p>If we assume that \( \lambda_0 \) is the largest eigenvector we see that in the limit \( t\rightarrow \infty \),
\( \mathbf{\hat{w}}(t) \) becomes proportional to the corresponding eigenvector 
\( \mathbf{\hat{v}}_0 \). This is our steady state or final distribution. 
</p>

<p>We can relate this property to an observable like the mean energy.
With the probabilty \( \mathbf{\hat{w}}(t) \) (which in our case is the squared trial wave function) we
can write the expectation values as 
</p>
$$
 \langle \mathbf{M}(t) \rangle  = \sum_{\mu} \mathbf{\hat{w}}(t)_{\mu}\mathbf{M}_{\mu},
$$

<p>or as the scalar of a  vector product</p>
$$
 \langle \mathbf{M}(t) \rangle  = \mathbf{\hat{w}}(t)\mathbf{m},
$$

<p>with \( \mathbf{m} \) being the vector whose elements are the values of \( \mathbf{M}_{\mu} \) in its 
various microstates \( \mu \).
</p>
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="time-auto-correlation-function">Time Auto-correlation Function </h2>

<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>

<p>We rewrite this relation  as</p>
$$
 \langle \mathbf{M}(t) \rangle  = \mathbf{\hat{w}}(t)\mathbf{m}=\sum_i\lambda_i^t\alpha_i\mathbf{\hat{v}}_i\mathbf{m}_i.
$$

<p>If we define \( m_i=\mathbf{\hat{v}}_i\mathbf{m}_i \) as the expectation value of
\( \mathbf{M} \) in the \( i^{\mathrm{th}} \) eigenstate we can rewrite the last equation as
</p>
$$
 \langle \mathbf{M}(t) \rangle  = \sum_i\lambda_i^t\alpha_im_i.
$$

<p>Since we have that in the limit \( t\rightarrow \infty \) the mean value is dominated by the 
the largest eigenvalue \( \lambda_0 \), we can rewrite the last equation as
</p>
$$
 \langle \mathbf{M}(t) \rangle  = \langle \mathbf{M}(\infty) \rangle+\sum_{i\ne 0}\lambda_i^t\alpha_im_i.
$$

<p>We define the quantity</p>
$$
   \tau_i=-\frac{1}{log\lambda_i},
$$

<p>and rewrite the last expectation value as</p>
$$
 \langle \mathbf{M}(t) \rangle  = \langle \mathbf{M}(\infty) \rangle+\sum_{i\ne 0}\alpha_im_ie^{-t/\tau_i}.
\label{eq:finalmeanm}
$$
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="time-auto-correlation-function">Time Auto-correlation Function </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>

<p>The quantities \( \tau_i \) are the correlation times for the system. They control also the auto-correlation function 
discussed above.  The longest correlation time is obviously given by the second largest
eigenvalue \( \tau_1 \), which normally defines the correlation time discussed above. For large times, this is the 
only correlation time that survives. If higher eigenvalues of the transition matrix are well separated from 
\( \lambda_1 \) and we simulate long enough,  \( \tau_1 \) may well define the correlation time. 
In other cases we may not be able to extract a reliable result for \( \tau_1 \). 
Coming back to the time correlation function \( \phi(t) \) we can present a more general definition in terms
of the mean magnetizations $ \langle \mathbf{M}(t) \rangle$. Recalling that the mean value is equal 
to $ \langle \mathbf{M}(\infty) \rangle$ we arrive at the expectation values
</p>
$$
\phi(t) =\langle \mathbf{M}(0)-\mathbf{M}(\infty)\rangle \langle \mathbf{M}(t)-\mathbf{M}(\infty)\rangle,
$$

<p>resulting in</p>
$$
\phi(t) =\sum_{i,j\ne 0}m_i\alpha_im_j\alpha_je^{-t/\tau_i},
$$

<p>which is appropriate for all times.</p>
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="correlation-time">Correlation Time </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>

<p>If the correlation function decays exponentially</p>
$$ \phi (t) \sim \exp{(-t/\tau)}$$

<p>then the exponential correlation time can be computed as the average</p>
$$   \tau_{\mathrm{exp}}  =  -\langle  \frac{t}{log|\frac{\phi(t)}{\phi(0)}|} \rangle. $$

<p>If the decay is exponential, then</p>
$$  \int_0^{\infty} dt \phi(t)  = \int_0^{\infty} dt \phi(0)\exp{(-t/\tau)}  = \tau \phi(0),$$

<p>which  suggests another measure of correlation</p>
$$   \tau_{\mathrm{int}} = \sum_k \frac{\phi(k)}{\phi(0)}, $$

<p>called the integrated correlation time.</p>
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="resampling-methods-blocking">Resampling methods: Blocking  </h2>

<p>The blocking method was made popular by <a href="https://aip.scitation.org/doi/10.1063/1.457480" target="_blank">Flyvbjerg and Pedersen (1989)</a>
and has become one of the standard ways to estimate
\( V(\widehat{\theta}) \) for exactly one \( \widehat{\theta} \), namely
\( \widehat{\theta} = \overline{X} \). 
</p>

<p>Assume \( n = 2^d \) for some integer \( d>1 \) and \( X_1,X_2,\cdots, X_n \) is a stationary time series to begin with. 
Moreover, assume that the time series is asymptotically uncorrelated. We switch to vector notation by arranging \( X_1,X_2,\cdots,X_n \) in an \( n \)-tuple. Define:
</p>
$$
\begin{align*}
\hat{X} = (X_1,X_2,\cdots,X_n).
\end{align*}
$$

<p>The strength of the blocking method is when the number of
observations, \( n \) is large. For large \( n \), the complexity of dependent
bootstrapping scales poorly, but the blocking method does not,
moreover, it becomes more accurate the larger \( n \) is.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="blocking-transformations">Blocking Transformations </h2>
<p> We now define
blocking transformations. The idea is to take the mean of subsequent
pair of elements from \( \vec{X} \) and form a new vector
\( \vec{X}_1 \). Continuing in the same way by taking the mean of
subsequent pairs of elements of \( \vec{X}_1 \) we obtain \( \vec{X}_2 \), and
so on. 
Define \( \vec{X}_i \) recursively by:
</p>

$$
\begin{align} 
(\vec{X}_0)_k &\equiv (\vec{X})_k \nonumber \\
(\vec{X}_{i+1})_k &\equiv \frac{1}{2}\Big( (\vec{X}_i)_{2k-1} +
(\vec{X}_i)_{2k} \Big) \qquad \text{for all} \qquad 1 \leq i \leq d-1
\label{_auto2}
\end{align} 
$$

<p>The quantity \( \vec{X}_k \) is
subject to \( k \) <b>blocking transformations</b>.  We now have \( d \) vectors
\( \vec{X}_0, \vec{X}_1,\cdots,\vec X_{d-1} \) containing the subsequent
averages of observations. It turns out that if the components of
\( \vec{X} \) is a stationary time series, then the components of
\( \vec{X}_i \) is a stationary time series for all \( 0 \leq i \leq d-1 \)
</p>

<p>We can then compute the autocovariance, the variance, sample mean, and
number of observations for each \( i \). 
Let \( \gamma_i, \sigma_i^2,
\overline{X}_i \) denote the autocovariance, variance and average of the
elements of \( \vec{X}_i \) and let \( n_i \) be the number of elements of
\( \vec{X}_i \). It follows by induction that \( n_i = n/2^i \). 
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="blocking-transformations">Blocking Transformations </h2>

<p>Using the
definition of the blocking transformation and the distributive
property of the covariance, it is clear that since \( h =|i-j| \)
we can define
</p>
$$
\begin{align}
\gamma_{k+1}(h) &= cov\left( ({X}_{k+1})_{i}, ({X}_{k+1})_{j} \right) \nonumber \\
&=  \frac{1}{4}cov\left( ({X}_{k})_{2i-1} + ({X}_{k})_{2i}, ({X}_{k})_{2j-1} + ({X}_{k})_{2j} \right) \nonumber \\
&=  \frac{1}{2}\gamma_{k}(2h) + \frac{1}{2}\gamma_k(2h+1) \hspace{0.1cm} \mathrm{h = 0} 
\label{_auto3}\\
&=\frac{1}{4}\gamma_k(2h-1) + \frac{1}{2}\gamma_k(2h) + \frac{1}{4}\gamma_k(2h+1) \quad \mathrm{else}
\label{_auto4}
\end{align}
$$

<p>The quantity \( \hat{X} \) is asymptotic uncorrelated by assumption, \( \hat{X}_k \) is also asymptotic uncorrelated. Let's turn our attention to the variance of the sample mean \( V(\overline{X}) \). </p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="blocking-transformations-getting-there">Blocking Transformations, getting there </h2>
<p>We have</p>
$$
\begin{align}
V(\overline{X}_k) = \frac{\sigma_k^2}{n_k} + \underbrace{\frac{2}{n_k} \sum_{h=1}^{n_k-1}\left( 1 - \frac{h}{n_k} \right)\gamma_k(h)}_{\equiv e_k} = \frac{\sigma^2_k}{n_k} + e_k \quad \text{if} \quad \gamma_k(0) = \sigma_k^2. 
\label{_auto5}
\end{align}
$$

<p>The term \( e_k \) is called the <b>truncation error</b>: </p>
$$
\begin{equation}
e_k = \frac{2}{n_k} \sum_{h=1}^{n_k-1}\left( 1 - \frac{h}{n_k} \right)\gamma_k(h). 
\label{_auto6}
\end{equation}
$$

<p>We can show that \( V(\overline{X}_i) = V(\overline{X}_j) \) for all \( 0 \leq i \leq d-1 \) and \( 0 \leq j \leq d-1 \). </p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="blocking-transformations-final-expressions">Blocking Transformations, final expressions </h2>

<p>We can then wrap up</p>
$$
\begin{align}
n_{j+1} \overline{X}_{j+1}  &= \sum_{i=1}^{n_{j+1}} (\hat{X}_{j+1})_i =  \frac{1}{2}\sum_{i=1}^{n_{j}/2} (\hat{X}_{j})_{2i-1} + (\hat{X}_{j})_{2i} \nonumber \\
&= \frac{1}{2}\left[ (\hat{X}_j)_1 + (\hat{X}_j)_2 + \cdots + (\hat{X}_j)_{n_j} \right] = \underbrace{\frac{n_j}{2}}_{=n_{j+1}} \overline{X}_j = n_{j+1}\overline{X}_j. 
\label{_auto7}
\end{align}
$$

<p>By repeated use of this equation we get \( V(\overline{X}_i) = V(\overline{X}_0) = V(\overline{X}) \) for all \( 0 \leq i \leq d-1 \). This has the consequence that</p>
$$
\begin{align}
V(\overline{X}) = \frac{\sigma_k^2}{n_k} + e_k \qquad \text{for all} \qquad 0 \leq k \leq d-1. \label{eq:convergence}
\end{align}
$$

<p>Flyvbjerg and Petersen demonstrated that the sequence
\( \{e_k\}_{k=0}^{d-1} \) is decreasing, and conjecture that the term
\( e_k \) can be made as small as we would like by making \( k \) (and hence
\( d \)) sufficiently large. The sequence is decreasing (Master of Science thesis by Marius Jonsson, UiO 2018).
It means we can apply blocking transformations until
\( e_k \) is sufficiently small, and then estimate \( V(\overline{X}) \) by
\( \widehat{\sigma}^2_k/n_k \). 
</p>

<p>For an elegant solution and proof of the blocking method, see the recent article of <a href="https://journals.aps.org/pre/abstract/10.1103/PhysRevE.98.043304" target="_blank">Marius Jonsson (former MSc student of the Computational Physics group)</a>.</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="example-code-form-last-week">Example code form last week </h2>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;"><span style="color: #408080; font-style: italic"># 2-electron VMC code for 2dim quantum dot with importance sampling</span>
<span style="color: #408080; font-style: italic"># Using gaussian rng for new positions and Metropolis- Hastings </span>
<span style="color: #408080; font-style: italic"># Added energy minimization</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">math</span> <span style="color: #008000; font-weight: bold">import</span> exp, sqrt
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">random</span> <span style="color: #008000; font-weight: bold">import</span> random, seed, normalvariate
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">matplotlib.pyplot</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">plt</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">mpl_toolkits.mplot3d</span> <span style="color: #008000; font-weight: bold">import</span> Axes3D
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">matplotlib</span> <span style="color: #008000; font-weight: bold">import</span> cm
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">matplotlib.ticker</span> <span style="color: #008000; font-weight: bold">import</span> LinearLocator, FormatStrFormatter
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">scipy.optimize</span> <span style="color: #008000; font-weight: bold">import</span> minimize
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">sys</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">os</span>

<span style="color: #408080; font-style: italic"># Where to save data files</span>
PROJECT_ROOT_DIR <span style="color: #666666">=</span> <span style="color: #BA2121">&quot;Results&quot;</span>
DATA_ID <span style="color: #666666">=</span> <span style="color: #BA2121">&quot;Results/EnergyMin&quot;</span>

<span style="color: #008000; font-weight: bold">if</span> <span style="color: #AA22FF; font-weight: bold">not</span> os<span style="color: #666666">.</span>path<span style="color: #666666">.</span>exists(PROJECT_ROOT_DIR):
    os<span style="color: #666666">.</span>mkdir(PROJECT_ROOT_DIR)

<span style="color: #008000; font-weight: bold">if</span> <span style="color: #AA22FF; font-weight: bold">not</span> os<span style="color: #666666">.</span>path<span style="color: #666666">.</span>exists(DATA_ID):
    os<span style="color: #666666">.</span>makedirs(DATA_ID)

<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">data_path</span>(dat_id):
    <span style="color: #008000; font-weight: bold">return</span> os<span style="color: #666666">.</span>path<span style="color: #666666">.</span>join(DATA_ID, dat_id)

outfile <span style="color: #666666">=</span> <span style="color: #008000">open</span>(data_path(<span style="color: #BA2121">&quot;Energies.dat&quot;</span>),<span style="color: #BA2121">&#39;w&#39;</span>)


<span style="color: #408080; font-style: italic"># Trial wave function for the 2-electron quantum dot in two dims</span>
<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">WaveFunction</span>(r,alpha,beta):
    r1 <span style="color: #666666">=</span> r[<span style="color: #666666">0</span>,<span style="color: #666666">0</span>]<span style="color: #666666">**2</span> <span style="color: #666666">+</span> r[<span style="color: #666666">0</span>,<span style="color: #666666">1</span>]<span style="color: #666666">**2</span>
    r2 <span style="color: #666666">=</span> r[<span style="color: #666666">1</span>,<span style="color: #666666">0</span>]<span style="color: #666666">**2</span> <span style="color: #666666">+</span> r[<span style="color: #666666">1</span>,<span style="color: #666666">1</span>]<span style="color: #666666">**2</span>
    r12 <span style="color: #666666">=</span> sqrt((r[<span style="color: #666666">0</span>,<span style="color: #666666">0</span>]<span style="color: #666666">-</span>r[<span style="color: #666666">1</span>,<span style="color: #666666">0</span>])<span style="color: #666666">**2</span> <span style="color: #666666">+</span> (r[<span style="color: #666666">0</span>,<span style="color: #666666">1</span>]<span style="color: #666666">-</span>r[<span style="color: #666666">1</span>,<span style="color: #666666">1</span>])<span style="color: #666666">**2</span>)
    deno <span style="color: #666666">=</span> r12<span style="color: #666666">/</span>(<span style="color: #666666">1+</span>beta<span style="color: #666666">*</span>r12)
    <span style="color: #008000; font-weight: bold">return</span> exp(<span style="color: #666666">-0.5*</span>alpha<span style="color: #666666">*</span>(r1<span style="color: #666666">+</span>r2)<span style="color: #666666">+</span>deno)

<span style="color: #408080; font-style: italic"># Local energy  for the 2-electron quantum dot in two dims, using analytical local energy</span>
<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">LocalEnergy</span>(r,alpha,beta):
    
    r1 <span style="color: #666666">=</span> (r[<span style="color: #666666">0</span>,<span style="color: #666666">0</span>]<span style="color: #666666">**2</span> <span style="color: #666666">+</span> r[<span style="color: #666666">0</span>,<span style="color: #666666">1</span>]<span style="color: #666666">**2</span>)
    r2 <span style="color: #666666">=</span> (r[<span style="color: #666666">1</span>,<span style="color: #666666">0</span>]<span style="color: #666666">**2</span> <span style="color: #666666">+</span> r[<span style="color: #666666">1</span>,<span style="color: #666666">1</span>]<span style="color: #666666">**2</span>)
    r12 <span style="color: #666666">=</span> sqrt((r[<span style="color: #666666">0</span>,<span style="color: #666666">0</span>]<span style="color: #666666">-</span>r[<span style="color: #666666">1</span>,<span style="color: #666666">0</span>])<span style="color: #666666">**2</span> <span style="color: #666666">+</span> (r[<span style="color: #666666">0</span>,<span style="color: #666666">1</span>]<span style="color: #666666">-</span>r[<span style="color: #666666">1</span>,<span style="color: #666666">1</span>])<span style="color: #666666">**2</span>)
    deno <span style="color: #666666">=</span> <span style="color: #666666">1.0/</span>(<span style="color: #666666">1+</span>beta<span style="color: #666666">*</span>r12)
    deno2 <span style="color: #666666">=</span> deno<span style="color: #666666">*</span>deno
    <span style="color: #008000; font-weight: bold">return</span> <span style="color: #666666">0.5*</span>(<span style="color: #666666">1-</span>alpha<span style="color: #666666">*</span>alpha)<span style="color: #666666">*</span>(r1 <span style="color: #666666">+</span> r2) <span style="color: #666666">+2.0*</span>alpha <span style="color: #666666">+</span> <span style="color: #666666">1.0/</span>r12<span style="color: #666666">+</span>deno2<span style="color: #666666">*</span>(alpha<span style="color: #666666">*</span>r12<span style="color: #666666">-</span>deno2<span style="color: #666666">+2*</span>beta<span style="color: #666666">*</span>deno<span style="color: #666666">-1.0/</span>r12)

<span style="color: #408080; font-style: italic"># Derivate of wave function ansatz as function of variational parameters</span>
<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">DerivativeWFansatz</span>(r,alpha,beta):
    
    WfDer  <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros((<span style="color: #666666">2</span>), np<span style="color: #666666">.</span>double)
    r1 <span style="color: #666666">=</span> (r[<span style="color: #666666">0</span>,<span style="color: #666666">0</span>]<span style="color: #666666">**2</span> <span style="color: #666666">+</span> r[<span style="color: #666666">0</span>,<span style="color: #666666">1</span>]<span style="color: #666666">**2</span>)
    r2 <span style="color: #666666">=</span> (r[<span style="color: #666666">1</span>,<span style="color: #666666">0</span>]<span style="color: #666666">**2</span> <span style="color: #666666">+</span> r[<span style="color: #666666">1</span>,<span style="color: #666666">1</span>]<span style="color: #666666">**2</span>)
    r12 <span style="color: #666666">=</span> sqrt((r[<span style="color: #666666">0</span>,<span style="color: #666666">0</span>]<span style="color: #666666">-</span>r[<span style="color: #666666">1</span>,<span style="color: #666666">0</span>])<span style="color: #666666">**2</span> <span style="color: #666666">+</span> (r[<span style="color: #666666">0</span>,<span style="color: #666666">1</span>]<span style="color: #666666">-</span>r[<span style="color: #666666">1</span>,<span style="color: #666666">1</span>])<span style="color: #666666">**2</span>)
    deno <span style="color: #666666">=</span> <span style="color: #666666">1.0/</span>(<span style="color: #666666">1+</span>beta<span style="color: #666666">*</span>r12)
    deno2 <span style="color: #666666">=</span> deno<span style="color: #666666">*</span>deno
    WfDer[<span style="color: #666666">0</span>] <span style="color: #666666">=</span> <span style="color: #666666">-0.5*</span>(r1<span style="color: #666666">+</span>r2)
    WfDer[<span style="color: #666666">1</span>] <span style="color: #666666">=</span> <span style="color: #666666">-</span>r12<span style="color: #666666">*</span>r12<span style="color: #666666">*</span>deno2
    <span style="color: #008000; font-weight: bold">return</span>  WfDer

<span style="color: #408080; font-style: italic"># Setting up the quantum force for the two-electron quantum dot, recall that it is a vector</span>
<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">QuantumForce</span>(r,alpha,beta):

    qforce <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros((NumberParticles,Dimension), np<span style="color: #666666">.</span>double)
    r12 <span style="color: #666666">=</span> sqrt((r[<span style="color: #666666">0</span>,<span style="color: #666666">0</span>]<span style="color: #666666">-</span>r[<span style="color: #666666">1</span>,<span style="color: #666666">0</span>])<span style="color: #666666">**2</span> <span style="color: #666666">+</span> (r[<span style="color: #666666">0</span>,<span style="color: #666666">1</span>]<span style="color: #666666">-</span>r[<span style="color: #666666">1</span>,<span style="color: #666666">1</span>])<span style="color: #666666">**2</span>)
    deno <span style="color: #666666">=</span> <span style="color: #666666">1.0/</span>(<span style="color: #666666">1+</span>beta<span style="color: #666666">*</span>r12)
    qforce[<span style="color: #666666">0</span>,:] <span style="color: #666666">=</span> <span style="color: #666666">-2*</span>r[<span style="color: #666666">0</span>,:]<span style="color: #666666">*</span>alpha<span style="color: #666666">*</span>(r[<span style="color: #666666">0</span>,:]<span style="color: #666666">-</span>r[<span style="color: #666666">1</span>,:])<span style="color: #666666">*</span>deno<span style="color: #666666">*</span>deno<span style="color: #666666">/</span>r12
    qforce[<span style="color: #666666">1</span>,:] <span style="color: #666666">=</span> <span style="color: #666666">-2*</span>r[<span style="color: #666666">1</span>,:]<span style="color: #666666">*</span>alpha<span style="color: #666666">*</span>(r[<span style="color: #666666">1</span>,:]<span style="color: #666666">-</span>r[<span style="color: #666666">0</span>,:])<span style="color: #666666">*</span>deno<span style="color: #666666">*</span>deno<span style="color: #666666">/</span>r12
    <span style="color: #008000; font-weight: bold">return</span> qforce
    

<span style="color: #408080; font-style: italic"># Computing the derivative of the energy and the energy </span>
<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">EnergyDerivative</span>(x0):

    
    <span style="color: #408080; font-style: italic"># Parameters in the Fokker-Planck simulation of the quantum force</span>
    D <span style="color: #666666">=</span> <span style="color: #666666">0.5</span>
    TimeStep <span style="color: #666666">=</span> <span style="color: #666666">0.05</span>
    <span style="color: #408080; font-style: italic"># positions</span>
    PositionOld <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros((NumberParticles,Dimension), np<span style="color: #666666">.</span>double)
    PositionNew <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros((NumberParticles,Dimension), np<span style="color: #666666">.</span>double)
    <span style="color: #408080; font-style: italic"># Quantum force</span>
    QuantumForceOld <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros((NumberParticles,Dimension), np<span style="color: #666666">.</span>double)
    QuantumForceNew <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros((NumberParticles,Dimension), np<span style="color: #666666">.</span>double)

    energy <span style="color: #666666">=</span> <span style="color: #666666">0.0</span>
    DeltaE <span style="color: #666666">=</span> <span style="color: #666666">0.0</span>
    alpha <span style="color: #666666">=</span> x0[<span style="color: #666666">0</span>]
    beta <span style="color: #666666">=</span> x0[<span style="color: #666666">1</span>]
    EnergyDer <span style="color: #666666">=</span> <span style="color: #666666">0.0</span>
    DeltaPsi <span style="color: #666666">=</span> <span style="color: #666666">0.0</span>
    DerivativePsiE <span style="color: #666666">=</span> <span style="color: #666666">0.0</span> 
    <span style="color: #408080; font-style: italic">#Initial position</span>
    <span style="color: #008000; font-weight: bold">for</span> i <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(NumberParticles):
        <span style="color: #008000; font-weight: bold">for</span> j <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(Dimension):
            PositionOld[i,j] <span style="color: #666666">=</span> normalvariate(<span style="color: #666666">0.0</span>,<span style="color: #666666">1.0</span>)<span style="color: #666666">*</span>sqrt(TimeStep)
    wfold <span style="color: #666666">=</span> WaveFunction(PositionOld,alpha,beta)
    QuantumForceOld <span style="color: #666666">=</span> QuantumForce(PositionOld,alpha, beta)

    <span style="color: #408080; font-style: italic">#Loop over MC MCcycles</span>
    <span style="color: #008000; font-weight: bold">for</span> MCcycle <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(NumberMCcycles):
        <span style="color: #408080; font-style: italic">#Trial position moving one particle at the time</span>
        <span style="color: #008000; font-weight: bold">for</span> i <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(NumberParticles):
            <span style="color: #008000; font-weight: bold">for</span> j <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(Dimension):
                PositionNew[i,j] <span style="color: #666666">=</span> PositionOld[i,j]<span style="color: #666666">+</span>normalvariate(<span style="color: #666666">0.0</span>,<span style="color: #666666">1.0</span>)<span style="color: #666666">*</span>sqrt(TimeStep)<span style="color: #666666">+</span>\
                                       QuantumForceOld[i,j]<span style="color: #666666">*</span>TimeStep<span style="color: #666666">*</span>D
            wfnew <span style="color: #666666">=</span> WaveFunction(PositionNew,alpha,beta)
            QuantumForceNew <span style="color: #666666">=</span> QuantumForce(PositionNew,alpha, beta)
            GreensFunction <span style="color: #666666">=</span> <span style="color: #666666">0.0</span>
            <span style="color: #008000; font-weight: bold">for</span> j <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(Dimension):
                GreensFunction <span style="color: #666666">+=</span> <span style="color: #666666">0.5*</span>(QuantumForceOld[i,j]<span style="color: #666666">+</span>QuantumForceNew[i,j])<span style="color: #666666">*</span>\
	                              (D<span style="color: #666666">*</span>TimeStep<span style="color: #666666">*0.5*</span>(QuantumForceOld[i,j]<span style="color: #666666">-</span>QuantumForceNew[i,j])<span style="color: #666666">-</span>\
                                      PositionNew[i,j]<span style="color: #666666">+</span>PositionOld[i,j])
      
            GreensFunction <span style="color: #666666">=</span> exp(GreensFunction)
            ProbabilityRatio <span style="color: #666666">=</span> GreensFunction<span style="color: #666666">*</span>wfnew<span style="color: #666666">**2/</span>wfold<span style="color: #666666">**2</span>
            <span style="color: #408080; font-style: italic">#Metropolis-Hastings test to see whether we accept the move</span>
            <span style="color: #008000; font-weight: bold">if</span> random() <span style="color: #666666">&lt;=</span> ProbabilityRatio:
                <span style="color: #008000; font-weight: bold">for</span> j <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(Dimension):
                    PositionOld[i,j] <span style="color: #666666">=</span> PositionNew[i,j]
                    QuantumForceOld[i,j] <span style="color: #666666">=</span> QuantumForceNew[i,j]
                wfold <span style="color: #666666">=</span> wfnew
        DeltaE <span style="color: #666666">=</span> LocalEnergy(PositionOld,alpha,beta)
        DerPsi <span style="color: #666666">=</span> DerivativeWFansatz(PositionOld,alpha,beta)
        DeltaPsi <span style="color: #666666">+=</span> DerPsi
        energy <span style="color: #666666">+=</span> DeltaE
        DerivativePsiE <span style="color: #666666">+=</span> DerPsi<span style="color: #666666">*</span>DeltaE
            
    <span style="color: #408080; font-style: italic"># We calculate mean values</span>
    energy <span style="color: #666666">/=</span> NumberMCcycles
    DerivativePsiE <span style="color: #666666">/=</span> NumberMCcycles
    DeltaPsi <span style="color: #666666">/=</span> NumberMCcycles
    EnergyDer  <span style="color: #666666">=</span> <span style="color: #666666">2*</span>(DerivativePsiE<span style="color: #666666">-</span>DeltaPsi<span style="color: #666666">*</span>energy)
    <span style="color: #008000; font-weight: bold">return</span> EnergyDer


<span style="color: #408080; font-style: italic"># Computing the expectation value of the local energy </span>
<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">Energy</span>(x0):
    <span style="color: #408080; font-style: italic"># Parameters in the Fokker-Planck simulation of the quantum force</span>
    D <span style="color: #666666">=</span> <span style="color: #666666">0.5</span>
    TimeStep <span style="color: #666666">=</span> <span style="color: #666666">0.05</span>
    <span style="color: #408080; font-style: italic"># positions</span>
    PositionOld <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros((NumberParticles,Dimension), np<span style="color: #666666">.</span>double)
    PositionNew <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros((NumberParticles,Dimension), np<span style="color: #666666">.</span>double)
    <span style="color: #408080; font-style: italic"># Quantum force</span>
    QuantumForceOld <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros((NumberParticles,Dimension), np<span style="color: #666666">.</span>double)
    QuantumForceNew <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros((NumberParticles,Dimension), np<span style="color: #666666">.</span>double)

    energy <span style="color: #666666">=</span> <span style="color: #666666">0.0</span>
    DeltaE <span style="color: #666666">=</span> <span style="color: #666666">0.0</span>
    alpha <span style="color: #666666">=</span> x0[<span style="color: #666666">0</span>]
    beta <span style="color: #666666">=</span> x0[<span style="color: #666666">1</span>]
    <span style="color: #408080; font-style: italic">#Initial position</span>
    <span style="color: #008000; font-weight: bold">for</span> i <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(NumberParticles):
        <span style="color: #008000; font-weight: bold">for</span> j <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(Dimension):
            PositionOld[i,j] <span style="color: #666666">=</span> normalvariate(<span style="color: #666666">0.0</span>,<span style="color: #666666">1.0</span>)<span style="color: #666666">*</span>sqrt(TimeStep)
    wfold <span style="color: #666666">=</span> WaveFunction(PositionOld,alpha,beta)
    QuantumForceOld <span style="color: #666666">=</span> QuantumForce(PositionOld,alpha, beta)

    <span style="color: #408080; font-style: italic">#Loop over MC MCcycles</span>
    <span style="color: #008000; font-weight: bold">for</span> MCcycle <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(NumberMCcycles):
        <span style="color: #408080; font-style: italic">#Trial position moving one particle at the time</span>
        <span style="color: #008000; font-weight: bold">for</span> i <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(NumberParticles):
            <span style="color: #008000; font-weight: bold">for</span> j <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(Dimension):
                PositionNew[i,j] <span style="color: #666666">=</span> PositionOld[i,j]<span style="color: #666666">+</span>normalvariate(<span style="color: #666666">0.0</span>,<span style="color: #666666">1.0</span>)<span style="color: #666666">*</span>sqrt(TimeStep)<span style="color: #666666">+</span>\
                                       QuantumForceOld[i,j]<span style="color: #666666">*</span>TimeStep<span style="color: #666666">*</span>D
            wfnew <span style="color: #666666">=</span> WaveFunction(PositionNew,alpha,beta)
            QuantumForceNew <span style="color: #666666">=</span> QuantumForce(PositionNew,alpha, beta)
            GreensFunction <span style="color: #666666">=</span> <span style="color: #666666">0.0</span>
            <span style="color: #008000; font-weight: bold">for</span> j <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(Dimension):
                GreensFunction <span style="color: #666666">+=</span> <span style="color: #666666">0.5*</span>(QuantumForceOld[i,j]<span style="color: #666666">+</span>QuantumForceNew[i,j])<span style="color: #666666">*</span>\
	                              (D<span style="color: #666666">*</span>TimeStep<span style="color: #666666">*0.5*</span>(QuantumForceOld[i,j]<span style="color: #666666">-</span>QuantumForceNew[i,j])<span style="color: #666666">-</span>\
                                      PositionNew[i,j]<span style="color: #666666">+</span>PositionOld[i,j])
      
            GreensFunction <span style="color: #666666">=</span> exp(GreensFunction)
            ProbabilityRatio <span style="color: #666666">=</span> GreensFunction<span style="color: #666666">*</span>wfnew<span style="color: #666666">**2/</span>wfold<span style="color: #666666">**2</span>
            <span style="color: #408080; font-style: italic">#Metropolis-Hastings test to see whether we accept the move</span>
            <span style="color: #008000; font-weight: bold">if</span> random() <span style="color: #666666">&lt;=</span> ProbabilityRatio:
                <span style="color: #008000; font-weight: bold">for</span> j <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(Dimension):
                    PositionOld[i,j] <span style="color: #666666">=</span> PositionNew[i,j]
                    QuantumForceOld[i,j] <span style="color: #666666">=</span> QuantumForceNew[i,j]
                wfold <span style="color: #666666">=</span> wfnew
        DeltaE <span style="color: #666666">=</span> LocalEnergy(PositionOld,alpha,beta)
        energy <span style="color: #666666">+=</span> DeltaE
        <span style="color: #008000; font-weight: bold">if</span> Printout: 
           outfile<span style="color: #666666">.</span>write(<span style="color: #BA2121">&#39;</span><span style="color: #BB6688; font-weight: bold">%f</span><span style="color: #BB6622; font-weight: bold">\n</span><span style="color: #BA2121">&#39;</span> <span style="color: #666666">%</span>(energy<span style="color: #666666">/</span>(MCcycle<span style="color: #666666">+1.0</span>)))            
    <span style="color: #408080; font-style: italic"># We calculate mean values</span>
    energy <span style="color: #666666">/=</span> NumberMCcycles
    <span style="color: #008000; font-weight: bold">return</span> energy

<span style="color: #408080; font-style: italic">#Here starts the main program with variable declarations</span>
NumberParticles <span style="color: #666666">=</span> <span style="color: #666666">2</span>
Dimension <span style="color: #666666">=</span> <span style="color: #666666">2</span>
<span style="color: #408080; font-style: italic"># seed for rng generator </span>
seed()
<span style="color: #408080; font-style: italic"># Monte Carlo cycles for parameter optimization</span>
Printout <span style="color: #666666">=</span> <span style="color: #008000; font-weight: bold">False</span>
NumberMCcycles<span style="color: #666666">=</span> <span style="color: #666666">10000</span>
<span style="color: #408080; font-style: italic"># guess for variational parameters</span>
x0 <span style="color: #666666">=</span> np<span style="color: #666666">.</span>array([<span style="color: #666666">0.9</span>,<span style="color: #666666">0.2</span>])
<span style="color: #408080; font-style: italic"># Using Broydens method to find optimal parameters</span>
res <span style="color: #666666">=</span> minimize(Energy, x0, method<span style="color: #666666">=</span><span style="color: #BA2121">&#39;BFGS&#39;</span>, jac<span style="color: #666666">=</span>EnergyDerivative, options<span style="color: #666666">=</span>{<span style="color: #BA2121">&#39;gtol&#39;</span>: <span style="color: #666666">1e-4</span>,<span style="color: #BA2121">&#39;disp&#39;</span>: <span style="color: #008000; font-weight: bold">True</span>})
x0 <span style="color: #666666">=</span> res<span style="color: #666666">.</span>x
<span style="color: #408080; font-style: italic"># Compute the energy again with the optimal parameters and increased number of Monte Cycles</span>
NumberMCcycles<span style="color: #666666">=</span> <span style="color: #666666">2**19</span>
Printout <span style="color: #666666">=</span> <span style="color: #008000; font-weight: bold">True</span>
FinalEnergy <span style="color: #666666">=</span> Energy(x0)
EResult <span style="color: #666666">=</span> np<span style="color: #666666">.</span>array([FinalEnergy,FinalEnergy])
outfile<span style="color: #666666">.</span>close()
<span style="color: #408080; font-style: italic">#nice printout with Pandas</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">pandas</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">pd</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">pandas</span> <span style="color: #008000; font-weight: bold">import</span> DataFrame
data <span style="color: #666666">=</span>{<span style="color: #BA2121">&#39;Optimal Parameters&#39;</span>:x0, <span style="color: #BA2121">&#39;Final Energy&#39;</span>:EResult}
frame <span style="color: #666666">=</span> pd<span style="color: #666666">.</span>DataFrame(data)
<span style="color: #008000">print</span>(frame)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="resampling-analysis">Resampling analysis </h2>

<p>The next step is then to use the above data sets and perform a
resampling analysis using the blocking method
The blocking code, based on the article of <a href="https://journals.aps.org/pre/abstract/10.1103/PhysRevE.98.043304" target="_blank">Marius Jonsson</a> is given here
</p>


<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;"><span style="color: #408080; font-style: italic"># Common imports</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">os</span>

<span style="color: #408080; font-style: italic"># Where to save the figures and data files</span>
DATA_ID <span style="color: #666666">=</span> <span style="color: #BA2121">&quot;Results/EnergyMin&quot;</span>

<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">data_path</span>(dat_id):
    <span style="color: #008000; font-weight: bold">return</span> os<span style="color: #666666">.</span>path<span style="color: #666666">.</span>join(DATA_ID, dat_id)

infile <span style="color: #666666">=</span> <span style="color: #008000">open</span>(data_path(<span style="color: #BA2121">&quot;Energies.dat&quot;</span>),<span style="color: #BA2121">&#39;r&#39;</span>)

<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">import</span> log2, zeros, mean, var, <span style="color: #008000">sum</span>, loadtxt, arange, array, cumsum, dot, transpose, diagonal, sqrt
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">numpy.linalg</span> <span style="color: #008000; font-weight: bold">import</span> inv

<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">block</span>(x):
    <span style="color: #408080; font-style: italic"># preliminaries</span>
    n <span style="color: #666666">=</span> <span style="color: #008000">len</span>(x)
    d <span style="color: #666666">=</span> <span style="color: #008000">int</span>(log2(n))
    s, gamma <span style="color: #666666">=</span> zeros(d), zeros(d)
    mu <span style="color: #666666">=</span> mean(x)

    <span style="color: #408080; font-style: italic"># estimate the auto-covariance and variances </span>
    <span style="color: #408080; font-style: italic"># for each blocking transformation</span>
    <span style="color: #008000; font-weight: bold">for</span> i <span style="color: #AA22FF; font-weight: bold">in</span> arange(<span style="color: #666666">0</span>,d):
        n <span style="color: #666666">=</span> <span style="color: #008000">len</span>(x)
        <span style="color: #408080; font-style: italic"># estimate autocovariance of x</span>
        gamma[i] <span style="color: #666666">=</span> (n)<span style="color: #666666">**</span>(<span style="color: #666666">-1</span>)<span style="color: #666666">*</span><span style="color: #008000">sum</span>( (x[<span style="color: #666666">0</span>:(n<span style="color: #666666">-1</span>)]<span style="color: #666666">-</span>mu)<span style="color: #666666">*</span>(x[<span style="color: #666666">1</span>:n]<span style="color: #666666">-</span>mu) )
        <span style="color: #408080; font-style: italic"># estimate variance of x</span>
        s[i] <span style="color: #666666">=</span> var(x)
        <span style="color: #408080; font-style: italic"># perform blocking transformation</span>
        x <span style="color: #666666">=</span> <span style="color: #666666">0.5*</span>(x[<span style="color: #666666">0</span>::<span style="color: #666666">2</span>] <span style="color: #666666">+</span> x[<span style="color: #666666">1</span>::<span style="color: #666666">2</span>])
   
    <span style="color: #408080; font-style: italic"># generate the test observator M_k from the theorem</span>
    M <span style="color: #666666">=</span> (cumsum( ((gamma<span style="color: #666666">/</span>s)<span style="color: #666666">**2*2**</span>arange(<span style="color: #666666">1</span>,d<span style="color: #666666">+1</span>)[::<span style="color: #666666">-1</span>])[::<span style="color: #666666">-1</span>] )  )[::<span style="color: #666666">-1</span>]

    <span style="color: #408080; font-style: italic"># we need a list of magic numbers</span>
    q <span style="color: #666666">=</span>array([<span style="color: #666666">6.634897</span>,<span style="color: #666666">9.210340</span>, <span style="color: #666666">11.344867</span>, <span style="color: #666666">13.276704</span>, <span style="color: #666666">15.086272</span>, <span style="color: #666666">16.811894</span>, <span style="color: #666666">18.475307</span>, <span style="color: #666666">20.090235</span>, <span style="color: #666666">21.665994</span>, <span style="color: #666666">23.209251</span>, <span style="color: #666666">24.724970</span>, <span style="color: #666666">26.216967</span>, <span style="color: #666666">27.688250</span>, <span style="color: #666666">29.141238</span>, <span style="color: #666666">30.577914</span>, <span style="color: #666666">31.999927</span>, <span style="color: #666666">33.408664</span>, <span style="color: #666666">34.805306</span>, <span style="color: #666666">36.190869</span>, <span style="color: #666666">37.566235</span>, <span style="color: #666666">38.932173</span>, <span style="color: #666666">40.289360</span>, <span style="color: #666666">41.638398</span>, <span style="color: #666666">42.979820</span>, <span style="color: #666666">44.314105</span>, <span style="color: #666666">45.641683</span>, <span style="color: #666666">46.962942</span>, <span style="color: #666666">48.278236</span>, <span style="color: #666666">49.587884</span>, <span style="color: #666666">50.892181</span>])

    <span style="color: #408080; font-style: italic"># use magic to determine when we should have stopped blocking</span>
    <span style="color: #008000; font-weight: bold">for</span> k <span style="color: #AA22FF; font-weight: bold">in</span> arange(<span style="color: #666666">0</span>,d):
        <span style="color: #008000; font-weight: bold">if</span>(M[k] <span style="color: #666666">&lt;</span> q[k]):
            <span style="color: #008000; font-weight: bold">break</span>
    <span style="color: #008000; font-weight: bold">if</span> (k <span style="color: #666666">&gt;=</span> d<span style="color: #666666">-1</span>):
        <span style="color: #008000">print</span>(<span style="color: #BA2121">&quot;Warning: Use more data&quot;</span>)
    <span style="color: #008000; font-weight: bold">return</span> mu, s[k]<span style="color: #666666">/2**</span>(d<span style="color: #666666">-</span>k)


x <span style="color: #666666">=</span> loadtxt(infile)
(mean, var) <span style="color: #666666">=</span> block(x) 
std <span style="color: #666666">=</span> sqrt(var)
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">pandas</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">pd</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">pandas</span> <span style="color: #008000; font-weight: bold">import</span> DataFrame
data <span style="color: #666666">=</span>{<span style="color: #BA2121">&#39;Mean&#39;</span>:[mean], <span style="color: #BA2121">&#39;STDev&#39;</span>:[std]}
frame <span style="color: #666666">=</span> pd<span style="color: #666666">.</span>DataFrame(data,index<span style="color: #666666">=</span>[<span style="color: #BA2121">&#39;Values&#39;</span>])
<span style="color: #008000">print</span>(frame)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>


<!-- ------------------- end of main content --------------- -->
<center style="font-size:80%">
<!-- copyright --> &copy; 1999-2024, Morten Hjorth-Jensen  Email morten.hjorth-jensen@fys.uio.no. Released under CC Attribution-NonCommercial 4.0 license
</center>
</body>
</html>

