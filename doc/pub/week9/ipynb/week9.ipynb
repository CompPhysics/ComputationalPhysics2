{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cf7535c",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- HTML file automatically generated from DocOnce source (https://github.com/doconce/doconce/)\n",
    "doconce format html week9.do.txt --no_mako --no_abort -->\n",
    "<!-- dom:TITLE: Resampling Techniques, Bootstrap and Blocking -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b5be53",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Resampling Techniques, Bootstrap and Blocking\n",
    "**Morten Hjorth-Jensen  Email morten.hjorth-jensen@fys.uio.no**, Department of Physics and Center fo Computing in Science Education, University of Oslo, Oslo, Norway\n",
    "\n",
    "Date: **March 21, 2025**\n",
    "\n",
    "<!-- To do: improve blocking part, better derivation -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258c036e",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Overview of week March 17-21, 2025\n",
    "**Topics.**\n",
    "\n",
    "1. Reminder from last week about statistical observables, the central limit theorem and bootstrapping, see notes from last week\n",
    "\n",
    "2. Resampling Techniques, emphasis on  Blocking \n",
    "\n",
    "3. Discussion of onebody densities (whiteboard notes)\n",
    "\n",
    "4. [Video of lecture TBA](https://youtu.be/cnPh5FuGf3o)\n",
    "\n",
    "5. [Handwritten notes](https://github.com/CompPhysics/ComputationalPhysics2/blob/gh-pages/doc/HandWrittenNotes/2025/NotesMarch21.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27329908",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Why resampling methods ?\n",
    "**Statistical analysis.**\n",
    "\n",
    "* Our simulations can be treated as *computer experiments*. This is particularly the case for Monte Carlo methods\n",
    "\n",
    "* The results can be analysed with the same statistical tools as we would use analysing experimental data.\n",
    "\n",
    "* As in all experiments, we are looking for expectation values and an estimate of how accurate they are, i.e., possible sources for errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e657013f",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Statistical analysis\n",
    "* As in other experiments, many numerical  experiments have two classes of errors:\n",
    "\n",
    "a. Statistical errors\n",
    "\n",
    "b. Systematical errors\n",
    "\n",
    "* Statistical errors can be estimated using standard tools from statistics\n",
    "\n",
    "* Systematical errors are method specific and must be treated differently from case to case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbb1a62",
   "metadata": {
    "editable": true
   },
   "source": [
    "## And why do we use such methods?\n",
    "\n",
    "As you will see below, due to correlations between various\n",
    "measurements, we need to evaluate the so-called covariance in order to\n",
    "establish a proper evaluation of the total variance and the thereby\n",
    "the standard deviation of a given expectation value.\n",
    "\n",
    "The covariance however, leads to an evaluation of a double sum over the various stochastic variables. This becomes computationally too expensive to evaluate.\n",
    "Methods like the Bootstrap, the Jackknife and/or Blocking allow us to circumvent this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f063301a",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Central limit theorem\n",
    "\n",
    "Last week we derived the central limit theorem with the following assumptions:\n",
    "\n",
    "**Measurement $i$.**\n",
    "\n",
    "We assumed that each individual measurement $x_{ij}$ is represented by stochastic variables which independent and identically distributed (iid).\n",
    "This defined the sample mean of of experiment $i$ with $n$ samples as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1430884",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\overline{x}_i=\\frac{1}{n}\\sum_{j} x_{ij}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0265950e",
   "metadata": {
    "editable": true
   },
   "source": [
    "and the sample variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f0d3f",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\sigma^2_i=\\frac{1}{n}\\sum_{j} \\left(x_{ij}-\\overline{x}_i\\right)^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfdf117",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Further remarks\n",
    "\n",
    "Note that we use $n$ instead of $n-1$ in the definition of\n",
    "variance. The sample variance and the sample mean are not necessarily equal to\n",
    "the exact values we would get if we knew the corresponding probability\n",
    "distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cafce8",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Running many measurements\n",
    "\n",
    "**Adding $m$ measurements $i$.**\n",
    "\n",
    "With the assumption that the average measurements $i$ are also defined as  iid stochastic variables and have the same probability function $p$,\n",
    "we defined the total average over $m$ experiments as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27874e9",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\overline{X}=\\frac{1}{m}\\sum_{i} \\overline{x}_{i}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b95e3b2",
   "metadata": {
    "editable": true
   },
   "source": [
    "and the total variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041795e7",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\sigma^2_{m}=\\frac{1}{m}\\sum_{i} \\left( \\overline{x}_{i}-\\overline{X}\\right)^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78249475",
   "metadata": {
    "editable": true
   },
   "source": [
    "These are the quantities we used in showing that if the individual mean values are iid stochastic variables, then in the limit $m\\rightarrow \\infty$, the distribution for $\\overline{X}$ is given by a Gaussian distribution with variance $\\sigma^2_m$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c156551",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Adding more definitions\n",
    "\n",
    "The total sample variance over the $mn$ measurements is defined as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958a33fc",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\sigma^2=\\frac{1}{mn}\\sum_{i=1}^{m} \\sum_{j=1}^{n}\\left(x_{ij}-\\overline{X}\\right)^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba261c9",
   "metadata": {
    "editable": true
   },
   "source": [
    "We have from the equation for $\\sigma_m^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562f9a54",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\overline{x}_i-\\overline{X}=\\frac{1}{n}\\sum_{j=1}^{n}\\left(x_{i}-\\overline{X}\\right),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaa3efd",
   "metadata": {
    "editable": true
   },
   "source": [
    "and introducing the centered value $\\tilde{x}_{ij}=x_{ij}-\\overline{X}$, we can rewrite $\\sigma_m^2$ as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaac0fc",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\sigma^2_{m}=\\frac{1}{m}\\sum_{i} \\left( \\overline{x}_{i}-\\overline{X}\\right)^2=\\frac{1}{m}\\sum_{i=1}^{m}\\left[ \\frac{i}{n}\\sum_{j=1}^{n}\\tilde{x}_{ij}\\right]^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609b22d0",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Further rewriting\n",
    "\n",
    "We can rewrite the latter in terms of a sum over diagonal elements only and another sum which contains the non-diagonal elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f041cc92",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\sigma^2_{m}& =\\frac{1}{m}\\sum_{i=1}^{m}\\left[ \\frac{i}{n}\\sum_{j=1}^{n}\\tilde{x}_{ij}\\right]^2 \\\\\n",
    "            & = \\frac{1}{mn^2}\\sum_{i=1}^{m} \\sum_{j=1}^{n}\\tilde{x}_{ij}^2+\\frac{2}{mn^2}\\sum_{i=1}^{m} \\sum_{j<k}^{n}\\tilde{x}_{ij}\\tilde{x}_{ik}.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae8f8df",
   "metadata": {
    "editable": true
   },
   "source": [
    "The first term on the last rhs is nothing but the total sample variance $\\sigma^2$ divided by $m$. The second term represents the covariance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6761764",
   "metadata": {
    "editable": true
   },
   "source": [
    "## The covariance term\n",
    "\n",
    "Using the definition of the total sample variance we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4a5968",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\sigma^2_{m}& = \\frac{\\sigma^2}{m}+\\frac{2}{mn^2}\\sum_{i=1}^{m} \\sum_{j<k}^{n}\\tilde{x}_{ij}\\tilde{x}_{ik}.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27a0165",
   "metadata": {
    "editable": true
   },
   "source": [
    "The first term is what we have used till now in order to estimate the\n",
    "standard deviation. However, the second term which gives us a measure\n",
    "of the correlations between different stochastic events, can result in\n",
    "contributions which give rise to a larger standard deviation and\n",
    "variance $\\sigma_m^2$. Note also the evaluation of the second term\n",
    "leads to a double sum over all events. If we run a VMC calculation\n",
    "with say $10^9$ Monte carlo samples, the latter term would lead to\n",
    "$10^{18}$ function evaluations. We don't want to, by obvious reasons, to venture into that many evaluations.\n",
    "\n",
    "Note also that if our stochastic events are iid then the covariance terms is zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2855c379",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Rewriting the covariance term\n",
    "\n",
    "We introduce now a variable $d=\\vert j-k\\vert $ and rewrite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d03ad86",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{2}{mn^2}\\sum_{i=1}^{m} \\sum_{j<k}^{n}\\tilde{x}_{ij}\\tilde{x}_{ik},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec87a1de",
   "metadata": {
    "editable": true
   },
   "source": [
    "in terms of a function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff481aab",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "f_d=\\frac{2}{mn}\\sum_{i=1}^{m} \\sum_{k=1}^{n-d}\\tilde{x}_{ik}\\tilde{x}_{i(k+d)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1ac763",
   "metadata": {
    "editable": true
   },
   "source": [
    "We note that for $d=0$ we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab4bd92",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "f_0=\\frac{2}{mn}\\sum_{i=1}^{m} \\sum_{k=1}^{n}\\tilde{x}_{ik}\\tilde{x}_{i(k)}=\\sigma^2!\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672ecd42",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Introducing the correlation function\n",
    "\n",
    "We introduce then a correlation function $\\kappa_d=f_d/\\sigma^2$. Note that $\\kappa_0 =1$.  We rewrite the variance $\\sigma_m^2$ as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03405038",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\sigma^2_{m}& = \\frac{\\sigma^2}{m}\\left[1+2\\sum_{d=1}^{n-1} \\kappa_d\\right].\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f4d270",
   "metadata": {
    "editable": true
   },
   "source": [
    "The code here shows the evolution of $\\kappa_d$ as a function of $d$\n",
    "for a series of random numbers. We see that the function $\\kappa_d$\n",
    "approaches $0$ as $d\\rightarrow \\infty$.\n",
    "\n",
    "In this case, our data are given by random numbers generated for the uniform distribution with $x\\in [0,1]$. Even with two random numbers being far away, we note that the correlation function is not zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55a61fa",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Computing the correlation function\n",
    "\n",
    "This code is best seen with the jupyter-notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fb34032",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#!/usr/bin/env python\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# initialize the rng with a seed, simple uniform distribution\n",
    "random.seed() \n",
    "m = 10000\n",
    "samplefactor = 1.0/m\n",
    "x = np.zeros(m)   \n",
    "MeanValue = 0.\n",
    "VarValue = 0.\n",
    "for i in range (m):\n",
    "    value = random.random()\n",
    "    x[i] = value\n",
    "    MeanValue += value\n",
    "    VarValue += value*value\n",
    "\n",
    "MeanValue *= samplefactor\n",
    "VarValue *= samplefactor\n",
    "Variance = VarValue-MeanValue*MeanValue\n",
    "STDev = np.sqrt(Variance)\n",
    "print(\"MeanValue =\", MeanValue)\n",
    "print(\"Variance =\", Variance)\n",
    "print(\"Standard deviation =\", STDev)\n",
    "\n",
    "# Computing the autocorrelation function\n",
    "autocorrelation = np.zeros(m)\n",
    "darray = np.zeros(m)\n",
    "for j in range (m):\n",
    "    sum = 0.0\n",
    "    darray[j] = j\n",
    "    for k in range (m-j):\n",
    "        sum += (x[k]-MeanValue)*(x[k+j]-MeanValue ) \n",
    "    autocorrelation[j] = (sum/Variance)*samplefactor\n",
    "# Visualize results\n",
    "plt.plot(darray, autocorrelation,'ro')\n",
    "plt.axis([0,m,-0.2, 1.1])\n",
    "plt.xlabel(r'$d$')\n",
    "plt.ylabel(r'$\\kappa_d$')\n",
    "plt.title(r'autocorrelation function for RNG with uniform distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f68528",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Resampling methods: Blocking\n",
    "\n",
    "The blocking method was made popular by [Flyvbjerg and Pedersen (1989)](https://aip.scitation.org/doi/10.1063/1.457480)\n",
    "and has become one of the standard ways to estimate the variance\n",
    "$\\mathrm{var}(\\widehat{\\theta})$ for exactly one estimator $\\widehat{\\theta}$, namely\n",
    "$\\widehat{\\theta} = \\overline{X}$, the mean value. \n",
    "\n",
    "Assume $n = 2^d$ for some integer $d>1$ and $X_1,X_2,\\cdots, X_n$ is a stationary time series to begin with. \n",
    "Moreover, assume that the series is asymptotically uncorrelated. We switch to vector notation by arranging $X_1,X_2,\\cdots,X_n$ in an $n$-tuple. Define:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc39ad6",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{X} = (X_1,X_2,\\cdots,X_n).\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c4067c",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Why blocking?\n",
    "\n",
    "The strength of the blocking method is when the number of\n",
    "observations, $n$ is large. For large $n$, the complexity of dependent\n",
    "bootstrapping scales poorly, but the blocking method does not,\n",
    "moreover, it becomes more accurate the larger $n$ is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49e76fe",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Blocking Transformations\n",
    " We now define the blocking transformations. The idea is to take the mean of subsequent\n",
    "pair of elements from $\\boldsymbol{X}$ and form a new vector\n",
    "$\\boldsymbol{X}_1$. Continuing in the same way by taking the mean of\n",
    "subsequent pairs of elements of $\\boldsymbol{X}_1$ we obtain $\\boldsymbol{X}_2$, and\n",
    "so on. \n",
    "Define $\\boldsymbol{X}_i$ recursively by:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f454eb32",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "(\\boldsymbol{X}_0)_k \\equiv (\\boldsymbol{X})_k \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc37efac",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto1\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "(\\boldsymbol{X}_{i+1})_k \\equiv \\frac{1}{2}\\Big( (\\boldsymbol{X}_i)_{2k-1} +\n",
    "(\\boldsymbol{X}_i)_{2k} \\Big) \\qquad \\text{for all} \\qquad 1 \\leq i \\leq d-1\n",
    "\\label{_auto1} \\tag{1}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3779f7d1",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Blocking transformations\n",
    "\n",
    "The quantity $\\boldsymbol{X}_k$ is\n",
    "subject to $k$ **blocking transformations**.  We now have $d$ vectors\n",
    "$\\boldsymbol{X}_0, \\boldsymbol{X}_1,\\cdots,\\boldsymbol{X}_{d-1}$ containing the subsequent\n",
    "averages of observations. It turns out that if the components of\n",
    "$\\boldsymbol{X}$ is a stationary time series, then the components of\n",
    "$\\boldsymbol{X}_i$ is a stationary time series for all $0 \\leq i \\leq d-1$\n",
    "\n",
    "We can then compute the autocovariance (or just covariance), the variance, sample mean, and\n",
    "number of observations for each $i$. \n",
    "Let $\\gamma_i, \\sigma_i^2,\n",
    "\\overline{X}_i$ denote the covariance, variance and average of the\n",
    "elements of $\\boldsymbol{X}_i$ and let $n_i$ be the number of elements of\n",
    "$\\boldsymbol{X}_i$. It follows by induction that $n_i = n/2^i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763c2c30",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Blocking Transformations\n",
    "\n",
    "Using the\n",
    "definition of the blocking transformation and the distributive\n",
    "property of the covariance, it is clear that since $h =|i-j|$\n",
    "we can define"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aee1b47",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\gamma_{k+1}(h) = cov\\left( ({X}_{k+1})_{i}, ({X}_{k+1})_{j} \\right) \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1ce980",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "=  \\frac{1}{4}cov\\left( ({X}_{k})_{2i-1} + ({X}_{k})_{2i}, ({X}_{k})_{2j-1} + ({X}_{k})_{2j} \\right) \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e4a30e",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto2\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "=  \\frac{1}{2}\\gamma_{k}(2h) + \\frac{1}{2}\\gamma_k(2h+1) \\hspace{0.1cm} \\mathrm{h = 0} \n",
    "\\label{_auto2} \\tag{2}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541143b7",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto3\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "=\\frac{1}{4}\\gamma_k(2h-1) + \\frac{1}{2}\\gamma_k(2h) + \\frac{1}{4}\\gamma_k(2h+1) \\quad \\mathrm{else}\n",
    "\\label{_auto3} \\tag{3}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3049847d",
   "metadata": {
    "editable": true
   },
   "source": [
    "The quantity $\\hat{X}$ is asymptotically uncorrelated by assumption, $\\hat{X}_k$ is also asymptotic uncorrelated. Let's turn our attention to the variance of the sample\n",
    "mean $\\mathrm{var}(\\overline{X})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ad1207",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Blocking Transformations, getting there\n",
    "We have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e727bf3",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto4\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathrm{var}(\\overline{X}_k) = \\frac{\\sigma_k^2}{n_k} + \\underbrace{\\frac{2}{n_k} \\sum_{h=1}^{n_k-1}\\left( 1 - \\frac{h}{n_k} \\right)\\gamma_k(h)}_{\\equiv e_k} = \\frac{\\sigma^2_k}{n_k} + e_k \\quad \\text{if} \\quad \\gamma_k(0) = \\sigma_k^2. \n",
    "\\label{_auto4} \\tag{4}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69730d29",
   "metadata": {
    "editable": true
   },
   "source": [
    "The term $e_k$ is called the **truncation error**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153452cf",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto5\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "e_k = \\frac{2}{n_k} \\sum_{h=1}^{n_k-1}\\left( 1 - \\frac{h}{n_k} \\right)\\gamma_k(h). \n",
    "\\label{_auto5} \\tag{5}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83e0f42",
   "metadata": {
    "editable": true
   },
   "source": [
    "We can show that $\\mathrm{var}(\\overline{X}_i) = \\mathrm{var}(\\overline{X}_j)$ for all $0 \\leq i \\leq d-1$ and $0 \\leq j \\leq d-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fc4e11",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Blocking Transformations, final expressions\n",
    "\n",
    "We can then wrap up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b600ce56",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "n_{j+1} \\overline{X}_{j+1}  = \\sum_{i=1}^{n_{j+1}} (\\hat{X}_{j+1})_i =  \\frac{1}{2}\\sum_{i=1}^{n_{j}/2} (\\hat{X}_{j})_{2i-1} + (\\hat{X}_{j})_{2i} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76471ca1",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto6\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "= \\frac{1}{2}\\left[ (\\hat{X}_j)_1 + (\\hat{X}_j)_2 + \\cdots + (\\hat{X}_j)_{n_j} \\right] = \\underbrace{\\frac{n_j}{2}}_{=n_{j+1}} \\overline{X}_j = n_{j+1}\\overline{X}_j. \n",
    "\\label{_auto6} \\tag{6}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dc2388",
   "metadata": {
    "editable": true
   },
   "source": [
    "By repeated use of this equation we get $\\mathrm{var}(\\overline{X}_i) = \\mathrm{var}(\\overline{X}_0) = \\mathrm{var}(\\overline{X})$ for all $0 \\leq i \\leq d-1$. This has the consequence that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ae88c7",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:convergence\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathrm{var}(\\overline{X}) = \\frac{\\sigma_k^2}{n_k} + e_k \\qquad \\text{for all} \\qquad 0 \\leq k \\leq d-1. \\label{eq:convergence} \\tag{7}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a673781",
   "metadata": {
    "editable": true
   },
   "source": [
    "## More on the blocking method\n",
    "\n",
    "Flyvbjerg and Petersen demonstrated that the sequence\n",
    "$\\{e_k\\}_{k=0}^{d-1}$ is decreasing, and conjecture that the term\n",
    "$e_k$ can be made as small as we would like by making $k$ (and hence\n",
    "$d$) sufficiently large. The sequence is decreasing.\n",
    "It means we can apply blocking transformations until\n",
    "$e_k$ is sufficiently small, and then estimate $\\mathrm{var}(\\overline{X})$ by\n",
    "$\\widehat{\\sigma}^2_k/n_k$. \n",
    "\n",
    "For an elegant solution and proof of the blocking method, see the recent article of [Marius Jonsson (former MSc student of the Computational Physics group)](https://journals.aps.org/pre/abstract/10.1103/PhysRevE.98.043304)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1d0467",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Example code form last week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22c962ec",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 2-electron VMC code for 2dim quantum dot with importance sampling\n",
    "# Using gaussian rng for new positions and Metropolis- Hastings \n",
    "# Added energy minimization\n",
    "from math import exp, sqrt\n",
    "from random import random, seed, normalvariate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from scipy.optimize import minimize\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Where to save data files\n",
    "PROJECT_ROOT_DIR = \"Results\"\n",
    "DATA_ID = \"Results/EnergyMin\"\n",
    "\n",
    "if not os.path.exists(PROJECT_ROOT_DIR):\n",
    "    os.mkdir(PROJECT_ROOT_DIR)\n",
    "\n",
    "if not os.path.exists(DATA_ID):\n",
    "    os.makedirs(DATA_ID)\n",
    "\n",
    "def data_path(dat_id):\n",
    "    return os.path.join(DATA_ID, dat_id)\n",
    "\n",
    "outfile = open(data_path(\"Energies.dat\"),'w')\n",
    "\n",
    "\n",
    "# Trial wave function for the 2-electron quantum dot in two dims\n",
    "def WaveFunction(r,alpha,beta):\n",
    "    r1 = r[0,0]**2 + r[0,1]**2\n",
    "    r2 = r[1,0]**2 + r[1,1]**2\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = r12/(1+beta*r12)\n",
    "    return exp(-0.5*alpha*(r1+r2)+deno)\n",
    "\n",
    "# Local energy  for the 2-electron quantum dot in two dims, using analytical local energy\n",
    "def LocalEnergy(r,alpha,beta):\n",
    "    \n",
    "    r1 = (r[0,0]**2 + r[0,1]**2)\n",
    "    r2 = (r[1,0]**2 + r[1,1]**2)\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = 1.0/(1+beta*r12)\n",
    "    deno2 = deno*deno\n",
    "    return 0.5*(1-alpha*alpha)*(r1 + r2) +2.0*alpha + 1.0/r12+deno2*(alpha*r12-deno2+2*beta*deno-1.0/r12)\n",
    "\n",
    "# Derivate of wave function ansatz as function of variational parameters\n",
    "def DerivativeWFansatz(r,alpha,beta):\n",
    "    \n",
    "    WfDer  = np.zeros((2), np.double)\n",
    "    r1 = (r[0,0]**2 + r[0,1]**2)\n",
    "    r2 = (r[1,0]**2 + r[1,1]**2)\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = 1.0/(1+beta*r12)\n",
    "    deno2 = deno*deno\n",
    "    WfDer[0] = -0.5*(r1+r2)\n",
    "    WfDer[1] = -r12*r12*deno2\n",
    "    return  WfDer\n",
    "\n",
    "# Setting up the quantum force for the two-electron quantum dot, recall that it is a vector\n",
    "def QuantumForce(r,alpha,beta):\n",
    "\n",
    "    qforce = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = 1.0/(1+beta*r12)\n",
    "    qforce[0,:] = -2*r[0,:]*alpha*(r[0,:]-r[1,:])*deno*deno/r12\n",
    "    qforce[1,:] = -2*r[1,:]*alpha*(r[1,:]-r[0,:])*deno*deno/r12\n",
    "    return qforce\n",
    "    \n",
    "\n",
    "# Computing the derivative of the energy and the energy \n",
    "def EnergyDerivative(x0):\n",
    "\n",
    "    \n",
    "    # Parameters in the Fokker-Planck simulation of the quantum force\n",
    "    D = 0.5\n",
    "    TimeStep = 0.05\n",
    "    # positions\n",
    "    PositionOld = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    PositionNew = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    # Quantum force\n",
    "    QuantumForceOld = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    QuantumForceNew = np.zeros((NumberParticles,Dimension), np.double)\n",
    "\n",
    "    energy = 0.0\n",
    "    DeltaE = 0.0\n",
    "    alpha = x0[0]\n",
    "    beta = x0[1]\n",
    "    EnergyDer = 0.0\n",
    "    DeltaPsi = 0.0\n",
    "    DerivativePsiE = 0.0 \n",
    "    #Initial position\n",
    "    for i in range(NumberParticles):\n",
    "        for j in range(Dimension):\n",
    "            PositionOld[i,j] = normalvariate(0.0,1.0)*sqrt(TimeStep)\n",
    "    wfold = WaveFunction(PositionOld,alpha,beta)\n",
    "    QuantumForceOld = QuantumForce(PositionOld,alpha, beta)\n",
    "\n",
    "    #Loop over MC MCcycles\n",
    "    for MCcycle in range(NumberMCcycles):\n",
    "        #Trial position moving one particle at the time\n",
    "        for i in range(NumberParticles):\n",
    "            for j in range(Dimension):\n",
    "                PositionNew[i,j] = PositionOld[i,j]+normalvariate(0.0,1.0)*sqrt(TimeStep)+\\\n",
    "                                       QuantumForceOld[i,j]*TimeStep*D\n",
    "            wfnew = WaveFunction(PositionNew,alpha,beta)\n",
    "            QuantumForceNew = QuantumForce(PositionNew,alpha, beta)\n",
    "            GreensFunction = 0.0\n",
    "            for j in range(Dimension):\n",
    "                GreensFunction += 0.5*(QuantumForceOld[i,j]+QuantumForceNew[i,j])*\\\n",
    "\t                              (D*TimeStep*0.5*(QuantumForceOld[i,j]-QuantumForceNew[i,j])-\\\n",
    "                                      PositionNew[i,j]+PositionOld[i,j])\n",
    "      \n",
    "            GreensFunction = exp(GreensFunction)\n",
    "            ProbabilityRatio = GreensFunction*wfnew**2/wfold**2\n",
    "            #Metropolis-Hastings test to see whether we accept the move\n",
    "            if random() <= ProbabilityRatio:\n",
    "                for j in range(Dimension):\n",
    "                    PositionOld[i,j] = PositionNew[i,j]\n",
    "                    QuantumForceOld[i,j] = QuantumForceNew[i,j]\n",
    "                wfold = wfnew\n",
    "        DeltaE = LocalEnergy(PositionOld,alpha,beta)\n",
    "        DerPsi = DerivativeWFansatz(PositionOld,alpha,beta)\n",
    "        DeltaPsi += DerPsi\n",
    "        energy += DeltaE\n",
    "        DerivativePsiE += DerPsi*DeltaE\n",
    "            \n",
    "    # We calculate mean values\n",
    "    energy /= NumberMCcycles\n",
    "    DerivativePsiE /= NumberMCcycles\n",
    "    DeltaPsi /= NumberMCcycles\n",
    "    EnergyDer  = 2*(DerivativePsiE-DeltaPsi*energy)\n",
    "    return EnergyDer\n",
    "\n",
    "\n",
    "# Computing the expectation value of the local energy \n",
    "def Energy(x0):\n",
    "    # Parameters in the Fokker-Planck simulation of the quantum force\n",
    "    D = 0.5\n",
    "    TimeStep = 0.05\n",
    "    # positions\n",
    "    PositionOld = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    PositionNew = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    # Quantum force\n",
    "    QuantumForceOld = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    QuantumForceNew = np.zeros((NumberParticles,Dimension), np.double)\n",
    "\n",
    "    energy = 0.0\n",
    "    DeltaE = 0.0\n",
    "    alpha = x0[0]\n",
    "    beta = x0[1]\n",
    "    #Initial position\n",
    "    for i in range(NumberParticles):\n",
    "        for j in range(Dimension):\n",
    "            PositionOld[i,j] = normalvariate(0.0,1.0)*sqrt(TimeStep)\n",
    "    wfold = WaveFunction(PositionOld,alpha,beta)\n",
    "    QuantumForceOld = QuantumForce(PositionOld,alpha, beta)\n",
    "\n",
    "    #Loop over MC MCcycles\n",
    "    for MCcycle in range(NumberMCcycles):\n",
    "        #Trial position moving one particle at the time\n",
    "        for i in range(NumberParticles):\n",
    "            for j in range(Dimension):\n",
    "                PositionNew[i,j] = PositionOld[i,j]+normalvariate(0.0,1.0)*sqrt(TimeStep)+\\\n",
    "                                       QuantumForceOld[i,j]*TimeStep*D\n",
    "            wfnew = WaveFunction(PositionNew,alpha,beta)\n",
    "            QuantumForceNew = QuantumForce(PositionNew,alpha, beta)\n",
    "            GreensFunction = 0.0\n",
    "            for j in range(Dimension):\n",
    "                GreensFunction += 0.5*(QuantumForceOld[i,j]+QuantumForceNew[i,j])*\\\n",
    "\t                              (D*TimeStep*0.5*(QuantumForceOld[i,j]-QuantumForceNew[i,j])-\\\n",
    "                                      PositionNew[i,j]+PositionOld[i,j])\n",
    "      \n",
    "            GreensFunction = exp(GreensFunction)\n",
    "            ProbabilityRatio = GreensFunction*wfnew**2/wfold**2\n",
    "            #Metropolis-Hastings test to see whether we accept the move\n",
    "            if random() <= ProbabilityRatio:\n",
    "                for j in range(Dimension):\n",
    "                    PositionOld[i,j] = PositionNew[i,j]\n",
    "                    QuantumForceOld[i,j] = QuantumForceNew[i,j]\n",
    "                wfold = wfnew\n",
    "        DeltaE = LocalEnergy(PositionOld,alpha,beta)\n",
    "        energy += DeltaE\n",
    "        if Printout: \n",
    "           outfile.write('%f\\n' %(energy/(MCcycle+1.0)))            \n",
    "    # We calculate mean values\n",
    "    energy /= NumberMCcycles\n",
    "    return energy\n",
    "\n",
    "#Here starts the main program with variable declarations\n",
    "NumberParticles = 2\n",
    "Dimension = 2\n",
    "# seed for rng generator \n",
    "seed()\n",
    "# Monte Carlo cycles for parameter optimization\n",
    "Printout = False\n",
    "NumberMCcycles= 10000\n",
    "# guess for variational parameters\n",
    "x0 = np.array([0.9,0.2])\n",
    "# Using Broydens method to find optimal parameters\n",
    "res = minimize(Energy, x0, method='BFGS', jac=EnergyDerivative, options={'gtol': 1e-4,'disp': True})\n",
    "x0 = res.x\n",
    "# Compute the energy again with the optimal parameters and increased number of Monte Cycles\n",
    "NumberMCcycles= 2**19\n",
    "Printout = True\n",
    "FinalEnergy = Energy(x0)\n",
    "EResult = np.array([FinalEnergy,FinalEnergy])\n",
    "outfile.close()\n",
    "#nice printout with Pandas\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "data ={'Optimal Parameters':x0, 'Final Energy':EResult}\n",
    "frame = pd.DataFrame(data)\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b631fcd",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Resampling analysis\n",
    "\n",
    "The next step is then to use the above data sets and perform a\n",
    "resampling analysis using the blocking method\n",
    "The blocking code, based on the article of [Marius Jonsson](https://journals.aps.org/pre/abstract/10.1103/PhysRevE.98.043304) is given here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4ea071e",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import os\n",
    "\n",
    "# Where to save the figures and data files\n",
    "DATA_ID = \"Results/EnergyMin\"\n",
    "\n",
    "def data_path(dat_id):\n",
    "    return os.path.join(DATA_ID, dat_id)\n",
    "\n",
    "infile = open(data_path(\"Energies.dat\"),'r')\n",
    "\n",
    "from numpy import log2, zeros, mean, var, sum, loadtxt, arange, array, cumsum, dot, transpose, diagonal, sqrt\n",
    "from numpy.linalg import inv\n",
    "\n",
    "def block(x):\n",
    "    # preliminaries\n",
    "    n = len(x)\n",
    "    d = int(log2(n))\n",
    "    s, gamma = zeros(d), zeros(d)\n",
    "    mu = mean(x)\n",
    "\n",
    "    # estimate the auto-covariance and variances \n",
    "    # for each blocking transformation\n",
    "    for i in arange(0,d):\n",
    "        n = len(x)\n",
    "        # estimate autocovariance of x\n",
    "        gamma[i] = (n)**(-1)*sum( (x[0:(n-1)]-mu)*(x[1:n]-mu) )\n",
    "        # estimate variance of x\n",
    "        s[i] = var(x)\n",
    "        # perform blocking transformation\n",
    "        x = 0.5*(x[0::2] + x[1::2])\n",
    "   \n",
    "    # generate the test observator M_k from the theorem\n",
    "    M = (cumsum( ((gamma/s)**2*2**arange(1,d+1)[::-1])[::-1] )  )[::-1]\n",
    "\n",
    "    # we need a list of magic numbers\n",
    "    q =array([6.634897,9.210340, 11.344867, 13.276704, 15.086272, 16.811894, 18.475307, 20.090235, 21.665994, 23.209251, 24.724970, 26.216967, 27.688250, 29.141238, 30.577914, 31.999927, 33.408664, 34.805306, 36.190869, 37.566235, 38.932173, 40.289360, 41.638398, 42.979820, 44.314105, 45.641683, 46.962942, 48.278236, 49.587884, 50.892181])\n",
    "\n",
    "    # use magic to determine when we should have stopped blocking\n",
    "    for k in arange(0,d):\n",
    "        if(M[k] < q[k]):\n",
    "            break\n",
    "    if (k >= d-1):\n",
    "        print(\"Warning: Use more data\")\n",
    "    return mu, s[k]/2**(d-k)\n",
    "\n",
    "\n",
    "x = loadtxt(infile)\n",
    "(mean, var) = block(x) \n",
    "std = sqrt(var)\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "data ={'Mean':[mean], 'STDev':[std]}\n",
    "frame = pd.DataFrame(data,index=['Values'])\n",
    "print(frame)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
