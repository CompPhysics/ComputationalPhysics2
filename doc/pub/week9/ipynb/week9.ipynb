{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23bd45d3",
   "metadata": {},
   "source": [
    "<!-- HTML file automatically generated from DocOnce source (https://github.com/doconce/doconce/)\n",
    "doconce format html week9.do.txt --no_mako --no_abort -->\n",
    "<!-- dom:TITLE: Week 12, March 20-24: Resampling Techniques, Bootstrap and Blocking -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc3dcf9",
   "metadata": {},
   "source": [
    "# Week 12, March 20-24: Resampling Techniques, Bootstrap and Blocking\n",
    "**Morten Hjorth-Jensen  Email morten.hjorth-jensen@fys.uio.no**, Department of Physics and Center fo Computing in Science Education, University of Oslo, Oslo, Norway and Department of Physics and Astronomy and Facility for Rare Ion Beams, Michigan State University, East Lansing, Michigan, USA\n",
    "\n",
    "Date: **March 20-24**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5866f777",
   "metadata": {},
   "source": [
    "## Overview of week 12, March 20-24\n",
    "**Topics.**\n",
    "\n",
    "* Resampling Techniques and statistics: Bootstrap and Blocking \n",
    "\n",
    "* Discussion of onebody densities\n",
    "\n",
    "* [Video of lecture TBA](https://youtu.be/)\n",
    "\n",
    "* [Handwritten notes](https://github.com/CompPhysics/ComputationalPhysics2/blob/gh-pages/doc/HandWrittenNotes/2023/NotesMarch16.pdf)\n",
    "\n",
    "**Teaching Material, videos and written material.**\n",
    "\n",
    "* Overview video on the [Bootstrap method](https://www.youtube.com/watch?v=O_Fj4q8lgmc&ab_channel=MarinStatsLectures-RProgramming%26Statistics)\n",
    "\n",
    "* [Marius Johnson's Master thesis on the Blocking Method](https://www.duo.uio.no/bitstream/handle/10852/68360/PhysRevE.98.043304.pdf?sequence=2&isAllowed=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb68d12f",
   "metadata": {},
   "source": [
    "## Why resampling methods ?\n",
    "**Statistical analysis.**\n",
    "\n",
    "* Our simulations can be treated as *computer experiments*. This is particularly the case for Monte Carlo methods\n",
    "\n",
    "* The results can be analysed with the same statistical tools as we would use analysing experimental data.\n",
    "\n",
    "* As in all experiments, we are looking for expectation values and an estimate of how accurate they are, i.e., possible sources for errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725a8d16",
   "metadata": {},
   "source": [
    "## Statistical analysis\n",
    "* As in other experiments, many numerical  experiments have two classes of errors:\n",
    "\n",
    "a. Statistical errors\n",
    "\n",
    "b. Systematical errors\n",
    "\n",
    "* Statistical errors can be estimated using standard tools from statistics\n",
    "\n",
    "* Systematical errors are method specific and must be treated differently from case to case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece8e068",
   "metadata": {},
   "source": [
    "## Statistics, wrapping up from last week\n",
    "Let us analyze the problem by splitting up the correlation term into\n",
    "partial sums of the form:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4962737",
   "metadata": {},
   "source": [
    "$$\n",
    "f_d = \\frac{1}{n-d}\\sum_{k=1}^{n-d}(x_k - \\bar x_n)(x_{k+d} - \\bar x_n)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0636e105",
   "metadata": {},
   "source": [
    "The correlation term of the error can now be rewritten in terms of\n",
    "$f_d$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152d61ff",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{2}{n}\\sum_{k<l} (x_k - \\bar x_n)(x_l - \\bar x_n) =\n",
    "2\\sum_{d=1}^{n-1} f_d\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb36185",
   "metadata": {},
   "source": [
    "The value of $f_d$ reflects the correlation between measurements\n",
    "separated by the distance $d$ in the sample samples.  Notice that for\n",
    "$d=0$, $f$ is just the sample variance, $\\mathrm{var}(x)$. If we divide $f_d$\n",
    "by $\\mathrm{var}(x)$, we arrive at the so called *autocorrelation function*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72273f7d",
   "metadata": {},
   "source": [
    "$$\n",
    "\\kappa_d = \\frac{f_d}{\\mathrm{var}(x)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fa58b7",
   "metadata": {},
   "source": [
    "which gives us a useful measure of pairwise correlations\n",
    "starting always at $1$ for $d=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baff89c",
   "metadata": {},
   "source": [
    "## Statistics, final expression\n",
    "The sample error can now be\n",
    "written in terms of the autocorrelation function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ba89ce",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathrm{err}_X^2 =\n",
    "\\frac{1}{n}\\mathrm{var}(x)+\\frac{2}{n}\\cdot\\mathrm{var}(x)\\sum_{d=1}^{n-1}\n",
    "\\frac{f_d}{\\mathrm{var}(x)}\\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b79b992",
   "metadata": {},
   "source": [
    "$$\n",
    "=\n",
    "\\left(1+2\\sum_{d=1}^{n-1}\\kappa_d\\right)\\frac{1}{n}\\mathrm{var}(x)\\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82b8eab",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto1\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "=\\frac{\\tau}{n}\\cdot\\mathrm{var}(x)\n",
    "\\label{_auto1} \\tag{1}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041c11ec",
   "metadata": {},
   "source": [
    "and we see that $\\mathrm{err}_X$ can be expressed in terms the\n",
    "uncorrelated sample variance times a correction factor $\\tau$ which\n",
    "accounts for the correlation between measurements. We call this\n",
    "correction factor the *autocorrelation time*:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbbae8e",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:autocorrelation_time\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\tau = 1+2\\sum_{d=1}^{n-1}\\kappa_d\n",
    "\\label{eq:autocorrelation_time} \\tag{2}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cde94f",
   "metadata": {},
   "source": [
    "## Statistics, effective number of correlations\n",
    "For a correlation free experiment, $\\tau$\n",
    "equals 1.\n",
    "\n",
    "We can interpret a sequential\n",
    "correlation as an effective reduction of the number of measurements by\n",
    "a factor $\\tau$. The effective number of measurements becomes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9616faaa",
   "metadata": {},
   "source": [
    "$$\n",
    "n_\\mathrm{eff} = \\frac{n}{\\tau}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c037197e",
   "metadata": {},
   "source": [
    "To neglect the autocorrelation time $\\tau$ will always cause our\n",
    "simple uncorrelated estimate of $\\mathrm{err}_X^2\\approx \\mathrm{var}(x)/n$ to\n",
    "be less than the true sample error. The estimate of the error will be\n",
    "too *good*. On the other hand, the calculation of the full\n",
    "autocorrelation time poses an efficiency problem if the set of\n",
    "measurements is very large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a5b62e",
   "metadata": {},
   "source": [
    "## Can we understand this? Time Auto-correlation Function\n",
    "\n",
    "The so-called time-displacement autocorrelation $\\phi(t)$ for a quantity $\\mathbf{M}$ is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df573663",
   "metadata": {},
   "source": [
    "$$\n",
    "\\phi(t) = \\int dt' \\left[\\mathbf{M}(t')-\\langle \\mathbf{M} \\rangle\\right]\\left[\\mathbf{M}(t'+t)-\\langle \\mathbf{M} \\rangle\\right],\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7cd373",
   "metadata": {},
   "source": [
    "which can be rewritten as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3c0b1a",
   "metadata": {},
   "source": [
    "$$\n",
    "\\phi(t) = \\int dt' \\left[\\mathbf{M}(t')\\mathbf{M}(t'+t)-\\langle \\mathbf{M} \\rangle^2\\right],\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6721c4",
   "metadata": {},
   "source": [
    "where $\\langle \\mathbf{M} \\rangle$ is the average value and\n",
    "$\\mathbf{M}(t)$ its instantaneous value. We can discretize this function as follows, where we used our\n",
    "set of computed values $\\mathbf{M}(t)$ for a set of discretized times (our Monte Carlo cycles corresponding to moving all electrons?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296e8d4b",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:phitf\"></div>\n",
    "\n",
    "$$\n",
    "\\phi(t)  = \\frac{1}{t_{\\mathrm{max}}-t}\\sum_{t'=0}^{t_{\\mathrm{max}}-t}\\mathbf{M}(t')\\mathbf{M}(t'+t)\n",
    "-\\frac{1}{t_{\\mathrm{max}}-t}\\sum_{t'=0}^{t_{\\mathrm{max}}-t}\\mathbf{M}(t')\\times\n",
    "\\frac{1}{t_{\\mathrm{max}}-t}\\sum_{t'=0}^{t_{\\mathrm{max}}-t}\\mathbf{M}(t'+t).\n",
    "\\label{eq:phitf} \\tag{3}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72200db2",
   "metadata": {},
   "source": [
    "## Time Auto-correlation Function\n",
    "\n",
    "One should be careful with times close to $t_{\\mathrm{max}}$, the upper limit of the sums \n",
    "becomes small and we end up integrating over a rather small time interval. This means that the statistical\n",
    "error in $\\phi(t)$ due to the random nature of the fluctuations in $\\mathbf{M}(t)$ can become large.\n",
    "\n",
    "One should therefore choose $t \\ll t_{\\mathrm{max}}$.\n",
    "\n",
    "Note that the variable $\\mathbf{M}$ can be any expectation values of interest.\n",
    "\n",
    "The time-correlation function gives a measure of the correlation between the various values of the variable \n",
    "at a time $t'$ and a time $t'+t$. If we multiply the values of $\\mathbf{M}$ at these two different times,\n",
    "we will get a positive contribution if they are fluctuating in the same direction, or a negative value\n",
    "if they fluctuate in the opposite direction. If we then integrate over time, or use the discretized version of, the time correlation function $\\phi(t)$ should take a non-zero value if the fluctuations are \n",
    "correlated, else it should gradually go to zero. For times a long way apart \n",
    "the different values of $\\mathbf{M}$  are most likely \n",
    "uncorrelated and $\\phi(t)$ should be zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a85c47",
   "metadata": {},
   "source": [
    "## Time Auto-correlation Function\n",
    "We can derive the correlation time by observing that our Metropolis algorithm is based on a random\n",
    "walk in the space of all  possible spin configurations. \n",
    "Our probability \n",
    "distribution function $\\mathbf{\\hat{w}}(t)$ after a given number of time steps $t$ could be written as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83d6b27",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{\\hat{w}}(t) = \\mathbf{\\hat{W}^t\\hat{w}}(0),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4076773b",
   "metadata": {},
   "source": [
    "with $\\mathbf{\\hat{w}}(0)$ the distribution at $t=0$ and $\\mathbf{\\hat{W}}$ representing the \n",
    "transition probability matrix. \n",
    "We can always expand $\\mathbf{\\hat{w}}(0)$ in terms of the right eigenvectors of \n",
    "$\\mathbf{\\hat{v}}$ of $\\mathbf{\\hat{W}}$ as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c992c25f",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{\\hat{w}}(0)  = \\sum_i\\alpha_i\\mathbf{\\hat{v}}_i,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da9fc9d",
   "metadata": {},
   "source": [
    "resulting in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354976eb",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{\\hat{w}}(t) = \\mathbf{\\hat{W}}^t\\mathbf{\\hat{w}}(0)=\\mathbf{\\hat{W}}^t\\sum_i\\alpha_i\\mathbf{\\hat{v}}_i=\n",
    "\\sum_i\\lambda_i^t\\alpha_i\\mathbf{\\hat{v}}_i,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2a26a9",
   "metadata": {},
   "source": [
    "with $\\lambda_i$ the $i^{\\mathrm{th}}$ eigenvalue corresponding to  \n",
    "the eigenvector $\\mathbf{\\hat{v}}_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879a211e",
   "metadata": {},
   "source": [
    "## Time Auto-correlation Function\n",
    "If we assume that $\\lambda_0$ is the largest eigenvector we see that in the limit $t\\rightarrow \\infty$,\n",
    "$\\mathbf{\\hat{w}}(t)$ becomes proportional to the corresponding eigenvector \n",
    "$\\mathbf{\\hat{v}}_0$. This is our steady state or final distribution. \n",
    "\n",
    "We can relate this property to an observable like the mean energy.\n",
    "With the probabilty $\\mathbf{\\hat{w}}(t)$ (which in our case is the squared trial wave function) we\n",
    "can write the expectation values as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23dfdc5",
   "metadata": {},
   "source": [
    "$$\n",
    "\\langle \\mathbf{M}(t) \\rangle  = \\sum_{\\mu} \\mathbf{\\hat{w}}(t)_{\\mu}\\mathbf{M}_{\\mu},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9ca030",
   "metadata": {},
   "source": [
    "or as the scalar of a  vector product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4f9d2d",
   "metadata": {},
   "source": [
    "$$\n",
    "\\langle \\mathbf{M}(t) \\rangle  = \\mathbf{\\hat{w}}(t)\\mathbf{m},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb2153e",
   "metadata": {},
   "source": [
    "with $\\mathbf{m}$ being the vector whose elements are the values of $\\mathbf{M}_{\\mu}$ in its \n",
    "various microstates $\\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964f2dd2",
   "metadata": {},
   "source": [
    "## Time Auto-correlation Function\n",
    "\n",
    "We rewrite this relation  as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c61cb4",
   "metadata": {},
   "source": [
    "$$\n",
    "\\langle \\mathbf{M}(t) \\rangle  = \\mathbf{\\hat{w}}(t)\\mathbf{m}=\\sum_i\\lambda_i^t\\alpha_i\\mathbf{\\hat{v}}_i\\mathbf{m}_i.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789ca09a",
   "metadata": {},
   "source": [
    "If we define $m_i=\\mathbf{\\hat{v}}_i\\mathbf{m}_i$ as the expectation value of\n",
    "$\\mathbf{M}$ in the $i^{\\mathrm{th}}$ eigenstate we can rewrite the last equation as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193418be",
   "metadata": {},
   "source": [
    "$$\n",
    "\\langle \\mathbf{M}(t) \\rangle  = \\sum_i\\lambda_i^t\\alpha_im_i.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d2ea9a",
   "metadata": {},
   "source": [
    "Since we have that in the limit $t\\rightarrow \\infty$ the mean value is dominated by the \n",
    "the largest eigenvalue $\\lambda_0$, we can rewrite the last equation as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce86706",
   "metadata": {},
   "source": [
    "$$\n",
    "\\langle \\mathbf{M}(t) \\rangle  = \\langle \\mathbf{M}(\\infty) \\rangle+\\sum_{i\\ne 0}\\lambda_i^t\\alpha_im_i.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add66885",
   "metadata": {},
   "source": [
    "We define the quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7418d12",
   "metadata": {},
   "source": [
    "$$\n",
    "\\tau_i=-\\frac{1}{log\\lambda_i},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c29b8f3",
   "metadata": {},
   "source": [
    "and rewrite the last expectation value as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2054579",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:finalmeanm\"></div>\n",
    "\n",
    "$$\n",
    "\\langle \\mathbf{M}(t) \\rangle  = \\langle \\mathbf{M}(\\infty) \\rangle+\\sum_{i\\ne 0}\\alpha_im_ie^{-t/\\tau_i}.\n",
    "\\label{eq:finalmeanm} \\tag{4}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb196e7",
   "metadata": {},
   "source": [
    "## Time Auto-correlation Function\n",
    "\n",
    "The quantities $\\tau_i$ are the correlation times for the system. They control also the auto-correlation function \n",
    "discussed above.  The longest correlation time is obviously given by the second largest\n",
    "eigenvalue $\\tau_1$, which normally defines the correlation time discussed above. For large times, this is the \n",
    "only correlation time that survives. If higher eigenvalues of the transition matrix are well separated from \n",
    "$\\lambda_1$ and we simulate long enough,  $\\tau_1$ may well define the correlation time. \n",
    "In other cases we may not be able to extract a reliable result for $\\tau_1$. \n",
    "Coming back to the time correlation function $\\phi(t)$ we can present a more general definition in terms\n",
    "of the mean magnetizations $ \\langle \\mathbf{M}(t) \\rangle$. Recalling that the mean value is equal \n",
    "to $ \\langle \\mathbf{M}(\\infty) \\rangle$ we arrive at the expectation values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a10f8c6",
   "metadata": {},
   "source": [
    "$$\n",
    "\\phi(t) =\\langle \\mathbf{M}(0)-\\mathbf{M}(\\infty)\\rangle \\langle \\mathbf{M}(t)-\\mathbf{M}(\\infty)\\rangle,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027e2831",
   "metadata": {},
   "source": [
    "resulting in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3cc7d3",
   "metadata": {},
   "source": [
    "$$\n",
    "\\phi(t) =\\sum_{i,j\\ne 0}m_i\\alpha_im_j\\alpha_je^{-t/\\tau_i},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb29fab",
   "metadata": {},
   "source": [
    "which is appropriate for all times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1780d417",
   "metadata": {},
   "source": [
    "## Correlation Time\n",
    "\n",
    "If the correlation function decays exponentially"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a6e2a8",
   "metadata": {},
   "source": [
    "$$\n",
    "\\phi (t) \\sim \\exp{(-t/\\tau)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e78b0e",
   "metadata": {},
   "source": [
    "then the exponential correlation time can be computed as the average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c23047",
   "metadata": {},
   "source": [
    "$$\n",
    "\\tau_{\\mathrm{exp}}  =  -\\langle  \\frac{t}{log|\\frac{\\phi(t)}{\\phi(0)}|} \\rangle.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8108f517",
   "metadata": {},
   "source": [
    "If the decay is exponential, then"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458b3a33",
   "metadata": {},
   "source": [
    "$$\n",
    "\\int_0^{\\infty} dt \\phi(t)  = \\int_0^{\\infty} dt \\phi(0)\\exp{(-t/\\tau)}  = \\tau \\phi(0),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0f6bf1",
   "metadata": {},
   "source": [
    "which  suggests another measure of correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eaf45e",
   "metadata": {},
   "source": [
    "$$\n",
    "\\tau_{\\mathrm{int}} = \\sum_k \\frac{\\phi(k)}{\\phi(0)},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3ee3a8",
   "metadata": {},
   "source": [
    "called the integrated correlation time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8da785",
   "metadata": {},
   "source": [
    "## Resampling methods: Jackknife and Bootstrap\n",
    "\n",
    "Two famous\n",
    "resampling methods are the **independent bootstrap** and **the jackknife**. \n",
    "\n",
    "The jackknife is a special case of the independent bootstrap. Still, the jackknife was made\n",
    "popular prior to the independent bootstrap. And as the popularity of\n",
    "the independent bootstrap soared, new variants, such as **the dependent bootstrap**.\n",
    "\n",
    "The Jackknife and independent bootstrap work for\n",
    "independent, identically distributed random variables.\n",
    "If these conditions are not\n",
    "satisfied, the methods will fail.  Yet, it should be said that if the data are\n",
    "independent, identically distributed, and we only want to estimate the\n",
    "variance of $\\overline{X}$ (which often is the case), then there is no\n",
    "need for bootstrapping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d138434",
   "metadata": {},
   "source": [
    "## Resampling methods: Jackknife\n",
    "\n",
    "The Jackknife works by making many replicas of the estimator $\\widehat{\\theta}$. \n",
    "The jackknife is a resampling method, we explained that this happens by scrambling the data in some way. When using the jackknife, this is done by systematically leaving out one observation from the vector of observed values $\\hat{x} = (x_1,x_2,\\cdots,X_n)$. \n",
    "Let $\\hat{x}_i$ denote the vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adbd5cd",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{x}_i = (x_1,x_2,\\cdots,x_{i-1},x_{i+1},\\cdots,x_n),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d248a2e5",
   "metadata": {},
   "source": [
    "which equals the vector $\\hat{x}$ with the exception that observation\n",
    "number $i$ is left out. Using this notation, define\n",
    "$\\widehat{\\theta}_i$ to be the estimator\n",
    "$\\widehat{\\theta}$ computed using $\\vec{X}_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cc29c7",
   "metadata": {},
   "source": [
    "## Resampling methods: Jackknife estimator\n",
    "\n",
    "To get an estimate for the bias and\n",
    "standard error of $\\widehat{\\theta}$, use the following\n",
    "estimators for each component of $\\widehat{\\theta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81f0668",
   "metadata": {},
   "source": [
    "$$\n",
    "\\widehat{\\mathrm{Bias}}(\\widehat \\theta,\\theta) = (n-1)\\left( - \\widehat{\\theta} + \\frac{1}{n}\\sum_{i=1}^{n} \\widehat \\theta_i \\right) \\qquad \\text{and} \\qquad \\widehat{\\sigma}^2_{\\widehat{\\theta} } = \\frac{n-1}{n}\\sum_{i=1}^{n}( \\widehat{\\theta}_i - \\frac{1}{n}\\sum_{j=1}^{n}\\widehat \\theta_j )^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa18572",
   "metadata": {},
   "source": [
    "## Jackknife code example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ecc9f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "from numpy.random import randint, randn\n",
    "from time import time\n",
    "\n",
    "def jackknife(data, stat):\n",
    "    n = len(data);t = zeros(n); inds = arange(n); t0 = time()\n",
    "    ## 'jackknifing' by leaving out an observation for each i                                                                                                                      \n",
    "    for i in range(n):\n",
    "        t[i] = stat(delete(data,i) )\n",
    "\n",
    "    # analysis                                                                                                                                                                     \n",
    "    print(\"Runtime: %g sec\" % (time()-t0)); print(\"Jackknife Statistics :\")\n",
    "    print(\"original           bias      std. error\")\n",
    "    print(\"%8g %14g %15g\" % (stat(data),(n-1)*mean(t)/n, (n*var(t))**.5))\n",
    "\n",
    "    return t\n",
    "\n",
    "\n",
    "# Returns mean of data samples                                                                                                                                                     \n",
    "def stat(data):\n",
    "    return mean(data)\n",
    "\n",
    "\n",
    "mu, sigma = 100, 15\n",
    "datapoints = 10000\n",
    "x = mu + sigma*random.randn(datapoints)\n",
    "# jackknife returns the data sample                                                                                                                                                \n",
    "t = jackknife(x, stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765618c5",
   "metadata": {},
   "source": [
    "## Resampling methods: Bootstrap\n",
    "Bootstrapping is a nonparametric approach to statistical inference\n",
    "that substitutes computation for more traditional distributional\n",
    "assumptions and asymptotic results. Bootstrapping offers a number of\n",
    "advantages: \n",
    "1. The bootstrap is quite general, although there are some cases in which it fails.  \n",
    "\n",
    "2. Because it does not require distributional assumptions (such as normally distributed errors), the bootstrap can provide more accurate inferences when the data are not well behaved or when the sample size is small.  \n",
    "\n",
    "3. It is possible to apply the bootstrap to statistics with sampling distributions that are difficult to derive, even asymptotically. \n",
    "\n",
    "4. It is relatively simple to apply the bootstrap to complex data-collection plans (such as stratified and clustered samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adff0ff",
   "metadata": {},
   "source": [
    "## Resampling methods: Bootstrap background\n",
    "\n",
    "Since $\\widehat{\\theta} = \\widehat{\\theta}(\\hat{X})$ is a function of random variables,\n",
    "$\\widehat{\\theta}$ itself must be a random variable. Thus it has\n",
    "a pdf, call this function $p(\\hat{t})$. The aim of the bootstrap is to\n",
    "estimate $p(\\hat{t})$ by the relative frequency of\n",
    "$\\widehat{\\theta}$. You can think of this as using a histogram\n",
    "in the place of $p(\\hat{t})$. If the relative frequency closely\n",
    "resembles $p(\\vec{t})$, then using numerics, it is straight forward to\n",
    "estimate all the interesting parameters of $p(\\hat{t})$ using point\n",
    "estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7333d9",
   "metadata": {},
   "source": [
    "## Resampling methods: More Bootstrap background\n",
    "\n",
    "In the case that $\\widehat{\\theta}$ has\n",
    "more than one component, and the components are independent, we use the\n",
    "same estimator on each component separately.  If the probability\n",
    "density function of $X_i$, $p(x)$, had been known, then it would have\n",
    "been straight forward to do this by: \n",
    "1. Drawing lots of numbers from $p(x)$, suppose we call one such set of numbers $(X_1^*, X_2^*, \\cdots, X_n^*)$. \n",
    "\n",
    "2. Then using these numbers, we could compute a replica of $\\widehat{\\theta}$ called $\\widehat{\\theta}^*$. \n",
    "\n",
    "By repeated use of (1) and (2), many\n",
    "estimates of $\\widehat{\\theta}$ could have been obtained. The\n",
    "idea is to use the relative frequency of $\\widehat{\\theta}^*$\n",
    "(think of a histogram) as an estimate of $p(\\hat{t})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68516f5f",
   "metadata": {},
   "source": [
    "## Resampling methods: Bootstrap approach\n",
    "\n",
    "But\n",
    "unless there is enough information available about the process that\n",
    "generated $X_1,X_2,\\cdots,X_n$, $p(x)$ is in general\n",
    "unknown. Therefore, [Efron in 1979](https://projecteuclid.org/euclid.aos/1176344552)  asked the\n",
    "question: What if we replace $p(x)$ by the relative frequency\n",
    "of the observation $X_i$; if we draw observations in accordance with\n",
    "the relative frequency of the observations, will we obtain the same\n",
    "result in some asymptotic sense? The answer is yes.\n",
    "\n",
    "Instead of generating the histogram for the relative\n",
    "frequency of the observation $X_i$, just draw the values\n",
    "$(X_1^*,X_2^*,\\cdots,X_n^*)$ with replacement from the vector\n",
    "$\\hat{X}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8881706",
   "metadata": {},
   "source": [
    "## Resampling methods: Bootstrap steps\n",
    "\n",
    "The independent bootstrap works like this: \n",
    "\n",
    "1. Draw with replacement $n$ numbers for the observed variables $\\hat{x} = (x_1,x_2,\\cdots,x_n)$. \n",
    "\n",
    "2. Define a vector $\\hat{x}^*$ containing the values which were drawn from $\\hat{x}$. \n",
    "\n",
    "3. Using the vector $\\hat{x}^*$ compute $\\widehat{\\theta}^*$ by evaluating $\\widehat \\theta$ under the observations $\\hat{x}^*$. \n",
    "\n",
    "4. Repeat this process $k$ times. \n",
    "\n",
    "When you are done, you can draw a histogram of the relative frequency of $\\widehat \\theta^*$. This is your estimate of the probability distribution $p(t)$. Using this probability distribution you can estimate any statistics thereof. In principle you never draw the histogram of the relative frequency of $\\widehat{\\theta}^*$. Instead you use the estimators corresponding to the statistic of interest. For example, if you are interested in estimating the variance of $\\widehat \\theta$, apply the etsimator $\\widehat \\sigma^2$ to the values $\\widehat \\theta ^*$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a41c34",
   "metadata": {},
   "source": [
    "## Code example for the Bootstrap method\n",
    "\n",
    "The following code starts with a Gaussian distribution with mean value $\\mu =100$ and variance $\\sigma=15$. We use this to generate the data used in the bootstrap analysis. The bootstrap analysis returns a data set after a given number of bootstrap operations (as many as we have data points). This data set consists of estimated mean values for each bootstrap operation. The histogram generated by the bootstrap method shows that the distribution for these mean values is also a Gaussian, centered around the mean value $\\mu=100$ but with standard deviation $\\sigma/\\sqrt{n}$, where $n$ is the number of bootstrap samples (in this case the same as the number of original data points). The value of the standard deviation is what we expect from the central limit theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a22d36a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 1.20815 sec\n",
      "Bootstrap Statistics :\n",
      "original           bias      std. error\n",
      " 100.111  15.1251        100.112        0.150682\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from numpy import *\n",
    "from numpy.random import randint, randn\n",
    "from time import time\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Returns mean of bootstrap samples                                                                                                                                                \n",
    "def stat(data):\n",
    "    return mean(data)\n",
    "\n",
    "# Bootstrap algorithm                                                                                                                                                              \n",
    "def bootstrap(data, statistic, R):\n",
    "    t = zeros(R); n = len(data); inds = arange(n); t0 = time()\n",
    "\n",
    "    # non-parametric bootstrap                                                                                                                                                     \n",
    "    for i in range(R):\n",
    "        t[i] = statistic(data[randint(0,n,n)])\n",
    "\n",
    "    # analysis                                                                                                                                                                     \n",
    "    print(\"Runtime: %g sec\" % (time()-t0)); print(\"Bootstrap Statistics :\")\n",
    "    print(\"original           bias      std. error\")\n",
    "    print(\"%8g %8g %14g %15g\" % (statistic(data), std(data),\\\n",
    "                             mean(t), \\\n",
    "                             std(t)))\n",
    "    return t\n",
    "\n",
    "\n",
    "mu, sigma = 100, 15\n",
    "datapoints = 10000\n",
    "x = mu + sigma*random.randn(datapoints)\n",
    "# bootstrap returns the data sample                                                                                                          t = bootstrap(x, stat, datapoints)\n",
    "# the histogram of the bootstrapped  data  \n",
    "t = bootstrap(x, stat, datapoints)\n",
    "# the histogram of the bootstrapped  data                                            \n",
    "n, binsboot, patches = plt.hist(t, bins=50, density='true',histtype='bar', color='red', alpha=0.75)\n",
    "\n",
    "# add a 'best fit' line                                                                                                                                                          \n",
    "y = norm.pdf( binsboot, mean(t), std(t))\n",
    "lt = plt.plot(binsboot, y, 'r--', linewidth=1)\n",
    "plt.xlabel('Smarts')\n",
    "plt.ylabel('Probability')\n",
    "plt.axis([99.5, 100.6, 0, 3.0])\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a399cc",
   "metadata": {},
   "source": [
    "## Resampling methods: Blocking\n",
    "\n",
    "The blocking method was made popular by [Flyvbjerg and Pedersen (1989)](https://aip.scitation.org/doi/10.1063/1.457480)\n",
    "and has become one of the standard ways to estimate\n",
    "$V(\\widehat{\\theta})$ for exactly one $\\widehat{\\theta}$, namely\n",
    "$\\widehat{\\theta} = \\overline{X}$. \n",
    "\n",
    "Assume $n = 2^d$ for some integer $d>1$ and $X_1,X_2,\\cdots, X_n$ is a stationary time series to begin with. \n",
    "Moreover, assume that the time series is asymptotically uncorrelated. We switch to vector notation by arranging $X_1,X_2,\\cdots,X_n$ in an $n$-tuple. Define:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d103616e",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{X} = (X_1,X_2,\\cdots,X_n).\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528b3e73",
   "metadata": {},
   "source": [
    "The strength of the blocking method is when the number of\n",
    "observations, $n$ is large. For large $n$, the complexity of dependent\n",
    "bootstrapping scales poorly, but the blocking method does not,\n",
    "moreover, it becomes more accurate the larger $n$ is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609b1d50",
   "metadata": {},
   "source": [
    "## Blocking Transformations\n",
    " We now define\n",
    "blocking transformations. The idea is to take the mean of subsequent\n",
    "pair of elements from $\\vec{X}$ and form a new vector\n",
    "$\\vec{X}_1$. Continuing in the same way by taking the mean of\n",
    "subsequent pairs of elements of $\\vec{X}_1$ we obtain $\\vec{X}_2$, and\n",
    "so on. \n",
    "Define $\\vec{X}_i$ recursively by:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2986b537",
   "metadata": {},
   "source": [
    "$$\n",
    "(\\vec{X}_0)_k \\equiv (\\vec{X})_k \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aa21ed",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto2\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "(\\vec{X}_{i+1})_k \\equiv \\frac{1}{2}\\Big( (\\vec{X}_i)_{2k-1} +\n",
    "(\\vec{X}_i)_{2k} \\Big) \\qquad \\text{for all} \\qquad 1 \\leq i \\leq d-1\n",
    "\\label{_auto2} \\tag{5}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a309e290",
   "metadata": {},
   "source": [
    "The quantity $\\vec{X}_k$ is\n",
    "subject to $k$ **blocking transformations**.  We now have $d$ vectors\n",
    "$\\vec{X}_0, \\vec{X}_1,\\cdots,\\vec X_{d-1}$ containing the subsequent\n",
    "averages of observations. It turns out that if the components of\n",
    "$\\vec{X}$ is a stationary time series, then the components of\n",
    "$\\vec{X}_i$ is a stationary time series for all $0 \\leq i \\leq d-1$\n",
    "\n",
    "We can then compute the autocovariance, the variance, sample mean, and\n",
    "number of observations for each $i$. \n",
    "Let $\\gamma_i, \\sigma_i^2,\n",
    "\\overline{X}_i$ denote the autocovariance, variance and average of the\n",
    "elements of $\\vec{X}_i$ and let $n_i$ be the number of elements of\n",
    "$\\vec{X}_i$. It follows by induction that $n_i = n/2^i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4630936",
   "metadata": {},
   "source": [
    "## Blocking Transformations\n",
    "\n",
    "Using the\n",
    "definition of the blocking transformation and the distributive\n",
    "property of the covariance, it is clear that since $h =|i-j|$\n",
    "we can define"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4986fa",
   "metadata": {},
   "source": [
    "$$\n",
    "\\gamma_{k+1}(h) = cov\\left( ({X}_{k+1})_{i}, ({X}_{k+1})_{j} \\right) \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542739ad",
   "metadata": {},
   "source": [
    "$$\n",
    "=  \\frac{1}{4}cov\\left( ({X}_{k})_{2i-1} + ({X}_{k})_{2i}, ({X}_{k})_{2j-1} + ({X}_{k})_{2j} \\right) \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb1b966",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto3\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "=  \\frac{1}{2}\\gamma_{k}(2h) + \\frac{1}{2}\\gamma_k(2h+1) \\hspace{0.1cm} \\mathrm{h = 0} \n",
    "\\label{_auto3} \\tag{6}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756419b7",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto4\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "=\\frac{1}{4}\\gamma_k(2h-1) + \\frac{1}{2}\\gamma_k(2h) + \\frac{1}{4}\\gamma_k(2h+1) \\quad \\mathrm{else}\n",
    "\\label{_auto4} \\tag{7}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96292ae5",
   "metadata": {},
   "source": [
    "The quantity $\\hat{X}$ is asymptotic uncorrelated by assumption, $\\hat{X}_k$ is also asymptotic uncorrelated. Let's turn our attention to the variance of the sample mean $V(\\overline{X})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dbbc03",
   "metadata": {},
   "source": [
    "## Blocking Transformations, getting there\n",
    "We have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80820c1e",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto5\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "V(\\overline{X}_k) = \\frac{\\sigma_k^2}{n_k} + \\underbrace{\\frac{2}{n_k} \\sum_{h=1}^{n_k-1}\\left( 1 - \\frac{h}{n_k} \\right)\\gamma_k(h)}_{\\equiv e_k} = \\frac{\\sigma^2_k}{n_k} + e_k \\quad \\text{if} \\quad \\gamma_k(0) = \\sigma_k^2. \n",
    "\\label{_auto5} \\tag{8}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad09af4b",
   "metadata": {},
   "source": [
    "The term $e_k$ is called the **truncation error**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da235d1",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto6\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "e_k = \\frac{2}{n_k} \\sum_{h=1}^{n_k-1}\\left( 1 - \\frac{h}{n_k} \\right)\\gamma_k(h). \n",
    "\\label{_auto6} \\tag{9}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8526de",
   "metadata": {},
   "source": [
    "We can show that $V(\\overline{X}_i) = V(\\overline{X}_j)$ for all $0 \\leq i \\leq d-1$ and $0 \\leq j \\leq d-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d97166",
   "metadata": {},
   "source": [
    "## Blocking Transformations, final expressions\n",
    "\n",
    "We can then wrap up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20db1df0",
   "metadata": {},
   "source": [
    "$$\n",
    "n_{j+1} \\overline{X}_{j+1}  = \\sum_{i=1}^{n_{j+1}} (\\hat{X}_{j+1})_i =  \\frac{1}{2}\\sum_{i=1}^{n_{j}/2} (\\hat{X}_{j})_{2i-1} + (\\hat{X}_{j})_{2i} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a82344",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto7\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "= \\frac{1}{2}\\left[ (\\hat{X}_j)_1 + (\\hat{X}_j)_2 + \\cdots + (\\hat{X}_j)_{n_j} \\right] = \\underbrace{\\frac{n_j}{2}}_{=n_{j+1}} \\overline{X}_j = n_{j+1}\\overline{X}_j. \n",
    "\\label{_auto7} \\tag{10}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f61cc7c",
   "metadata": {},
   "source": [
    "By repeated use of this equation we get $V(\\overline{X}_i) = V(\\overline{X}_0) = V(\\overline{X})$ for all $0 \\leq i \\leq d-1$. This has the consequence that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4460d2f",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:convergence\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "V(\\overline{X}) = \\frac{\\sigma_k^2}{n_k} + e_k \\qquad \\text{for all} \\qquad 0 \\leq k \\leq d-1. \\label{eq:convergence} \\tag{11}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae737194",
   "metadata": {},
   "source": [
    "Flyvbjerg and Petersen demonstrated that the sequence\n",
    "$\\{e_k\\}_{k=0}^{d-1}$ is decreasing, and conjecture that the term\n",
    "$e_k$ can be made as small as we would like by making $k$ (and hence\n",
    "$d$) sufficiently large. The sequence is decreasing (Master of Science thesis by Marius Jonsson, UiO 2018).\n",
    "It means we can apply blocking transformations until\n",
    "$e_k$ is sufficiently small, and then estimate $V(\\overline{X})$ by\n",
    "$\\widehat{\\sigma}^2_k/n_k$. \n",
    "\n",
    "For an elegant solution and proof of the blocking method, see the recent article of [Marius Jonsson (former MSc student of the Computational Physics group)](https://journals.aps.org/pre/abstract/10.1103/PhysRevE.98.043304).\n",
    "\n",
    "We can improve upon this by using the algorithms provided by the **optimize** package in Python.\n",
    "One of these algorithms is  Broyden–Fletcher–Goldfarb–Shanno (BFGS) algorithm. \n",
    "\n",
    "The optimization problem is to minimize $f(\\mathbf {x} )$ where\n",
    "$\\mathbf {x}$ is a vector in $R^{n}$, and $f$ is a differentiable\n",
    "scalar function. There are no constraints on the values that $\\mathbf{x}$ can take.\n",
    "\n",
    "The algorithm begins at an initial estimate for the optimal value\n",
    "$\\mathbf {x}_{0}$ and proceeds iteratively to get a better estimate at\n",
    "each stage.\n",
    "\n",
    "The search direction $p_k$ at stage $k$ is given by the solution of the analogue of the Newton equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc9d551",
   "metadata": {},
   "source": [
    "$$\n",
    "B_{k}\\mathbf {p} _{k}=-\\nabla f(\\mathbf {x}_{k}),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491da769",
   "metadata": {},
   "source": [
    "where $B_{k}$ is an approximation to the Hessian matrix, which is\n",
    "updated iteratively at each stage, and $\\nabla f(\\mathbf {x} _{k})$\n",
    "is the gradient of the function\n",
    "evaluated at $x_k$. \n",
    "A line search in the direction $p_k$ is then used to\n",
    "find the next point $x_{k+1}$ by minimising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1919899d",
   "metadata": {},
   "source": [
    "$$\n",
    "f(\\mathbf {x}_{k}+\\alpha \\mathbf {p}_{k}),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cf4a7c",
   "metadata": {},
   "source": [
    "over the scalar $\\alpha > 0$.\n",
    "\n",
    "The modified code here uses the BFGS algorithm but performs now a\n",
    "production run and writes to file all average values of the\n",
    "energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ec500eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 2.999496\n",
      "         Iterations: 4\n",
      "         Function evaluations: 31\n",
      "         Gradient evaluations: 19\n",
      "   Optimal Parameters  Final Energy\n",
      "0            0.985363      3.000518\n",
      "1            0.426177      3.000518\n"
     ]
    }
   ],
   "source": [
    "# 2-electron VMC code for 2dim quantum dot with importance sampling\n",
    "# Using gaussian rng for new positions and Metropolis- Hastings \n",
    "# Added energy minimization\n",
    "from math import exp, sqrt\n",
    "from random import random, seed, normalvariate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from scipy.optimize import minimize\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Where to save data files\n",
    "PROJECT_ROOT_DIR = \"Results\"\n",
    "DATA_ID = \"Results/EnergyMin\"\n",
    "\n",
    "if not os.path.exists(PROJECT_ROOT_DIR):\n",
    "    os.mkdir(PROJECT_ROOT_DIR)\n",
    "\n",
    "if not os.path.exists(DATA_ID):\n",
    "    os.makedirs(DATA_ID)\n",
    "\n",
    "def data_path(dat_id):\n",
    "    return os.path.join(DATA_ID, dat_id)\n",
    "\n",
    "outfile = open(data_path(\"Energies.dat\"),'w')\n",
    "\n",
    "\n",
    "# Trial wave function for the 2-electron quantum dot in two dims\n",
    "def WaveFunction(r,alpha,beta):\n",
    "    r1 = r[0,0]**2 + r[0,1]**2\n",
    "    r2 = r[1,0]**2 + r[1,1]**2\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = r12/(1+beta*r12)\n",
    "    return exp(-0.5*alpha*(r1+r2)+deno)\n",
    "\n",
    "# Local energy  for the 2-electron quantum dot in two dims, using analytical local energy\n",
    "def LocalEnergy(r,alpha,beta):\n",
    "    \n",
    "    r1 = (r[0,0]**2 + r[0,1]**2)\n",
    "    r2 = (r[1,0]**2 + r[1,1]**2)\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = 1.0/(1+beta*r12)\n",
    "    deno2 = deno*deno\n",
    "    return 0.5*(1-alpha*alpha)*(r1 + r2) +2.0*alpha + 1.0/r12+deno2*(alpha*r12-deno2+2*beta*deno-1.0/r12)\n",
    "\n",
    "# Derivate of wave function ansatz as function of variational parameters\n",
    "def DerivativeWFansatz(r,alpha,beta):\n",
    "    \n",
    "    WfDer  = np.zeros((2), np.double)\n",
    "    r1 = (r[0,0]**2 + r[0,1]**2)\n",
    "    r2 = (r[1,0]**2 + r[1,1]**2)\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = 1.0/(1+beta*r12)\n",
    "    deno2 = deno*deno\n",
    "    WfDer[0] = -0.5*(r1+r2)\n",
    "    WfDer[1] = -r12*r12*deno2\n",
    "    return  WfDer\n",
    "\n",
    "# Setting up the quantum force for the two-electron quantum dot, recall that it is a vector\n",
    "def QuantumForce(r,alpha,beta):\n",
    "\n",
    "    qforce = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = 1.0/(1+beta*r12)\n",
    "    qforce[0,:] = -2*r[0,:]*alpha*(r[0,:]-r[1,:])*deno*deno/r12\n",
    "    qforce[1,:] = -2*r[1,:]*alpha*(r[1,:]-r[0,:])*deno*deno/r12\n",
    "    return qforce\n",
    "    \n",
    "\n",
    "# Computing the derivative of the energy and the energy \n",
    "def EnergyDerivative(x0):\n",
    "\n",
    "    \n",
    "    # Parameters in the Fokker-Planck simulation of the quantum force\n",
    "    D = 0.5\n",
    "    TimeStep = 0.05\n",
    "    # positions\n",
    "    PositionOld = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    PositionNew = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    # Quantum force\n",
    "    QuantumForceOld = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    QuantumForceNew = np.zeros((NumberParticles,Dimension), np.double)\n",
    "\n",
    "    energy = 0.0\n",
    "    DeltaE = 0.0\n",
    "    alpha = x0[0]\n",
    "    beta = x0[1]\n",
    "    EnergyDer = 0.0\n",
    "    DeltaPsi = 0.0\n",
    "    DerivativePsiE = 0.0 \n",
    "    #Initial position\n",
    "    for i in range(NumberParticles):\n",
    "        for j in range(Dimension):\n",
    "            PositionOld[i,j] = normalvariate(0.0,1.0)*sqrt(TimeStep)\n",
    "    wfold = WaveFunction(PositionOld,alpha,beta)\n",
    "    QuantumForceOld = QuantumForce(PositionOld,alpha, beta)\n",
    "\n",
    "    #Loop over MC MCcycles\n",
    "    for MCcycle in range(NumberMCcycles):\n",
    "        #Trial position moving one particle at the time\n",
    "        for i in range(NumberParticles):\n",
    "            for j in range(Dimension):\n",
    "                PositionNew[i,j] = PositionOld[i,j]+normalvariate(0.0,1.0)*sqrt(TimeStep)+\\\n",
    "                                       QuantumForceOld[i,j]*TimeStep*D\n",
    "            wfnew = WaveFunction(PositionNew,alpha,beta)\n",
    "            QuantumForceNew = QuantumForce(PositionNew,alpha, beta)\n",
    "            GreensFunction = 0.0\n",
    "            for j in range(Dimension):\n",
    "                GreensFunction += 0.5*(QuantumForceOld[i,j]+QuantumForceNew[i,j])*\\\n",
    "\t                              (D*TimeStep*0.5*(QuantumForceOld[i,j]-QuantumForceNew[i,j])-\\\n",
    "                                      PositionNew[i,j]+PositionOld[i,j])\n",
    "      \n",
    "            GreensFunction = exp(GreensFunction)\n",
    "            ProbabilityRatio = GreensFunction*wfnew**2/wfold**2\n",
    "            #Metropolis-Hastings test to see whether we accept the move\n",
    "            if random() <= ProbabilityRatio:\n",
    "                for j in range(Dimension):\n",
    "                    PositionOld[i,j] = PositionNew[i,j]\n",
    "                    QuantumForceOld[i,j] = QuantumForceNew[i,j]\n",
    "                wfold = wfnew\n",
    "        DeltaE = LocalEnergy(PositionOld,alpha,beta)\n",
    "        DerPsi = DerivativeWFansatz(PositionOld,alpha,beta)\n",
    "        DeltaPsi += DerPsi\n",
    "        energy += DeltaE\n",
    "        DerivativePsiE += DerPsi*DeltaE\n",
    "            \n",
    "    # We calculate mean values\n",
    "    energy /= NumberMCcycles\n",
    "    DerivativePsiE /= NumberMCcycles\n",
    "    DeltaPsi /= NumberMCcycles\n",
    "    EnergyDer  = 2*(DerivativePsiE-DeltaPsi*energy)\n",
    "    return EnergyDer\n",
    "\n",
    "\n",
    "# Computing the expectation value of the local energy \n",
    "def Energy(x0):\n",
    "    # Parameters in the Fokker-Planck simulation of the quantum force\n",
    "    D = 0.5\n",
    "    TimeStep = 0.05\n",
    "    # positions\n",
    "    PositionOld = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    PositionNew = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    # Quantum force\n",
    "    QuantumForceOld = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    QuantumForceNew = np.zeros((NumberParticles,Dimension), np.double)\n",
    "\n",
    "    energy = 0.0\n",
    "    DeltaE = 0.0\n",
    "    alpha = x0[0]\n",
    "    beta = x0[1]\n",
    "    #Initial position\n",
    "    for i in range(NumberParticles):\n",
    "        for j in range(Dimension):\n",
    "            PositionOld[i,j] = normalvariate(0.0,1.0)*sqrt(TimeStep)\n",
    "    wfold = WaveFunction(PositionOld,alpha,beta)\n",
    "    QuantumForceOld = QuantumForce(PositionOld,alpha, beta)\n",
    "\n",
    "    #Loop over MC MCcycles\n",
    "    for MCcycle in range(NumberMCcycles):\n",
    "        #Trial position moving one particle at the time\n",
    "        for i in range(NumberParticles):\n",
    "            for j in range(Dimension):\n",
    "                PositionNew[i,j] = PositionOld[i,j]+normalvariate(0.0,1.0)*sqrt(TimeStep)+\\\n",
    "                                       QuantumForceOld[i,j]*TimeStep*D\n",
    "            wfnew = WaveFunction(PositionNew,alpha,beta)\n",
    "            QuantumForceNew = QuantumForce(PositionNew,alpha, beta)\n",
    "            GreensFunction = 0.0\n",
    "            for j in range(Dimension):\n",
    "                GreensFunction += 0.5*(QuantumForceOld[i,j]+QuantumForceNew[i,j])*\\\n",
    "\t                              (D*TimeStep*0.5*(QuantumForceOld[i,j]-QuantumForceNew[i,j])-\\\n",
    "                                      PositionNew[i,j]+PositionOld[i,j])\n",
    "      \n",
    "            GreensFunction = exp(GreensFunction)\n",
    "            ProbabilityRatio = GreensFunction*wfnew**2/wfold**2\n",
    "            #Metropolis-Hastings test to see whether we accept the move\n",
    "            if random() <= ProbabilityRatio:\n",
    "                for j in range(Dimension):\n",
    "                    PositionOld[i,j] = PositionNew[i,j]\n",
    "                    QuantumForceOld[i,j] = QuantumForceNew[i,j]\n",
    "                wfold = wfnew\n",
    "        DeltaE = LocalEnergy(PositionOld,alpha,beta)\n",
    "        energy += DeltaE\n",
    "        if Printout: \n",
    "           outfile.write('%f\\n' %(energy/(MCcycle+1.0)))            \n",
    "    # We calculate mean values\n",
    "    energy /= NumberMCcycles\n",
    "    return energy\n",
    "\n",
    "#Here starts the main program with variable declarations\n",
    "NumberParticles = 2\n",
    "Dimension = 2\n",
    "# seed for rng generator \n",
    "seed()\n",
    "# Monte Carlo cycles for parameter optimization\n",
    "Printout = False\n",
    "NumberMCcycles= 100000\n",
    "# guess for variational parameters\n",
    "x0 = np.array([0.9,0.2])\n",
    "# Using Broydens method to find optimal parameters\n",
    "res = minimize(Energy, x0, method='BFGS', jac=EnergyDerivative, options={'gtol': 1e-4,'disp': True})\n",
    "x0 = res.x\n",
    "# Compute the energy again with the optimal parameters and increased number of Monte Cycles\n",
    "NumberMCcycles= 2**19\n",
    "Printout = True\n",
    "FinalEnergy = Energy(x0)\n",
    "EResult = np.array([FinalEnergy,FinalEnergy])\n",
    "outfile.close()\n",
    "#nice printout with Pandas\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "data ={'Optimal Parameters':x0, 'Final Energy':EResult}\n",
    "frame = pd.DataFrame(data)\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf86d89",
   "metadata": {},
   "source": [
    "Note that the **minimize** function returns the final values for the\n",
    "variable $\\alpha=x0[0]$ and $\\beta=x0[1]$ in the array $x$.\n",
    "\n",
    "When we have found the minimum, we use these optimal parameters to perform a production run of energies.\n",
    "The output is in turn written to file and is used, together with resampling methods like the **blocking method**,\n",
    "to obtain the best possible estimate for the standard deviation.   The optimal minimum is, even with our guess, rather close to the exact value of $3.0$ a.u.\n",
    "\n",
    "The [sampling\n",
    "functions](https://github.com/CompPhysics/ComputationalPhysics2/tree/gh-pages/doc/Programs/Resampling)\n",
    "can be used to perform both a blocking analysis, or a standard\n",
    "bootstrap and jackknife analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4012c31",
   "metadata": {},
   "source": [
    "## How do we proceed?\n",
    "\n",
    "There are several paths which can be chosen. One is to extend the\n",
    "brute force gradient descent method with an adapative stochastic\n",
    "gradient. There are several examples of this. A recent approach based\n",
    "on [the Langevin equations](https://arxiv.org/pdf/1805.09416.pdf)\n",
    "seems like a promising approach for general and possibly non-convex\n",
    "optimization problems.\n",
    "\n",
    "Here we would like to point out that our next step is now to use the\n",
    "optimal values for our variational parameters and use these as inputs\n",
    "to a production run. Here we would output values of the energy and\n",
    "perform for example a blocking analysis of the results in order to get\n",
    "a best possible estimate of the standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94ab471",
   "metadata": {},
   "source": [
    "## Resampling analysis\n",
    "\n",
    "The next step is then to use the above data sets and perform a\n",
    "resampling analysis, either using say the Bootstrap method or the\n",
    "Blocking method. Since the data will be correlated, we would recommend\n",
    "to use the non-iid Bootstrap code here. The theoretical background for these resampling methods is found in the [statistical analysis lecture notes](http://compphysics.github.io/ComputationalPhysics2/doc/pub/statanalysis/html/statanalysis.html)\n",
    "\n",
    "Here we have tailored the codes to the output file from the previous example. We present first the bootstrap resampling with non-iid stochastic event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb807e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 2.92407 sec\n",
      "Bootstrap Statistics :\n",
      "original           bias      std. error\n",
      "  3.0007   -1.54299e-06     2.28397e-05\n"
     ]
    }
   ],
   "source": [
    "# Common imports\n",
    "import os\n",
    "\n",
    "# Where to save the figures and data files\n",
    "DATA_ID = \"Results/EnergyMin\"\n",
    "\n",
    "def data_path(dat_id):\n",
    "    return os.path.join(DATA_ID, dat_id)\n",
    "\n",
    "infile = open(data_path(\"Energies.dat\"),'r')\n",
    "\n",
    "from numpy import std, mean, concatenate, arange, loadtxt, zeros, ceil\n",
    "from numpy.random import randint\n",
    "from time import time\n",
    "\n",
    "\n",
    "def tsboot(data,statistic,R,l):\n",
    "    t = zeros(R); n = len(data); k = int(ceil(float(n)/l));\n",
    "    inds = arange(n); t0 = time()\n",
    "    \n",
    "    # time series bootstrap\n",
    "    for i in range(R):\n",
    "        # construct bootstrap sample from\n",
    "        # k chunks of data. The chunksize is l\n",
    "        _data = concatenate([data[j:j+l] for j in randint(0,n-l,k)])[0:n];\n",
    "        t[i] = statistic(_data)\n",
    "\n",
    "    # analysis\n",
    "    print (\"Runtime: %g sec\" % (time()-t0)); print (\"Bootstrap Statistics :\")\n",
    "    print (\"original           bias      std. error\")\n",
    "    print (\"%8g %14g %15g\" % (statistic(data), \\\n",
    "                             mean(t) - statistic(data), \\\n",
    "                             std(t) ))\n",
    "    return t\n",
    "# Read in data\n",
    "X = loadtxt(infile)\n",
    "# statistic to be estimated. Takes two args.\n",
    "# arg1: the data\n",
    "def stat(data):\n",
    "    return mean(data)\n",
    "t = tsboot(X, stat, 2**12, 2**10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e644c50",
   "metadata": {},
   "source": [
    "The blocking code, based on the article of [Marius Jonsson](https://journals.aps.org/pre/abstract/10.1103/PhysRevE.98.043304) is given here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "521e75c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Mean     STDev\n",
      "Values  3.000699  0.000082\n"
     ]
    }
   ],
   "source": [
    "# Common imports\n",
    "import os\n",
    "\n",
    "# Where to save the figures and data files\n",
    "DATA_ID = \"Results/EnergyMin\"\n",
    "\n",
    "def data_path(dat_id):\n",
    "    return os.path.join(DATA_ID, dat_id)\n",
    "\n",
    "infile = open(data_path(\"Energies.dat\"),'r')\n",
    "\n",
    "from numpy import log2, zeros, mean, var, sum, loadtxt, arange, array, cumsum, dot, transpose, diagonal, sqrt\n",
    "from numpy.linalg import inv\n",
    "\n",
    "def block(x):\n",
    "    # preliminaries\n",
    "    n = len(x)\n",
    "    d = int(log2(n))\n",
    "    s, gamma = zeros(d), zeros(d)\n",
    "    mu = mean(x)\n",
    "\n",
    "    # estimate the auto-covariance and variances \n",
    "    # for each blocking transformation\n",
    "    for i in arange(0,d):\n",
    "        n = len(x)\n",
    "        # estimate autocovariance of x\n",
    "        gamma[i] = (n)**(-1)*sum( (x[0:(n-1)]-mu)*(x[1:n]-mu) )\n",
    "        # estimate variance of x\n",
    "        s[i] = var(x)\n",
    "        # perform blocking transformation\n",
    "        x = 0.5*(x[0::2] + x[1::2])\n",
    "   \n",
    "    # generate the test observator M_k from the theorem\n",
    "    M = (cumsum( ((gamma/s)**2*2**arange(1,d+1)[::-1])[::-1] )  )[::-1]\n",
    "\n",
    "    # we need a list of magic numbers\n",
    "    q =array([6.634897,9.210340, 11.344867, 13.276704, 15.086272, 16.811894, 18.475307, 20.090235, 21.665994, 23.209251, 24.724970, 26.216967, 27.688250, 29.141238, 30.577914, 31.999927, 33.408664, 34.805306, 36.190869, 37.566235, 38.932173, 40.289360, 41.638398, 42.979820, 44.314105, 45.641683, 46.962942, 48.278236, 49.587884, 50.892181])\n",
    "\n",
    "    # use magic to determine when we should have stopped blocking\n",
    "    for k in arange(0,d):\n",
    "        if(M[k] < q[k]):\n",
    "            break\n",
    "    if (k >= d-1):\n",
    "        print(\"Warning: Use more data\")\n",
    "    return mu, s[k]/2**(d-k)\n",
    "\n",
    "\n",
    "x = loadtxt(infile)\n",
    "(mean, var) = block(x) \n",
    "std = sqrt(var)\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "data ={'Mean':[mean], 'STDev':[std]}\n",
    "frame = pd.DataFrame(data,index=['Values'])\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20da7dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
