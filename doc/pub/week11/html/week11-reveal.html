<!DOCTYPE html>

<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Week 12 March 22-26: Parallelization with MPI and OpenMP and discussions of project 1">

<title>Week 12 March 22-26: Parallelization with MPI and OpenMP and discussions of project 1</title>







<!-- reveal.js: https://lab.hakim.se/reveal-js/ -->

<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

<link rel="stylesheet" href="reveal.js/css/reveal.css">
<link rel="stylesheet" href="reveal.js/css/theme/beige.css" id="theme">
<!--
<link rel="stylesheet" href="reveal.js/css/reveal.css">
<link rel="stylesheet" href="reveal.js/css/theme/beige.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/beigesmall.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/solarized.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/serif.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/night.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/moon.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/simple.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/sky.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/darkgray.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/default.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/cbc.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/simula.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/white.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/league.css" id="theme">
-->

<!-- For syntax highlighting -->
<link rel="stylesheet" href="reveal.js/lib/css/zenburn.css">

<!-- Printing and PDF exports -->
<script>
var link = document.createElement( 'link' );
link.rel = 'stylesheet';
link.type = 'text/css';
link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
document.getElementsByTagName( 'head' )[0].appendChild( link );
</script>

<style type="text/css">
    hr { border: 0; width: 80%; border-bottom: 1px solid #aaa}
    p.caption { width: 80%; font-size: 60%; font-style: italic; text-align: left; }
    hr.figure { border: 0; width: 80%; border-bottom: 1px solid #aaa}
    .reveal .alert-text-small   { font-size: 80%;  }
    .reveal .alert-text-large   { font-size: 130%; }
    .reveal .alert-text-normal  { font-size: 90%;  }
    .reveal .alert {
             padding:8px 35px 8px 14px; margin-bottom:18px;
             text-shadow:0 1px 0 rgba(255,255,255,0.5);
             border:5px solid #bababa;
             -webkit-border-radius: 14px; -moz-border-radius: 14px;
             border-radius:14px;
             background-position: 10px 10px;
             background-repeat: no-repeat;
             background-size: 38px;
             padding-left: 30px; /* 55px; if icon */
     }
     .reveal .alert-block {padding-top:14px; padding-bottom:14px}
     .reveal .alert-block > p, .alert-block > ul {margin-bottom:1em}
     /*.reveal .alert li {margin-top: 1em}*/
     .reveal .alert-block p+p {margin-top:5px}
     /*.reveal .alert-notice { background-image: url(https://hplgit.github.io/doconce/bundled/html_images/small_gray_notice.png); }
     .reveal .alert-summary  { background-image:url(https://hplgit.github.io/doconce/bundled/html_images/small_gray_summary.png); }
     .reveal .alert-warning { background-image: url(https://hplgit.github.io/doconce/bundled/html_images/small_gray_warning.png); }
     .reveal .alert-question {background-image:url(https://hplgit.github.io/doconce/bundled/html_images/small_gray_question.png); } */

</style>



<!-- Styles for table layout of slides -->
<style type="text/css">
td.padding {
  padding-top:20px;
  padding-bottom:20px;
  padding-right:50px;
  padding-left:50px;
}
</style>

</head>

<body>
<div class="reveal">

<!-- Any section element inside the <div class="slides"> container
     is displayed as a slide -->

<div class="slides">





<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



    



<section>
<!-- ------------------- main content ---------------------- -->



<center><h1 style="text-align: center;">Week 12 March 22-26: Parallelization with MPI and OpenMP and discussions of project 1</h1></center>  <!-- document title -->

<p>
<!-- author(s): Morten Hjorth-Jensen  Email morten.hjorth-jensen@fys.uio.no -->

<center>
<b>Morten Hjorth-Jensen  Email morten.hjorth-jensen@fys.uio.no</b> [1, 2]
</center>

<p>&nbsp;<br>
<!-- institution(s) -->

<center>[1] <b>Department of Physics and Center fo Computing in Science Education, University of Oslo, Oslo, Norway</b></center>
<center>[2] <b>Department of Physics and Astronomy and Facility for Rare Ion Beams, Michigan State University, East Lansing, Michigan, USA</b></center>
<br>
<p>&nbsp;<br>
<center><h4>Mar 18, 2021</h4></center> <!-- date -->
<br>
<p>

<center style="font-size:80%">
<!-- copyright --> &copy; 1999-2021, Morten Hjorth-Jensen  Email morten.hjorth-jensen@fys.uio.no. Released under CC Attribution-NonCommercial 4.0 license
</center>
</section>


<section>
<h2 id="overview-of-week-12-march-22-26">Overview of week 12, March 22-26 </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b>Topics</b>
<ul>
<p><li> Discussion of project 1 and possible alternatives for project 2</li>
<p><li> Wrap up of parallelization discussions</li>
</ul>
</div>

<p>
<div class="alert alert-block alert-block alert-text-normal">
<b>Teaching Material, videos and written material</b>
<ul>
<p><li> Background literature: <a href="https://mitpress.mit.edu/books/using-openmp" target="_blank">Using OpenMP by Chapman et al.</a> and <a href="https://mitpress.mit.edu/books/using-mpi-third-edition" target="_blank">Using MPI by Gropp et al.</a>.</li>
</ul>
</div>
</section>


<section>
<h2 id="alternatives-for-project-2">Alternatives for project 2 </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<ol>
<p><li> Fermion VMC, continuation of project 1</li>
<p><li> Deep learning applied to project 1, either neural networks or Boltzmann machines</li>
<p><li> Hartree-Fock theory and time-dependent theories</li>
<p><li> Many-body methods like coupled-cluster theory or other many-body methods</li>
<p><li> Quantum computing and possibly quantum machine learning</li>
<p><li> Suggestions from you</li>
</ol>
</div>
</section>


<section>
<h2 id="what-is-openmp">What is OpenMP </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<ul>
<p><li> OpenMP provides high-level thread programming</li>
<p><li> Multiple cooperating threads are allowed to run simultaneously</li>
<p><li> Threads are created and destroyed dynamically in a fork-join pattern</li>

<ul>

<p><li> An OpenMP program consists of a number of parallel regions</li>

<p><li> Between two parallel regions there is only one master thread</li>

<p><li> In the beginning of a parallel region, a team of new threads is spawned</li>
</ul>
<p><li> The newly spawned threads work simultaneously with the master thread</li>

<p><li> At the end of a parallel region, the new threads are destroyed</li>
</ul>
<p>

Many good tutorials online and excellent textbook

<ol>
<p><li> <a href="http://mitpress.mit.edu/books/using-openmp" target="_blank">Using OpenMP, by B. Chapman, G. Jost, and A. van der Pas</a></li>
<p><li> Many tutorials online like <a href="http://www.openmp.org" target="_blank">OpenMP official site</a></li>
</ol>
</div>
</section>


<section>
<h2 id="getting-started-things-to-remember">Getting started, things to remember </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<ul>
 <p><li> Remember the header file</li> 
</ul>
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#include</span> <span style="color: #228B22">&lt;omp.h&gt;</span><span style="color: #1e889b"></span>
</pre></div>
<ul>
 <p><li> Insert compiler directives in C++ syntax as</li> 
</ul>
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#pragma omp...</span>
</pre></div>
<ul>
<p><li> Compile with for example <em>c++ -fopenmp code.cpp</em></li>
<p><li> Execute</li>

<ul>

<p><li> Remember to assign the environment variable <b>OMP NUM THREADS</b></li>

<p><li> It specifies the total number of threads inside a parallel region, if not otherwise overwritten</li>
</ul>
<p>
</ul>
</div>
</section>


<section>
<h2 id="openmp-syntax">OpenMP syntax </h2>

<ul>
<p><li> Mostly directives</li>
</ul>
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#pragma omp construct [ clause ...]</span>
</pre></div>
<ul>
 <p><li> Some functions and types</li> 
</ul>
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#include</span> <span style="color: #228B22">&lt;omp.h&gt;</span><span style="color: #1e889b"></span>
</pre></div>
<ul>
 <p><li> Most apply to a block of code</li>
 <p><li> Specifically, a <b>structured block</b></li>
 <p><li> Enter at top, exit at bottom only, exit(), abort() permitted</li>
</ul>
</section>


<section>
<h2 id="different-openmp-styles-of-parallelism">Different OpenMP styles of parallelism </h2>
OpenMP supports several different ways to specify thread parallelism

<ul>
<p><li> General parallel regions: All threads execute the code, roughly as if you made a routine of that region and created a thread to run that code</li>
<p><li> Parallel loops: Special case for loops, simplifies data parallel code</li>
<p><li> Task parallelism, new in OpenMP 3</li>
<p><li> Several ways to manage thread coordination, including Master regions and Locks</li>
<p><li> Memory model for shared data</li>
</ul>
</section>


<section>
<h2 id="general-code-structure">General code structure  </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#include</span> <span style="color: #228B22">&lt;omp.h&gt;</span><span style="color: #1e889b"></span>
main ()
{
<span style="color: #00688B; font-weight: bold">int</span> var1, var2, var3;
<span style="color: #228B22">/* serial code */</span>
<span style="color: #228B22">/* ... */</span>
<span style="color: #228B22">/* start of a parallel region */</span>
<span style="color: #1e889b">#pragma omp parallel private(var1, var2) shared(var3)</span>
{
<span style="color: #228B22">/* ... */</span>
}
<span style="color: #228B22">/* more serial code */</span>
<span style="color: #228B22">/* ... */</span>
<span style="color: #228B22">/* another parallel region */</span>
<span style="color: #1e889b">#pragma omp parallel</span>
{
<span style="color: #228B22">/* ... */</span>
}
}
</pre></div>

</div>
</section>


<section>
<h2 id="parallel-region">Parallel region </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<ul>
<p><li> A parallel region is a block of code that is executed by a team of threads</li>
<p><li> The following compiler directive creates a parallel region</li>
</ul>
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#pragma omp parallel { ... }</span>
</pre></div>
<ul>
<p><li> Clauses can be added at the end of the directive</li>
<p><li> Most often used clauses:</li>

<ul>
 <p><li> <b>default(shared)</b> or <b>default(none)</b></li>
 <p><li> <b>public(list of variables)</b></li>
 <p><li> <b>private(list of variables)</b></li>
</ul>
<p>
</ul>
</div>
</section>


<section>
<h2 id="hello-world-not-again-please">Hello world, not again, please! </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#include</span> <span style="color: #228B22">&lt;omp.h&gt;</span><span style="color: #1e889b"></span>
<span style="color: #1e889b">#include</span> <span style="color: #228B22">&lt;cstdio&gt;</span><span style="color: #1e889b"></span>
<span style="color: #00688B; font-weight: bold">int</span> <span style="color: #008b45">main</span> (<span style="color: #00688B; font-weight: bold">int</span> argc, <span style="color: #00688B; font-weight: bold">char</span> *argv[])
{
<span style="color: #00688B; font-weight: bold">int</span> th_id, nthreads;
<span style="color: #1e889b">#pragma omp parallel private(th_id) shared(nthreads)</span>
{
th_id = omp_get_thread_num();
printf(<span style="color: #CD5555">&quot;Hello World from thread %d\n&quot;</span>, th_id);
<span style="color: #1e889b">#pragma omp barrier</span>
<span style="color: #8B008B; font-weight: bold">if</span> ( th_id == <span style="color: #B452CD">0</span> ) {
nthreads = omp_get_num_threads();
printf(<span style="color: #CD5555">&quot;There are %d threads\n&quot;</span>,nthreads);
}
}
<span style="color: #8B008B; font-weight: bold">return</span> <span style="color: #B452CD">0</span>;
}
</pre></div>

</div>
</section>


<section>
<h2 id="hello-world-yet-another-variant">Hello world, yet another variant </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#include</span> <span style="color: #228B22">&lt;cstdio&gt;</span><span style="color: #1e889b"></span>
<span style="color: #1e889b">#include</span> <span style="color: #228B22">&lt;omp.h&gt;</span><span style="color: #1e889b"></span>
<span style="color: #00688B; font-weight: bold">int</span> <span style="color: #008b45">main</span>(<span style="color: #00688B; font-weight: bold">int</span> argc, <span style="color: #00688B; font-weight: bold">char</span> *argv[]) 
{
 omp_set_num_threads(<span style="color: #B452CD">4</span>); 
<span style="color: #1e889b">#pragma omp parallel</span>
 {
   <span style="color: #00688B; font-weight: bold">int</span> id = omp_get_thread_num();
   <span style="color: #00688B; font-weight: bold">int</span> nproc = omp_get_num_threads(); 
   cout &lt;&lt; <span style="color: #CD5555">&quot;Hello world with id number and processes &quot;</span> &lt;&lt;  id &lt;&lt;  nproc &lt;&lt; endl;
 } 
<span style="color: #8B008B; font-weight: bold">return</span> <span style="color: #B452CD">0</span>;
}
</pre></div>
<p>
Variables declared outside of the parallel region are shared by all threads
If a variable like <b>id</b> is  declared outside of the 
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#pragma omp parallel, </span>
</pre></div>
<p>
it would have been shared by various the threads, possibly causing erroneous output

<ul>
 <p><li> Why? What would go wrong? Why do we add  possibly?</li>
</ul>
</div>
</section>


<section>
<h2 id="important-openmp-library-routines">Important OpenMP library routines </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<ul>
<p><li> <b>int omp get num threads ()</b>, returns the number of threads inside a parallel region</li>
<p><li> <b>int omp get thread num ()</b>,  returns the  a thread for each thread inside a parallel region</li>
<p><li> <b>void omp set num threads (int)</b>, sets the number of threads to be used</li>
<p><li> <b>void omp set nested (int)</b>,  turns nested parallelism on/off</li>
</ul>
</div>
</section>


<section>
<h2 id="private-variables">Private variables </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
Private clause can be used to make thread- private versions of such variables: 
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#pragma omp parallel private(id)</span>
{
 <span style="color: #00688B; font-weight: bold">int</span> id = omp_get_thread_num();
 cout &lt;&lt; <span style="color: #CD5555">&quot;My thread num&quot;</span> &lt;&lt; id &lt;&lt; endl; 
}
</pre></div>
<ul>
<p><li> What is their value on entry? Exit?</li>
<p><li> OpenMP provides ways to control that</li>
<p><li> Can use default(none) to require the sharing of each variable to be described</li>
</ul>
</div>
</section>


<section>
<h2 id="master-region">Master region </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
It is often useful to have only one thread execute some of the code in a parallel region. I/O statements are a common example
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#pragma omp parallel </span>
{
  <span style="color: #1e889b">#pragma omp master</span>
   {
      <span style="color: #00688B; font-weight: bold">int</span> id = omp_get_thread_num();
      cout &lt;&lt; <span style="color: #CD5555">&quot;My thread num&quot;</span> &lt;&lt; id &lt;&lt; endl; 
   } 
}
</pre></div>

</div>
</section>


<section>
<h2 id="parallel-for-loop">Parallel for loop </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<ul>
 <p><li> Inside a parallel region, the following compiler directive can be used to parallelize a for-loop:</li>
</ul>
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#pragma omp for</span>
</pre></div>
<ul>
<p><li> Clauses can be added, such as</li>

<ul>

<p><li> <b>schedule(static, chunk size)</b></li>

<p><li> <b>schedule(dynamic, chunk size)</b></li>

<p><li> <b>schedule(guided, chunk size)</b> (non-deterministic allocation)</li>

<p><li> <b>schedule(runtime)</b></li>

<p><li> <b>private(list of variables)</b></li>

<p><li> <b>reduction(operator:variable)</b></li>

<p><li> <b>nowait</b></li>
</ul>
<p>
</ul>
</div>
</section>


<section>
<h2 id="parallel-computations-and-loops">Parallel computations and loops </h2>

<p>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
OpenMP provides an easy way to parallelize a loop
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#pragma omp parallel for</span>
  <span style="color: #8B008B; font-weight: bold">for</span> (i=<span style="color: #B452CD">0</span>; i&lt;n; i++) c[i] = a[i];
</pre></div>
<p>
OpenMP handles index variable (no need to declare in for loop or make private)

<p>
Which thread does which values?  Several options.
</div>
</section>


<section>
<h2 id="scheduling-of-loop-computations">Scheduling of  loop computations </h2>

<p>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
We can let  the OpenMP runtime decide. The decision is about how the loop iterates are scheduled
and  OpenMP defines three choices of loop scheduling:

<ol>
<p><li> Static: Predefined at compile time. Lowest overhead, predictable</li>
<p><li> Dynamic: Selection made at runtime</li> 
<p><li> Guided: Special case of dynamic; attempts to reduce overhead</li>
</ol>
</div>
</section>


<section>
<h2 id="example-code-for-loop-scheduling">Example code for loop scheduling </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#include</span> <span style="color: #228B22">&lt;omp.h&gt;</span><span style="color: #1e889b"></span>
<span style="color: #1e889b">#define CHUNKSIZE 100</span>
<span style="color: #1e889b">#define N 1000</span>
<span style="color: #00688B; font-weight: bold">int</span> <span style="color: #008b45">main</span> (<span style="color: #00688B; font-weight: bold">int</span> argc, <span style="color: #00688B; font-weight: bold">char</span> *argv[])
{
<span style="color: #00688B; font-weight: bold">int</span> i, chunk;
<span style="color: #00688B; font-weight: bold">float</span> a[N], b[N], c[N];
<span style="color: #8B008B; font-weight: bold">for</span> (i=<span style="color: #B452CD">0</span>; i &lt; N; i++) a[i] = b[i] = i * <span style="color: #B452CD">1.0</span>;
chunk = CHUNKSIZE;
<span style="color: #1e889b">#pragma omp parallel shared(a,b,c,chunk) private(i)</span>
{
<span style="color: #1e889b">#pragma omp for schedule(dynamic,chunk)</span>
<span style="color: #8B008B; font-weight: bold">for</span> (i=<span style="color: #B452CD">0</span>; i &lt; N; i++) c[i] = a[i] + b[i];
} <span style="color: #228B22">/* end of parallel region */</span>
}
</pre></div>

</div>
</section>


<section>
<h2 id="example-code-for-loop-scheduling-guided-instead-of-dynamic">Example code for loop scheduling, guided instead of dynamic </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#include</span> <span style="color: #228B22">&lt;omp.h&gt;</span><span style="color: #1e889b"></span>
<span style="color: #1e889b">#define CHUNKSIZE 100</span>
<span style="color: #1e889b">#define N 1000</span>
<span style="color: #00688B; font-weight: bold">int</span> <span style="color: #008b45">main</span> (<span style="color: #00688B; font-weight: bold">int</span> argc, <span style="color: #00688B; font-weight: bold">char</span> *argv[])
{
<span style="color: #00688B; font-weight: bold">int</span> i, chunk;
<span style="color: #00688B; font-weight: bold">float</span> a[N], b[N], c[N];
<span style="color: #8B008B; font-weight: bold">for</span> (i=<span style="color: #B452CD">0</span>; i &lt; N; i++) a[i] = b[i] = i * <span style="color: #B452CD">1.0</span>;
chunk = CHUNKSIZE;
<span style="color: #1e889b">#pragma omp parallel shared(a,b,c,chunk) private(i)</span>
{
<span style="color: #1e889b">#pragma omp for schedule(guided,chunk)</span>
<span style="color: #8B008B; font-weight: bold">for</span> (i=<span style="color: #B452CD">0</span>; i &lt; N; i++) c[i] = a[i] + b[i];
} <span style="color: #228B22">/* end of parallel region */</span>
}
</pre></div>

</div>
</section>


<section>
<h2 id="more-on-parallel-for-loop">More on Parallel for loop </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<ul>
<p><li> The number of loop iterations cannot be non-deterministic; break, return, exit, goto not allowed inside the for-loop</li>
<p><li> The loop index is private to each thread</li>
<p><li> A reduction variable is special</li>

<ul>

<p><li> During the for-loop there is a local private copy in each thread</li>

<p><li> At the end of the for-loop, all the local copies are combined together by the reduction operation</li>
</ul>
<p><li> Unless the nowait clause is used, an implicit barrier synchronization will be added at the end by the compiler</li>
</ul>
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #228B22">// #pragma omp parallel and #pragma omp for</span>
</pre></div>
<p>
can be combined into
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#pragma omp parallel for</span>
</pre></div>

</div>
</section>


<section>
<h2 id="what-can-happen-with-this-loop">What can happen with this loop? </h2>

<p>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
What happens with code like this 
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#pragma omp parallel for</span>
<span style="color: #8B008B; font-weight: bold">for</span> (i=<span style="color: #B452CD">0</span>; i&lt;n; i++) sum += a[i]*a[i];
</pre></div>
<p>
All threads can access the <b>sum</b> variable, but the addition is not atomic! It is important to avoid race between threads. So-called reductions in OpenMP are thus important for performance and for obtaining correct results.  OpenMP lets us indicate that a variable is used for a reduction with a particular operator. The above code becomes
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span>sum = <span style="color: #B452CD">0.0</span>;
<span style="color: #1e889b">#pragma omp parallel for reduction(+:sum)</span>
<span style="color: #8B008B; font-weight: bold">for</span> (i=<span style="color: #B452CD">0</span>; i&lt;n; i++) sum += a[i]*a[i];
</pre></div>

</div>
</section>


<section>
<h2 id="inner-product">Inner product </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>&nbsp;<br>
$$
\sum_{i=0}^{n-1} a_ib_i
$$
<p>&nbsp;<br>

<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #00688B; font-weight: bold">int</span> i;
<span style="color: #00688B; font-weight: bold">double</span> sum = <span style="color: #B452CD">0.</span>;
<span style="color: #228B22">/* allocating and initializing arrays */</span>
<span style="color: #228B22">/* ... */</span>
<span style="color: #1e889b">#pragma omp parallel for default(shared) private(i) reduction(+:sum)</span>
 <span style="color: #8B008B; font-weight: bold">for</span> (i=<span style="color: #B452CD">0</span>; i&lt;N; i++) sum += a[i]*b[i];
}
</pre></div>

</div>
</section>


<section>
<h2 id="different-threads-do-different-tasks">Different threads do different tasks </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
Different threads do different tasks independently, each section is executed by one thread.
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#pragma omp parallel</span>
{
<span style="color: #1e889b">#pragma omp sections</span>
{
<span style="color: #1e889b">#pragma omp section</span>
funcA ();
<span style="color: #1e889b">#pragma omp section</span>
funcB ();
<span style="color: #1e889b">#pragma omp section</span>
funcC ();
}
}
</pre></div>

</div>
</section>


<section>
<h2 id="single-execution">Single execution  </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#pragma omp single { ... }</span>
</pre></div>
<p>
The code is executed by one thread only, no guarantee which thread

<p>
Can introduce an implicit barrier at the end
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#pragma omp master { ... }</span>
</pre></div>
<p>
Code executed by the master thread, guaranteed and no implicit barrier at the end.
</div>
</section>


<section>
<h2 id="coordination-and-synchronization">Coordination and synchronization  </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#pragma omp barrier</span>
</pre></div>
<p>
Synchronization, must be encountered by all threads in a team (or none)
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#pragma omp ordered { a block of codes }</span>
</pre></div>
<p>
is another form of synchronization (in sequential order).
The form
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#pragma omp critical { a block of codes }</span>
</pre></div>
<p>
and 
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#pragma omp atomic { single assignment statement }</span>
</pre></div>
<p>
is  more efficient than 
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#pragma omp critical</span>
</pre></div>

</div>
</section>


<section>
<h2 id="data-scope">Data scope  </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<ul>
<p><li> OpenMP data scope attribute clauses:</li>

<ul>
 <p><li> <b>shared</b></li>
 <p><li> <b>private</b></li>
 <p><li> <b>firstprivate</b></li>
 <p><li> <b>lastprivate</b></li>
 <p><li> <b>reduction</b></li>
</ul>
<p>
</ul>
<p>

What are the purposes of these attributes

<ul>
<p><li> define how and which variables are transferred to a parallel region (and back)</li>
<p><li> define which variables are visible to all threads in a parallel region, and which variables are privately allocated to each thread</li>
</ul>
</div>
</section>


<section>
<h2 id="some-remarks">Some remarks  </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<ul>
<p><li> When entering a parallel region, the <b>private</b> clause ensures each thread having its own new variable instances. The new variables are assumed to be uninitialized.</li>
<p><li> A shared variable exists in only one memory location and all threads can read and write to that address. It is the programmer's responsibility to ensure that multiple threads properly access a shared variable.</li>
<p><li> The <b>firstprivate</b> clause combines the behavior of the private clause with automatic initialization.</li>
<p><li> The <b>lastprivate</b> clause combines the behavior of the private clause with a copy back (from the last loop iteration or section) to the original variable outside the parallel region.</li>
</ul>
</div>
</section>


<section>
<h2 id="parallelizing-nested-for-loops">Parallelizing nested for-loops </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<ul>
 <p><li> Serial code</li>
</ul>
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #8B008B; font-weight: bold">for</span> (i=<span style="color: #B452CD">0</span>; i&lt;<span style="color: #B452CD">100</span>; i++)
    <span style="color: #8B008B; font-weight: bold">for</span> (j=<span style="color: #B452CD">0</span>; j&lt;<span style="color: #B452CD">100</span>; j++)
        a[i][j] = b[i][j] + c[i][j];
    }
}
</pre></div>
<ul>
<p><li> Parallelization</li>
</ul>
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#pragma omp parallel for private(j)</span>
<span style="color: #8B008B; font-weight: bold">for</span> (i=<span style="color: #B452CD">0</span>; i&lt;<span style="color: #B452CD">100</span>; i++)
    <span style="color: #8B008B; font-weight: bold">for</span> (j=<span style="color: #B452CD">0</span>; j&lt;<span style="color: #B452CD">100</span>; j++)
       a[i][j] = b[i][j] + c[i][j];
    }
}
</pre></div>
<ul>
<p><li> Why not parallelize the inner loop? to save overhead of repeated thread forks-joins</li>
<p><li> Why must <b>j</b> be private? To avoid race condition among the threads</li>
</ul>
</div>
</section>


<section>
<h2 id="nested-parallelism">Nested parallelism  </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
When a thread in a parallel region encounters another parallel construct, it
may create a new team of threads and become the master of the new
team.
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#pragma omp parallel num_threads(4)</span>
{
<span style="color: #228B22">/* .... */</span>
<span style="color: #1e889b">#pragma omp parallel num_threads(2)</span>
{
<span style="color: #228B22">//  </span>
}
}
</pre></div>

</div>
</section>


<section>
<h2 id="parallel-tasks">Parallel tasks </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#pragma omp task </span>
<span style="color: #1e889b">#pragma omp parallel shared(p_vec) private(i)</span>
{
<span style="color: #1e889b">#pragma omp single</span>
{
<span style="color: #8B008B; font-weight: bold">for</span> (i=<span style="color: #B452CD">0</span>; i&lt;N; i++) {
  <span style="color: #00688B; font-weight: bold">double</span> r = random_number();
  <span style="color: #8B008B; font-weight: bold">if</span> (p_vec[i] &gt; r) {
<span style="color: #1e889b">#pragma omp task</span>
   do_work (p_vec[i]);
</pre></div>

</div>
</section>


<section>
<h2 id="common-mistakes">Common mistakes </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
Race condition
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #00688B; font-weight: bold">int</span> nthreads;
<span style="color: #1e889b">#pragma omp parallel shared(nthreads)</span>
{
nthreads = omp_get_num_threads();
}
</pre></div>
<p>
Deadlock
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#pragma omp parallel</span>
{
...
<span style="color: #1e889b">#pragma omp critical</span>
{
...
<span style="color: #1e889b">#pragma omp barrier</span>
}
}
</pre></div>

</div>
</section>


<section>
<h2 id="not-all-computations-are-simple">Not all computations are simple </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
Not all computations are simple loops where the data can be evenly 
divided among threads without any dependencies between threads

<p>
An example is finding the location and value of the largest element in an array
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #8B008B; font-weight: bold">for</span> (i=<span style="color: #B452CD">0</span>; i&lt;n; i++) { 
   <span style="color: #8B008B; font-weight: bold">if</span> (x[i] &gt; maxval) {
      maxval = x[i];
      maxloc = i; 
   }
}
</pre></div>

</div>
</section>


<section>
<h2 id="not-all-computations-are-simple-competing-threads">Not all computations are simple, competing threads </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
All threads are potentially accessing and changing the same values, <b>maxloc</b> and <b>maxval</b>.

<ol>
<p><li> OpenMP provides several ways to coordinate access to shared values</li>
</ol>
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#pragma omp atomic</span>
</pre></div>
<ol>
<p><li> Only one thread at a time can execute the following statement (not block). We can use the critical option</li>
</ol>
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#pragma omp critical</span>
</pre></div>
<ol>
<p><li> Only one thread at a time can execute the following block</li>
</ol>
<p>

Atomic may be faster than critical but depends on hardware
</div>
</section>


<section>
<h2 id="how-to-find-the-max-value-using-openmp">How to find the max value using OpenMP </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
Write down the simplest algorithm and look carefully for race conditions. How would you handle them? 
The first step would be to parallelize as 
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#pragma omp parallel for</span>
 <span style="color: #8B008B; font-weight: bold">for</span> (i=<span style="color: #B452CD">0</span>; i&lt;n; i++) {
    <span style="color: #8B008B; font-weight: bold">if</span> (x[i] &gt; maxval) {
      maxval = x[i];
      maxloc = i; 
    }
}
</pre></div>

</div>
</section>


<section>
<h2 id="then-deal-with-the-race-conditions">Then deal with the race conditions  </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
Write down the simplest algorithm and look carefully for race conditions. How would you handle them? 
The first step would be to parallelize as 
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#pragma omp parallel for</span>
 <span style="color: #8B008B; font-weight: bold">for</span> (i=<span style="color: #B452CD">0</span>; i&lt;n; i++) {
<span style="color: #1e889b">#pragma omp critical</span>
  {
     <span style="color: #8B008B; font-weight: bold">if</span> (x[i] &gt; maxval) {
       maxval = x[i];
       maxloc = i; 
     }
  }
} 
</pre></div>
<p>
Exercise: write a code which implements this and give an estimate on performance. Perform several runs,
with a serial code only with and without vectorization and compare the serial code with the one that  uses OpenMP. Run on different archictectures if you can.
</div>
</section>


<section>
<h2 id="what-can-slow-down-openmp-performance">What can slow down OpenMP performance?   </h2>
Give it a thought!
</section>


<section>
<h2 id="what-can-slow-down-openmp-performance">What can slow down OpenMP performance?   </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
Performance poor because we insisted on keeping track of the maxval and location during the execution of the loop.

<ul>
 <p><li> We do not care about the value during the execution of the loop, just the value at the end.</li>
</ul>
<p>

This is a common source of performance issues, namely the description of the method used to compute a value imposes additional, unnecessary requirements or properties

<p>
<b>Idea: Have each thread find the maxloc in its own data, then combine and use temporary arrays indexed by thread number to hold the values found by each thread</b>
</div>
</section>


<section>
<h2 id="find-the-max-location-for-each-thread">Find the max location for each thread </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #00688B; font-weight: bold">int</span> maxloc[MAX_THREADS], mloc;
<span style="color: #00688B; font-weight: bold">double</span> maxval[MAX_THREADS], mval; 
<span style="color: #1e889b">#pragma omp parallel shared(maxval,maxloc)</span>
{
  <span style="color: #00688B; font-weight: bold">int</span> id = omp_get_thread_num(); 
  maxval[id] = <span style="color: #B452CD">-1.0e30</span>;
<span style="color: #1e889b">#pragma omp for</span>
   <span style="color: #8B008B; font-weight: bold">for</span> (<span style="color: #00688B; font-weight: bold">int</span> i=<span style="color: #B452CD">0</span>; i&lt;n; i++) {
       <span style="color: #8B008B; font-weight: bold">if</span> (x[i] &gt; maxval[id]) { 
           maxloc[id] = i;
           maxval[id] = x[i]; 
       }
    }
}
</pre></div>

</div>
</section>


<section>
<h2 id="combine-the-values-from-each-thread">Combine the values from each thread </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span><span style="color: #1e889b">#pragma omp flush (maxloc,maxval)</span>
<span style="color: #1e889b">#pragma omp master</span>
  {
    <span style="color: #00688B; font-weight: bold">int</span> nt = omp_get_num_threads(); 
    mloc = maxloc[<span style="color: #B452CD">0</span>]; 
    mval = maxval[<span style="color: #B452CD">0</span>]; 
    <span style="color: #8B008B; font-weight: bold">for</span> (<span style="color: #00688B; font-weight: bold">int</span> i=<span style="color: #B452CD">1</span>; i&lt;nt; i++) {
        <span style="color: #8B008B; font-weight: bold">if</span> (maxval[i] &gt; mval) { 
           mval = maxval[i]; 
           mloc = maxloc[i];
        } 
     }
   }
</pre></div>
<p>
Note that we let the master process perform the last operation.
</div>
</section>


<section>
<h2 id="matrix-matrix-multiplication-https-github-com-compphysics-computationalphysicsmsu-blob-master-doc-programs-parallelizationopenmp-openmpvectornorm-cpp"><a href="https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/ParallelizationOpenMP/OpenMPvectornorm.cpp" target="_blank">Matrix-matrix multiplication</a> </h2>
This code computes the norm of a vector using OpenMp
<p>

<!-- code=text typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span>//  OpenMP program to compute vector norm by adding two other vectors
#include &lt;cstdlib&gt;
#include &lt;iostream&gt;
#include &lt;cmath&gt;
#include &lt;iomanip&gt;
#include  &lt;omp.h&gt;
# include &lt;ctime&gt;

using namespace std; // note use of namespace
int main (int argc, char* argv[])
{
  // read in dimension of vector
  int n = atoi(argv[1]);
  double *a, *b, *c;
  int i;
  int thread_num;
  double wtime, Norm2, s, angle;
  cout &lt;&lt; &quot;  Perform addition of two vectors and compute the norm-2.&quot; &lt;&lt; endl;
  omp_set_num_threads(4);
  thread_num = omp_get_max_threads ();
  cout &lt;&lt; &quot;  The number of processors available = &quot; &lt;&lt; omp_get_num_procs () &lt;&lt; endl ;
  cout &lt;&lt; &quot;  The number of threads available    = &quot; &lt;&lt; thread_num &lt;&lt;  endl;
  cout &lt;&lt; &quot;  The matrix order n                 = &quot; &lt;&lt; n &lt;&lt; endl;

  s = 1.0/sqrt( (double) n);
  wtime = omp_get_wtime ( );
  // Allocate space for the vectors to be used
  a = new double [n]; b = new double [n]; c = new double [n];
  // Define parallel region
# pragma omp parallel for default(shared) private (angle, i) reduction(+:Norm2)
  // Set up values for vectors  a and b
  for (i = 0; i &lt; n; i++){
      angle = 2.0*M_PI*i/ (( double ) n);
      a[i] = s*(sin(angle) + cos(angle));
      b[i] =  s*sin(2.0*angle);
      c[i] = 0.0;
  }
  // Then perform the vector addition
  for (i = 0; i &lt; n; i++){
     c[i] += a[i]+b[i];
  }
  // Compute now the norm-2
  Norm2 = 0.0;
  for (i = 0; i &lt; n; i++){
     Norm2  += c[i]*c[i];
  }
// end parallel region
  wtime = omp_get_wtime ( ) - wtime;
  cout &lt;&lt; setiosflags(ios::showpoint | ios::uppercase);
  cout &lt;&lt; setprecision(10) &lt;&lt; setw(20) &lt;&lt; &quot;Time used  for norm-2 computation=&quot; &lt;&lt; wtime  &lt;&lt; endl;
  cout &lt;&lt; &quot; Norm-2  = &quot; &lt;&lt; Norm2 &lt;&lt; endl;
  // Free up space
  delete[] a;
  delete[] b;
  delete[] c;
  return 0;
}
</pre></div>
</section>


<section>
<h2 id="matrix-matrix-multiplication-https-github-com-compphysics-computationalphysicsmsu-blob-master-doc-programs-parallelizationopenmp-openmpmatrixmatrixmult-cpp"><a href="https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/ParallelizationOpenMP/OpenMPmatrixmatrixmult.cpp" target="_blank">Matrix-matrix multiplication</a> </h2>
This the matrix-matrix multiplication code with plain c++ memory allocation using OpenMP

<p>

<!-- code=text typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="font-size: 80%; line-height: 125%;"><span></span>//  Matrix-matrix multiplication and Frobenius norm of a matrix with OpenMP
#include &lt;cstdlib&gt;
#include &lt;iostream&gt;
#include &lt;cmath&gt;
#include &lt;iomanip&gt;
#include  &lt;omp.h&gt;
# include &lt;ctime&gt;

using namespace std; // note use of namespace
int main (int argc, char* argv[])
{
  // read in dimension of square matrix
  int n = atoi(argv[1]);
  double **A, **B, **C;
  int i, j, k;
  int thread_num;
  double wtime, Fsum, s, angle;
  cout &lt;&lt; &quot;  Compute matrix product C = A * B and Frobenius norm.&quot; &lt;&lt; endl;
  omp_set_num_threads(4);
  thread_num = omp_get_max_threads ();
  cout &lt;&lt; &quot;  The number of processors available = &quot; &lt;&lt; omp_get_num_procs () &lt;&lt; endl ;
  cout &lt;&lt; &quot;  The number of threads available    = &quot; &lt;&lt; thread_num &lt;&lt;  endl;
  cout &lt;&lt; &quot;  The matrix order n                 = &quot; &lt;&lt; n &lt;&lt; endl;

  s = 1.0/sqrt( (double) n);
  wtime = omp_get_wtime ( );
  // Allocate space for the two matrices
  A = new double*[n]; B = new double*[n]; C = new double*[n];
  for (i = 0; i &lt; n; i++){
    A[i] = new double[n];
    B[i] = new double[n];
    C[i] = new double[n];
  }
  // Define parallel region
# pragma omp parallel for default(shared) private (angle, i, j, k) reduction(+:Fsum)
  // Set up values for matrix A and B and zero matrix C
  for (i = 0; i &lt; n; i++){
    for (j = 0; j &lt; n; j++) {
      angle = 2.0*M_PI*i*j/ (( double ) n);
      A[i][j] = s * ( sin ( angle ) + cos ( angle ) );
      B[j][i] =  A[i][j];
    }
  }
  // Then perform the matrix-matrix multiplication
  for (i = 0; i &lt; n; i++){
    for (j = 0; j &lt; n; j++) {
       C[i][j] =  0.0;    
       for (k = 0; k &lt; n; k++) {
            C[i][j] += A[i][k]*B[k][j];
       }
    }
  }
  // Compute now the Frobenius norm
  Fsum = 0.0;
  for (i = 0; i &lt; n; i++){
    for (j = 0; j &lt; n; j++) {
      Fsum += C[i][j]*C[i][j];
    }
  }
  Fsum = sqrt(Fsum);
// end parallel region and letting only one thread perform I/O
  wtime = omp_get_wtime ( ) - wtime;
  cout &lt;&lt; setiosflags(ios::showpoint | ios::uppercase);
  cout &lt;&lt; setprecision(10) &lt;&lt; setw(20) &lt;&lt; &quot;Time used  for matrix-matrix multiplication=&quot; &lt;&lt; wtime  &lt;&lt; endl;
  cout &lt;&lt; &quot;  Frobenius norm  = &quot; &lt;&lt; Fsum &lt;&lt; endl;
  // Free up space
  for (int i = 0; i &lt; n; i++){
    delete[] A[i];
    delete[] B[i];
    delete[] C[i];
  }
  delete[] A;
  delete[] B;
  delete[] C;
  return 0;
}
</pre></div>
</section>



</div> <!-- class="slides" -->
</div> <!-- class="reveal" -->

<script src="reveal.js/lib/js/head.min.js"></script>
<script src="reveal.js/js/reveal.js"></script>

<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({

    // Display navigation controls in the bottom right corner
    controls: true,

    // Display progress bar (below the horiz. slider)
    progress: true,

    // Display the page number of the current slide
    slideNumber: true,

    // Push each slide change to the browser history
    history: false,

    // Enable keyboard shortcuts for navigation
    keyboard: true,

    // Enable the slide overview mode
    overview: true,

    // Vertical centering of slides
    //center: true,
    center: false,

    // Enables touch navigation on devices with touch input
    touch: true,

    // Loop the presentation
    loop: false,

    // Change the presentation direction to be RTL
    rtl: false,

    // Turns fragments on and off globally
    fragments: true,

    // Flags if the presentation is running in an embedded mode,
    // i.e. contained within a limited portion of the screen
    embedded: false,

    // Number of milliseconds between automatically proceeding to the
    // next slide, disabled when set to 0, this value can be overwritten
    // by using a data-autoslide attribute on your slides
    autoSlide: 0,

    // Stop auto-sliding after user input
    autoSlideStoppable: true,

    // Enable slide navigation via mouse wheel
    mouseWheel: false,

    // Hides the address bar on mobile devices
    hideAddressBar: true,

    // Opens links in an iframe preview overlay
    previewLinks: false,

    // Transition style
    transition: 'default', // default/cube/page/concave/zoom/linear/fade/none

    // Transition speed
    transitionSpeed: 'default', // default/fast/slow

    // Transition style for full page slide backgrounds
    backgroundTransition: 'default', // default/none/slide/concave/convex/zoom

    // Number of slides away from the current that are visible
    viewDistance: 3,

    // Parallax background image
    //parallaxBackgroundImage: '', // e.g. "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'"

    // Parallax background size
    //parallaxBackgroundSize: '' // CSS syntax, e.g. "2100px 900px"

    theme: Reveal.getQueryHash().theme, // available themes are in reveal.js/css/theme
    transition: Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/none

});

Reveal.initialize({
    dependencies: [
        // Cross-browser shim that fully implements classList - https://github.com/eligrey/classList.js/
        { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },

        // Interpret Markdown in <section> elements
        { src: 'reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
        { src: 'reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },

        // Syntax highlight for <code> elements
        { src: 'reveal.js/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },

        // Zoom in and out with Alt+click
        { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },

        // Speaker notes
        { src: 'reveal.js/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } },

        // Remote control your reveal.js presentation using a touch device
        //{ src: 'reveal.js/plugin/remotes/remotes.js', async: true, condition: function() { return !!document.body.classList; } },

        // MathJax
        //{ src: 'reveal.js/plugin/math/math.js', async: true }
    ]
});

Reveal.initialize({

    // The "normal" size of the presentation, aspect ratio will be preserved
    // when the presentation is scaled to fit different resolutions. Can be
    // specified using percentage units.
    width: 1170,  // original: 960,
    height: 700,

    // Factor of the display size that should remain empty around the content
    margin: 0.1,

    // Bounds for smallest/largest possible scale to apply to content
    minScale: 0.2,
    maxScale: 1.0

});
</script>

<!-- begin footer logo
<div style="position: absolute; bottom: 0px; left: 0; margin-left: 0px">
<img src="somelogo.png">
</div>
     end footer logo -->



</body>
</html>
