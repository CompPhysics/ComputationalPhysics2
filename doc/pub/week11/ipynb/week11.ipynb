{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- dom:TITLE: Week 12 March 22-26: Parallelization with MPI and OpenMP and discussions of project 1 -->\n",
    "# Week 12 March 22-26: Parallelization with MPI and OpenMP and discussions of project 1\n",
    "<!-- dom:AUTHOR: Morten Hjorth-Jensen  Email morten.hjorth-jensen@fys.uio.no at Department of Physics and Center fo Computing in Science Education, University of Oslo, Oslo, Norway & Department of Physics and Astronomy and Facility for Rare Ion Beams, Michigan State University, East Lansing, Michigan, USA -->\n",
    "<!-- Author: -->  \n",
    "**Morten Hjorth-Jensen  Email morten.hjorth-jensen@fys.uio.no**, Department of Physics and Center fo Computing in Science Education, University of Oslo, Oslo, Norway and Department of Physics and Astronomy and Facility for Rare Ion Beams, Michigan State University, East Lansing, Michigan, USA\n",
    "\n",
    "Date: **Mar 18, 2021**\n",
    "\n",
    "Copyright 1999-2021, Morten Hjorth-Jensen  Email morten.hjorth-jensen@fys.uio.no. Released under CC Attribution-NonCommercial 4.0 license\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Overview of week 12, March 22-26\n",
    "**Topics.**\n",
    "\n",
    "* Discussion of project 1 and possible alternatives for project 2\n",
    "\n",
    "* Wrap up of parallelization discussions\n",
    "\n",
    "\n",
    "\n",
    "**Teaching Material, videos and written material.**\n",
    "\n",
    "* Background literature: [Using OpenMP by Chapman et al.](https://mitpress.mit.edu/books/using-openmp) and [Using MPI by Gropp et al.](https://mitpress.mit.edu/books/using-mpi-third-edition).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Alternatives for project 2\n",
    "1. Fermion VMC, continuation of project 1\n",
    "\n",
    "2. Deep learning applied to project 1, either neural networks or Boltzmann machines\n",
    "\n",
    "3. Hartree-Fock theory and time-dependent theories\n",
    "\n",
    "4. Many-body methods like coupled-cluster theory or other many-body methods\n",
    "\n",
    "5. Quantum computing and possibly quantum machine learning\n",
    "\n",
    "6. Suggestions from you\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## What is OpenMP\n",
    "* OpenMP provides high-level thread programming\n",
    "\n",
    "* Multiple cooperating threads are allowed to run simultaneously\n",
    "\n",
    "* Threads are created and destroyed dynamically in a fork-join pattern\n",
    "\n",
    "   * An OpenMP program consists of a number of parallel regions\n",
    "\n",
    "   * Between two parallel regions there is only one master thread\n",
    "\n",
    "   * In the beginning of a parallel region, a team of new threads is spawned\n",
    "\n",
    "\n",
    "  * The newly spawned threads work simultaneously with the master thread\n",
    "\n",
    "  * At the end of a parallel region, the new threads are destroyed\n",
    "\n",
    "Many good tutorials online and excellent textbook\n",
    "1. [Using OpenMP, by B. Chapman, G. Jost, and A. van der Pas](http://mitpress.mit.edu/books/using-openmp)\n",
    "\n",
    "2. Many tutorials online like [OpenMP official site](http://www.openmp.org)\n",
    "\n",
    "\n",
    "\n",
    "## Getting started, things to remember\n",
    " * Remember the header file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #include <omp.h>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Insert compiler directives in C++ syntax as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compile with for example *c++ -fopenmp code.cpp*\n",
    "\n",
    "* Execute\n",
    "\n",
    "  * Remember to assign the environment variable **OMP NUM THREADS**\n",
    "\n",
    "  * It specifies the total number of threads inside a parallel region, if not otherwise overwritten\n",
    "\n",
    "\n",
    "\n",
    "## OpenMP syntax\n",
    "* Mostly directives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp construct [ clause ...]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Some functions and types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #include <omp.h>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Most apply to a block of code\n",
    "\n",
    " * Specifically, a **structured block**\n",
    "\n",
    " * Enter at top, exit at bottom only, exit(), abort() permitted\n",
    "\n",
    "## Different OpenMP styles of parallelism\n",
    "OpenMP supports several different ways to specify thread parallelism\n",
    "\n",
    "* General parallel regions: All threads execute the code, roughly as if you made a routine of that region and created a thread to run that code\n",
    "\n",
    "* Parallel loops: Special case for loops, simplifies data parallel code\n",
    "\n",
    "* Task parallelism, new in OpenMP 3\n",
    "\n",
    "* Several ways to manage thread coordination, including Master regions and Locks\n",
    "\n",
    "* Memory model for shared data\n",
    "\n",
    "## General code structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #include <omp.h>\n",
    "        main ()\n",
    "        {\n",
    "        int var1, var2, var3;\n",
    "        /* serial code */\n",
    "        /* ... */\n",
    "        /* start of a parallel region */\n",
    "        #pragma omp parallel private(var1, var2) shared(var3)\n",
    "        {\n",
    "        /* ... */\n",
    "        }\n",
    "        /* more serial code */\n",
    "        /* ... */\n",
    "        /* another parallel region */\n",
    "        #pragma omp parallel\n",
    "        {\n",
    "        /* ... */\n",
    "        }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel region\n",
    "* A parallel region is a block of code that is executed by a team of threads\n",
    "\n",
    "* The following compiler directive creates a parallel region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp parallel { ... }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Clauses can be added at the end of the directive\n",
    "\n",
    "* Most often used clauses:\n",
    "\n",
    " * **default(shared)** or **default(none)**\n",
    "\n",
    " * **public(list of variables)**\n",
    "\n",
    " * **private(list of variables)**\n",
    "\n",
    "\n",
    "\n",
    "## Hello world, not again, please!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #include <omp.h>\n",
    "        #include <cstdio>\n",
    "        int main (int argc, char *argv[])\n",
    "        {\n",
    "        int th_id, nthreads;\n",
    "        #pragma omp parallel private(th_id) shared(nthreads)\n",
    "        {\n",
    "        th_id = omp_get_thread_num();\n",
    "        printf(\"Hello World from thread %d\\n\", th_id);\n",
    "        #pragma omp barrier\n",
    "        if ( th_id == 0 ) {\n",
    "        nthreads = omp_get_num_threads();\n",
    "        printf(\"There are %d threads\\n\",nthreads);\n",
    "        }\n",
    "        }\n",
    "        return 0;\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello world, yet another variant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #include <cstdio>\n",
    "        #include <omp.h>\n",
    "        int main(int argc, char *argv[]) \n",
    "        {\n",
    "         omp_set_num_threads(4); \n",
    "        #pragma omp parallel\n",
    "         {\n",
    "           int id = omp_get_thread_num();\n",
    "           int nproc = omp_get_num_threads(); \n",
    "           cout << \"Hello world with id number and processes \" <<  id <<  nproc << endl;\n",
    "         } \n",
    "        return 0;\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables declared outside of the parallel region are shared by all threads\n",
    "If a variable like **id** is  declared outside of the"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp parallel, \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it would have been shared by various the threads, possibly causing erroneous output\n",
    " * Why? What would go wrong? Why do we add  possibly?\n",
    "\n",
    "\n",
    "\n",
    "## Important OpenMP library routines\n",
    "\n",
    "* **int omp get num threads ()**, returns the number of threads inside a parallel region\n",
    "\n",
    "* **int omp get thread num ()**,  returns the  a thread for each thread inside a parallel region\n",
    "\n",
    "* **void omp set num threads (int)**, sets the number of threads to be used\n",
    "\n",
    "* **void omp set nested (int)**,  turns nested parallelism on/off\n",
    "\n",
    "\n",
    "\n",
    "## Private variables\n",
    "Private clause can be used to make thread- private versions of such variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp parallel private(id)\n",
    "        {\n",
    "         int id = omp_get_thread_num();\n",
    "         cout << \"My thread num\" << id << endl; \n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is their value on entry? Exit?\n",
    "\n",
    "* OpenMP provides ways to control that\n",
    "\n",
    "* Can use default(none) to require the sharing of each variable to be described\n",
    "\n",
    "\n",
    "\n",
    "## Master region\n",
    "It is often useful to have only one thread execute some of the code in a parallel region. I/O statements are a common example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp parallel \n",
    "        {\n",
    "          #pragma omp master\n",
    "           {\n",
    "              int id = omp_get_thread_num();\n",
    "              cout << \"My thread num\" << id << endl; \n",
    "           } \n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel for loop\n",
    " * Inside a parallel region, the following compiler directive can be used to parallelize a for-loop:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp for\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Clauses can be added, such as\n",
    "\n",
    "  * **schedule(static, chunk size)**\n",
    "\n",
    "  * **schedule(dynamic, chunk size)** \n",
    "\n",
    "  * **schedule(guided, chunk size)** (non-deterministic allocation)\n",
    "\n",
    "  * **schedule(runtime)**\n",
    "\n",
    "  * **private(list of variables)**\n",
    "\n",
    "  * **reduction(operator:variable)**\n",
    "\n",
    "  * **nowait**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Parallel computations and loops\n",
    "\n",
    "OpenMP provides an easy way to parallelize a loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp parallel for\n",
    "          for (i=0; i<n; i++) c[i] = a[i];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenMP handles index variable (no need to declare in for loop or make private)\n",
    "\n",
    "Which thread does which values?  Several options.\n",
    "\n",
    "\n",
    "\n",
    "## Scheduling of  loop computations\n",
    "\n",
    "We can let  the OpenMP runtime decide. The decision is about how the loop iterates are scheduled\n",
    "and  OpenMP defines three choices of loop scheduling:\n",
    "1. Static: Predefined at compile time. Lowest overhead, predictable\n",
    "\n",
    "2. Dynamic: Selection made at runtime \n",
    "\n",
    "3. Guided: Special case of dynamic; attempts to reduce overhead\n",
    "\n",
    "\n",
    "\n",
    "## Example code for loop scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #include <omp.h>\n",
    "        #define CHUNKSIZE 100\n",
    "        #define N 1000\n",
    "        int main (int argc, char *argv[])\n",
    "        {\n",
    "        int i, chunk;\n",
    "        float a[N], b[N], c[N];\n",
    "        for (i=0; i < N; i++) a[i] = b[i] = i * 1.0;\n",
    "        chunk = CHUNKSIZE;\n",
    "        #pragma omp parallel shared(a,b,c,chunk) private(i)\n",
    "        {\n",
    "        #pragma omp for schedule(dynamic,chunk)\n",
    "        for (i=0; i < N; i++) c[i] = a[i] + b[i];\n",
    "        } /* end of parallel region */\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example code for loop scheduling, guided instead of dynamic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #include <omp.h>\n",
    "        #define CHUNKSIZE 100\n",
    "        #define N 1000\n",
    "        int main (int argc, char *argv[])\n",
    "        {\n",
    "        int i, chunk;\n",
    "        float a[N], b[N], c[N];\n",
    "        for (i=0; i < N; i++) a[i] = b[i] = i * 1.0;\n",
    "        chunk = CHUNKSIZE;\n",
    "        #pragma omp parallel shared(a,b,c,chunk) private(i)\n",
    "        {\n",
    "        #pragma omp for schedule(guided,chunk)\n",
    "        for (i=0; i < N; i++) c[i] = a[i] + b[i];\n",
    "        } /* end of parallel region */\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More on Parallel for loop\n",
    "* The number of loop iterations cannot be non-deterministic; break, return, exit, goto not allowed inside the for-loop\n",
    "\n",
    "* The loop index is private to each thread\n",
    "\n",
    "* A reduction variable is special\n",
    "\n",
    "  * During the for-loop there is a local private copy in each thread\n",
    "\n",
    "  * At the end of the for-loop, all the local copies are combined together by the reduction operation\n",
    "\n",
    "\n",
    "* Unless the nowait clause is used, an implicit barrier synchronization will be added at the end by the compiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        // #pragma omp parallel and #pragma omp for\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can be combined into"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp parallel for\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What can happen with this loop?\n",
    "\n",
    "What happens with code like this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp parallel for\n",
    "        for (i=0; i<n; i++) sum += a[i]*a[i];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All threads can access the **sum** variable, but the addition is not atomic! It is important to avoid race between threads. So-called reductions in OpenMP are thus important for performance and for obtaining correct results.  OpenMP lets us indicate that a variable is used for a reduction with a particular operator. The above code becomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        sum = 0.0;\n",
    "        #pragma omp parallel for reduction(+:sum)\n",
    "        for (i=0; i<n; i++) sum += a[i]*a[i];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inner product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0\n",
    " \n",
    "<\n",
    "<\n",
    "<\n",
    "!\n",
    "!\n",
    "M\n",
    "A\n",
    "T\n",
    "H\n",
    "_\n",
    "B\n",
    "L\n",
    "O\n",
    "C\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        int i;\n",
    "        double sum = 0.;\n",
    "        /* allocating and initializing arrays */\n",
    "        /* ... */\n",
    "        #pragma omp parallel for default(shared) private(i) reduction(+:sum)\n",
    "         for (i=0; i<N; i++) sum += a[i]*b[i];\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different threads do different tasks\n",
    "\n",
    "Different threads do different tasks independently, each section is executed by one thread."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp parallel\n",
    "        {\n",
    "        #pragma omp sections\n",
    "        {\n",
    "        #pragma omp section\n",
    "        funcA ();\n",
    "        #pragma omp section\n",
    "        funcB ();\n",
    "        #pragma omp section\n",
    "        funcC ();\n",
    "        }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp single { ... }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code is executed by one thread only, no guarantee which thread\n",
    "\n",
    "Can introduce an implicit barrier at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp master { ... }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code executed by the master thread, guaranteed and no implicit barrier at the end.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Coordination and synchronization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp barrier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synchronization, must be encountered by all threads in a team (or none)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp ordered { a block of codes }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is another form of synchronization (in sequential order).\n",
    "The form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp critical { a block of codes }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp atomic { single assignment statement }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is  more efficient than"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp critical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data scope\n",
    "* OpenMP data scope attribute clauses:\n",
    "\n",
    " * **shared**\n",
    "\n",
    " * **private**\n",
    "\n",
    " * **firstprivate**\n",
    "\n",
    " * **lastprivate**\n",
    "\n",
    " * **reduction**\n",
    "\n",
    "\n",
    "What are the purposes of these attributes\n",
    "* define how and which variables are transferred to a parallel region (and back)\n",
    "\n",
    "* define which variables are visible to all threads in a parallel region, and which variables are privately allocated to each thread\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Some remarks\n",
    "\n",
    "* When entering a parallel region, the **private** clause ensures each thread having its own new variable instances. The new variables are assumed to be uninitialized.\n",
    "\n",
    "* A shared variable exists in only one memory location and all threads can read and write to that address. It is the programmer's responsibility to ensure that multiple threads properly access a shared variable.\n",
    "\n",
    "* The **firstprivate** clause combines the behavior of the private clause with automatic initialization.\n",
    "\n",
    "* The **lastprivate** clause combines the behavior of the private clause with a copy back (from the last loop iteration or section) to the original variable outside the parallel region.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Parallelizing nested for-loops\n",
    "\n",
    " * Serial code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        for (i=0; i<100; i++)\n",
    "            for (j=0; j<100; j++)\n",
    "                a[i][j] = b[i][j] + c[i][j];\n",
    "            }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Parallelization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp parallel for private(j)\n",
    "        for (i=0; i<100; i++)\n",
    "            for (j=0; j<100; j++)\n",
    "               a[i][j] = b[i][j] + c[i][j];\n",
    "            }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Why not parallelize the inner loop? to save overhead of repeated thread forks-joins\n",
    "\n",
    "* Why must **j** be private? To avoid race condition among the threads\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Nested parallelism\n",
    "When a thread in a parallel region encounters another parallel construct, it\n",
    "may create a new team of threads and become the master of the new\n",
    "team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp parallel num_threads(4)\n",
    "        {\n",
    "        /* .... */\n",
    "        #pragma omp parallel num_threads(2)\n",
    "        {\n",
    "        //  \n",
    "        }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp task \n",
    "        #pragma omp parallel shared(p_vec) private(i)\n",
    "        {\n",
    "        #pragma omp single\n",
    "        {\n",
    "        for (i=0; i<N; i++) {\n",
    "          double r = random_number();\n",
    "          if (p_vec[i] > r) {\n",
    "        #pragma omp task\n",
    "           do_work (p_vec[i]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common mistakes\n",
    "Race condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        int nthreads;\n",
    "        #pragma omp parallel shared(nthreads)\n",
    "        {\n",
    "        nthreads = omp_get_num_threads();\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deadlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp parallel\n",
    "        {\n",
    "        ...\n",
    "        #pragma omp critical\n",
    "        {\n",
    "        ...\n",
    "        #pragma omp barrier\n",
    "        }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- !split  -->\n",
    "## Not all computations are simple\n",
    "Not all computations are simple loops where the data can be evenly \n",
    "divided among threads without any dependencies between threads\n",
    "\n",
    "An example is finding the location and value of the largest element in an array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        for (i=0; i<n; i++) { \n",
    "           if (x[i] > maxval) {\n",
    "              maxval = x[i];\n",
    "              maxloc = i; \n",
    "           }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- !split  -->\n",
    "## Not all computations are simple, competing threads\n",
    "All threads are potentially accessing and changing the same values, **maxloc** and **maxval**.\n",
    "1. OpenMP provides several ways to coordinate access to shared values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp atomic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Only one thread at a time can execute the following statement (not block). We can use the critical option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp critical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Only one thread at a time can execute the following block\n",
    "\n",
    "Atomic may be faster than critical but depends on hardware\n",
    "\n",
    "\n",
    "\n",
    "## How to find the max value using OpenMP\n",
    "Write down the simplest algorithm and look carefully for race conditions. How would you handle them? \n",
    "The first step would be to parallelize as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp parallel for\n",
    "         for (i=0; i<n; i++) {\n",
    "            if (x[i] > maxval) {\n",
    "              maxval = x[i];\n",
    "              maxloc = i; \n",
    "            }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then deal with the race conditions\n",
    "Write down the simplest algorithm and look carefully for race conditions. How would you handle them? \n",
    "The first step would be to parallelize as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp parallel for\n",
    "         for (i=0; i<n; i++) {\n",
    "        #pragma omp critical\n",
    "          {\n",
    "             if (x[i] > maxval) {\n",
    "               maxval = x[i];\n",
    "               maxloc = i; \n",
    "             }\n",
    "          }\n",
    "        } \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: write a code which implements this and give an estimate on performance. Perform several runs,\n",
    "with a serial code only with and without vectorization and compare the serial code with the one that  uses OpenMP. Run on different archictectures if you can.\n",
    "\n",
    "\n",
    "## What can slow down OpenMP performance?\n",
    "Give it a thought!\n",
    "\n",
    "## What can slow down OpenMP performance?\n",
    "Performance poor because we insisted on keeping track of the maxval and location during the execution of the loop.\n",
    " * We do not care about the value during the execution of the loop, just the value at the end.\n",
    "\n",
    "This is a common source of performance issues, namely the description of the method used to compute a value imposes additional, unnecessary requirements or properties\n",
    "\n",
    "**Idea: Have each thread find the maxloc in its own data, then combine and use temporary arrays indexed by thread number to hold the values found by each thread**\n",
    "\n",
    "\n",
    "\n",
    "## Find the max location for each thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        int maxloc[MAX_THREADS], mloc;\n",
    "        double maxval[MAX_THREADS], mval; \n",
    "        #pragma omp parallel shared(maxval,maxloc)\n",
    "        {\n",
    "          int id = omp_get_thread_num(); \n",
    "          maxval[id] = -1.0e30;\n",
    "        #pragma omp for\n",
    "           for (int i=0; i<n; i++) {\n",
    "               if (x[i] > maxval[id]) { \n",
    "                   maxloc[id] = i;\n",
    "                   maxval[id] = x[i]; \n",
    "               }\n",
    "            }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the values from each thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp flush (maxloc,maxval)\n",
    "        #pragma omp master\n",
    "          {\n",
    "            int nt = omp_get_num_threads(); \n",
    "            mloc = maxloc[0]; \n",
    "            mval = maxval[0]; \n",
    "            for (int i=1; i<nt; i++) {\n",
    "                if (maxval[i] > mval) { \n",
    "                   mval = maxval[i]; \n",
    "                   mloc = maxloc[i];\n",
    "                } \n",
    "             }\n",
    "           }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we let the master process perform the last operation.\n",
    "\n",
    "\n",
    "## [Matrix-matrix multiplication](https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/ParallelizationOpenMP/OpenMPvectornorm.cpp)\n",
    "This code computes the norm of a vector using OpenMp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        //  OpenMP program to compute vector norm by adding two other vectors\n",
    "        #include <cstdlib>\n",
    "        #include <iostream>\n",
    "        #include <cmath>\n",
    "        #include <iomanip>\n",
    "        #include  <omp.h>\n",
    "        # include <ctime>\n",
    "        \n",
    "        using namespace std; // note use of namespace\n",
    "        int main (int argc, char* argv[])\n",
    "        {\n",
    "          // read in dimension of vector\n",
    "          int n = atoi(argv[1]);\n",
    "          double *a, *b, *c;\n",
    "          int i;\n",
    "          int thread_num;\n",
    "          double wtime, Norm2, s, angle;\n",
    "          cout << \"  Perform addition of two vectors and compute the norm-2.\" << endl;\n",
    "          omp_set_num_threads(4);\n",
    "          thread_num = omp_get_max_threads ();\n",
    "          cout << \"  The number of processors available = \" << omp_get_num_procs () << endl ;\n",
    "          cout << \"  The number of threads available    = \" << thread_num <<  endl;\n",
    "          cout << \"  The matrix order n                 = \" << n << endl;\n",
    "        \n",
    "          s = 1.0/sqrt( (double) n);\n",
    "          wtime = omp_get_wtime ( );\n",
    "          // Allocate space for the vectors to be used\n",
    "          a = new double [n]; b = new double [n]; c = new double [n];\n",
    "          // Define parallel region\n",
    "        # pragma omp parallel for default(shared) private (angle, i) reduction(+:Norm2)\n",
    "          // Set up values for vectors  a and b\n",
    "          for (i = 0; i < n; i++){\n",
    "              angle = 2.0*M_PI*i/ (( double ) n);\n",
    "              a[i] = s*(sin(angle) + cos(angle));\n",
    "              b[i] =  s*sin(2.0*angle);\n",
    "              c[i] = 0.0;\n",
    "          }\n",
    "          // Then perform the vector addition\n",
    "          for (i = 0; i < n; i++){\n",
    "             c[i] += a[i]+b[i];\n",
    "          }\n",
    "          // Compute now the norm-2\n",
    "          Norm2 = 0.0;\n",
    "          for (i = 0; i < n; i++){\n",
    "             Norm2  += c[i]*c[i];\n",
    "          }\n",
    "        // end parallel region\n",
    "          wtime = omp_get_wtime ( ) - wtime;\n",
    "          cout << setiosflags(ios::showpoint | ios::uppercase);\n",
    "          cout << setprecision(10) << setw(20) << \"Time used  for norm-2 computation=\" << wtime  << endl;\n",
    "          cout << \" Norm-2  = \" << Norm2 << endl;\n",
    "          // Free up space\n",
    "          delete[] a;\n",
    "          delete[] b;\n",
    "          delete[] c;\n",
    "          return 0;\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Matrix-matrix multiplication](https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/ParallelizationOpenMP/OpenMPmatrixmatrixmult.cpp)\n",
    "This the matrix-matrix multiplication code with plain c++ memory allocation using OpenMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        //  Matrix-matrix multiplication and Frobenius norm of a matrix with OpenMP\n",
    "        #include <cstdlib>\n",
    "        #include <iostream>\n",
    "        #include <cmath>\n",
    "        #include <iomanip>\n",
    "        #include  <omp.h>\n",
    "        # include <ctime>\n",
    "        \n",
    "        using namespace std; // note use of namespace\n",
    "        int main (int argc, char* argv[])\n",
    "        {\n",
    "          // read in dimension of square matrix\n",
    "          int n = atoi(argv[1]);\n",
    "          double **A, **B, **C;\n",
    "          int i, j, k;\n",
    "          int thread_num;\n",
    "          double wtime, Fsum, s, angle;\n",
    "          cout << \"  Compute matrix product C = A * B and Frobenius norm.\" << endl;\n",
    "          omp_set_num_threads(4);\n",
    "          thread_num = omp_get_max_threads ();\n",
    "          cout << \"  The number of processors available = \" << omp_get_num_procs () << endl ;\n",
    "          cout << \"  The number of threads available    = \" << thread_num <<  endl;\n",
    "          cout << \"  The matrix order n                 = \" << n << endl;\n",
    "        \n",
    "          s = 1.0/sqrt( (double) n);\n",
    "          wtime = omp_get_wtime ( );\n",
    "          // Allocate space for the two matrices\n",
    "          A = new double*[n]; B = new double*[n]; C = new double*[n];\n",
    "          for (i = 0; i < n; i++){\n",
    "            A[i] = new double[n];\n",
    "            B[i] = new double[n];\n",
    "            C[i] = new double[n];\n",
    "          }\n",
    "          // Define parallel region\n",
    "        # pragma omp parallel for default(shared) private (angle, i, j, k) reduction(+:Fsum)\n",
    "          // Set up values for matrix A and B and zero matrix C\n",
    "          for (i = 0; i < n; i++){\n",
    "            for (j = 0; j < n; j++) {\n",
    "              angle = 2.0*M_PI*i*j/ (( double ) n);\n",
    "              A[i][j] = s * ( sin ( angle ) + cos ( angle ) );\n",
    "              B[j][i] =  A[i][j];\n",
    "            }\n",
    "          }\n",
    "          // Then perform the matrix-matrix multiplication\n",
    "          for (i = 0; i < n; i++){\n",
    "            for (j = 0; j < n; j++) {\n",
    "               C[i][j] =  0.0;    \n",
    "               for (k = 0; k < n; k++) {\n",
    "                    C[i][j] += A[i][k]*B[k][j];\n",
    "               }\n",
    "            }\n",
    "          }\n",
    "          // Compute now the Frobenius norm\n",
    "          Fsum = 0.0;\n",
    "          for (i = 0; i < n; i++){\n",
    "            for (j = 0; j < n; j++) {\n",
    "              Fsum += C[i][j]*C[i][j];\n",
    "            }\n",
    "          }\n",
    "          Fsum = sqrt(Fsum);\n",
    "        // end parallel region and letting only one thread perform I/O\n",
    "          wtime = omp_get_wtime ( ) - wtime;\n",
    "          cout << setiosflags(ios::showpoint | ios::uppercase);\n",
    "          cout << setprecision(10) << setw(20) << \"Time used  for matrix-matrix multiplication=\" << wtime  << endl;\n",
    "          cout << \"  Frobenius norm  = \" << Fsum << endl;\n",
    "          // Free up space\n",
    "          for (int i = 0; i < n; i++){\n",
    "            delete[] A[i];\n",
    "            delete[] B[i];\n",
    "            delete[] C[i];\n",
    "          }\n",
    "          delete[] A;\n",
    "          delete[] B;\n",
    "          delete[] C;\n",
    "          return 0;\n",
    "        }\n",
    "        \n",
    "        \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
